{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import time\n",
    "from pickle import load\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "K = keras.backend\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "from helper import *\n",
    "\n",
    "hr_data = np.load(\"ks_coarse_grained.npy\")\n",
    "\n",
    "data = np.mean(hr_data.reshape((hr_data.shape[0],20,5),order=\"C\"),axis=-1)\n",
    "\n",
    "# Can change amount of training data here. When we use only first 2000 or so, we get a bigger improvement \n",
    "# from transfer learning approach, even if dropout is included. \n",
    "\n",
    "training_data = data[:10000,:]\n",
    "hold_out_val = data[20000:30000]\n",
    "hold_out = data[70000:,:]\n",
    "\n",
    "training_data_high_res = hr_data[:10000,:]\n",
    "hold_out_val_high_res = hr_data[20000:30000]\n",
    "hold_out_high_res = hr_data[70000:,:]\n",
    "\n",
    "training_data_scaled = (training_data - training_data.mean())/training_data.std()\n",
    "hold_out_val_scaled = (hold_out_val-training_data.mean())/training_data.std()\n",
    "hold_out_scaled = (hold_out-training_data.mean())/training_data.std()\n",
    "\n",
    "training_data_scaled = np.expand_dims(training_data_scaled,axis=1)\n",
    "hold_out_val_scaled = np.expand_dims(hold_out_val_scaled,axis=1)\n",
    "hold_out_scaled = np.expand_dims(hold_out_scaled,axis=1)\n",
    "\n",
    "\n",
    "training_data_hr_scaled = (training_data_high_res - training_data_high_res.mean())/training_data_high_res.std()\n",
    "hold_out_hr_val_scaled = (hold_out_val_high_res-training_data_high_res.mean())/training_data_high_res.std()\n",
    "hold_out_hr_scaled = (hold_out_high_res-training_data_high_res.mean())/training_data_high_res.std()\n",
    "\n",
    "\n",
    "training_data_hr_scaled = np.expand_dims(training_data_hr_scaled,axis=1)\n",
    "hold_out_hr_val_scaled = np.expand_dims(hold_out_hr_val_scaled,axis=1)\n",
    "hold_out_hr_scaled = np.expand_dims(hold_out_hr_scaled,axis=1)\n",
    "\n",
    "\n",
    "history_length = 100\n",
    "\n",
    "k = 1\n",
    "\n",
    "num_dims = 20\n",
    "num_dims_hr = 100\n",
    "\n",
    "#Prepare RNN sequences\n",
    "\n",
    "def prepare_datasets_for_RNN(dataset,history_length,num_dims):\n",
    "    dataset = dataset[:(dataset.shape[0]//history_length)*history_length,:] # to make it multiple of history\n",
    "    dataset_shape = dataset.shape[0]\n",
    "    reshaped = dataset.reshape(int(dataset_shape/history_length),history_length,k,num_dims)\n",
    "    add_on = reshaped[1:,0,:,:]\n",
    "    add_on = add_on.reshape(int(dataset_shape/history_length)-1,1,k,num_dims)\n",
    "    reshaped = reshaped[:-1,:,:,:]\n",
    "    concat = np.concatenate((reshaped,add_on),axis=1)\n",
    "    concat = concat.reshape(((int(dataset_shape/history_length)-1)*(history_length+1),k,num_dims))\n",
    "    concat = concat.reshape((k*(int(dataset_shape/history_length)-1)*(history_length+1),num_dims),order=\"F\")\n",
    "    features = concat.reshape(k*(int(dataset_shape/history_length)-1),(history_length+1),num_dims)\n",
    "    \n",
    "    return features\n",
    "\n",
    "train_nn_features = prepare_datasets_for_RNN(training_data_scaled,history_length,num_dims)\n",
    "valid_nn_features = prepare_datasets_for_RNN(hold_out_val_scaled,history_length,num_dims)\n",
    "test_nn_features = hold_out_scaled.transpose([1,0,2])\n",
    "\n",
    "train_hr_nn_features = prepare_datasets_for_RNN(training_data_hr_scaled,history_length,num_dims_hr)\n",
    "valid_hr_nn_features =  prepare_datasets_for_RNN(hold_out_hr_val_scaled,history_length,num_dims_hr)\n",
    "test_hr_nn_features =  hold_out_hr_scaled.transpose([1,0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nn_input = train_nn_features[:,:-1,:]\n",
    "train_nn_output = train_nn_features[:,1:,:]\n",
    "\n",
    "train_hr_nn_input = train_hr_nn_features[:,:-1,:]\n",
    "train_hr_nn_output = train_hr_nn_features[:,1:,:]\n",
    "\n",
    "train_shape = train_nn_input.shape[0]\n",
    "\n",
    "\n",
    "valid_nn_input = valid_nn_features[:,:-1,:]\n",
    "valid_nn_output = valid_nn_features[:,1:,:]\n",
    "\n",
    "valid_hr_nn_input = valid_hr_nn_features[:,:-1,:]\n",
    "valid_hr_nn_output = valid_hr_nn_features[:,1:,:]\n",
    "\n",
    "valid_shape = valid_nn_input.shape[0]\n",
    "\n",
    "\n",
    "test_nn_input = test_nn_features[:,:-1,:]\n",
    "test_nn_output = test_nn_features[:,1:,:]\n",
    "\n",
    "test_hr_nn_input = test_hr_nn_features[:,:-1,:]\n",
    "test_hr_nn_output = test_hr_nn_features[:,1:,:]\n",
    "\n",
    "test_shape = test_nn_input.shape[0]\n",
    "\n",
    "def loglik_gaussian_x(array,mean,sigma):\n",
    "    term = -K.log(sigma**2 * 2*math.pi) - tf.math.divide((array-mean),sigma)**2\n",
    "    loglik = 0.5*term\n",
    "    return tf.math.reduce_sum(loglik,axis=[1,2])\n",
    "\n",
    "def loglik_gaussian_hr(array,mean,sigma):\n",
    "    term = -K.log(sigma**2 * 2*math.pi) - tf.math.divide((array-mean),sigma)**2\n",
    "    loglik = 0.5*term\n",
    "    return tf.math.reduce_sum(loglik,axis=[1,2])\n",
    "\n",
    "def loss(loglikelihood_x):\n",
    "    loglik = loglikelihood_x \n",
    "    loss = -loglik / history_length #to make it avg per spatial vector\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def valid_loss(valid_list,simulator,sigma_x,hr=False):\n",
    "    mean = simulator(valid_list,training=False)[0]\n",
    "    if hr == False:\n",
    "        return -np.mean(loglik_gaussian_x(valid_list[1],mean,sigma_x))\n",
    "    if hr == True:\n",
    "        return -np.mean(loglik_gaussian_x(valid_list[3],mean,sigma_x))\n",
    "\n",
    "\n",
    "hidden_state_size = 8\n",
    "\n",
    "hidden_in_train = np.zeros(shape=(train_shape,hidden_state_size))\n",
    "input_list = [train_nn_input,train_nn_output,train_hr_nn_input,train_hr_nn_output,hidden_in_train]\n",
    "\n",
    "hidden_in_test = np.zeros(shape=(test_shape,hidden_state_size))\n",
    "test_list = [test_nn_input,test_nn_output,test_hr_nn_input,test_hr_nn_output,hidden_in_test]\n",
    "\n",
    "hidden_in_valid = np.zeros(shape=(valid_shape,hidden_state_size))\n",
    "valid_list = [valid_nn_input,valid_nn_output,valid_hr_nn_input,valid_hr_nn_output,hidden_in_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No TL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 14:07:31.708685: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-11 14:07:32.452008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:3b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 14:07:33.652964: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-11 14:07:34.272186: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/99 [============================>.] - Loss for batch: 18.4026WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 18.4026  Val_loss: 660.7765 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 16.8881WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.8881  Val_loss: 564.9594 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 14.6874WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.6874  Val_loss: 484.7906 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 12.8669WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.8669  Val_loss: 423.4495 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 12.6050WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.6050  Val_loss: 384.1761 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 10.3901WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.3901  Val_loss: 362.8312 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 8.8495  Val_loss: 366.5126 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 7.7661  Val_loss: 395.8059 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 6.4287  Val_loss: 441.3385 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 5.2762  Val_loss: 504.5482 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 4.4444  Val_loss: 570.2888 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 2.7433  Val_loss: 659.8571 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 1.8437  Val_loss: 764.8899 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 0.5119  Val_loss: 884.3485 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -0.4011  Val_loss: 1016.5108 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -1.6411  Val_loss: 1187.9708 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -2.5039  Val_loss: 1370.5830 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -4.2453  Val_loss: 1570.0867 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -5.0269  Val_loss: 1834.6169 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -6.2262  Val_loss: 2068.8071 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -8.0057  Val_loss: 2270.9189 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -8.6294  Val_loss: 2484.4788 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -10.1940  Val_loss: 2724.1860 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -11.3347  Val_loss: 3015.5173 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -13.0773  Val_loss: 3335.2927 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -13.9870  Val_loss: 3625.5520 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -16.3316  Val_loss: 4031.5593 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -16.5324  Val_loss: 4511.0801 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -17.8531  Val_loss: 5072.3574 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -20.1351  Val_loss: 5396.7979 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -21.9578  Val_loss: 5483.2954 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -22.5416  Val_loss: 6173.9438 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -24.6904  Val_loss: 6312.9907 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -27.0212  Val_loss: 6843.7715 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -27.6965  Val_loss: 7645.9746 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -29.6637  Val_loss: 8666.6328 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -31.5163  Val_loss: 9670.0527 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -33.0721  Val_loss: 9573.5693 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -35.2988  Val_loss: 10956.6611 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -37.1154  Val_loss: 12298.9688 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -39.0555  Val_loss: 13544.9385 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -40.9459  Val_loss: 14549.5947 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -43.2719  Val_loss: 15755.2617 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -46.0328  Val_loss: 17372.7148 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -47.3208  Val_loss: 21584.1895 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -49.8996  Val_loss: 24606.3184 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -53.3844  Val_loss: 26681.3223 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -54.4714  Val_loss: 28459.3223 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -56.0705  Val_loss: 31034.3086 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -60.6285  Val_loss: 39248.9844 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -61.2358  Val_loss: 40057.2266 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -65.6948  Val_loss: 38642.3906 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -68.7361  Val_loss: 38267.2070 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -71.6190  Val_loss: 35862.9023 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -72.9434  Val_loss: 28120.4551 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -75.2834  Val_loss: 23332.8984 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -79.4579  Val_loss: 18422.5312 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -80.8481  Val_loss: 15396.0977 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -84.4701  Val_loss: 9570.0527 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -84.5113  Val_loss: 9074.0332 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -87.6350  Val_loss: 7646.2178 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -88.9159  Val_loss: 4121.6084 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -89.0513  Val_loss: 3414.7229 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -89.8822  Val_loss: 540.5596 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -90.2680WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.2680  Val_loss: 63.0529 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -92.8033  Val_loss: 198.9878 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -92.3277WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.3277  Val_loss: -220.5763 \n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/99 [============================>.] - Loss for batch: -93.7310WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.7310  Val_loss: -1675.3729 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -94.3850  Val_loss: 736.7327 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.8494  Val_loss: 544.6407 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.9650  Val_loss: 2090.3069 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.2223  Val_loss: 1558.7887 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.8926  Val_loss: 3334.6284 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.7834  Val_loss: 5026.2114 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.5942  Val_loss: 5186.8511 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.9847  Val_loss: 6000.3989 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -94.9903  Val_loss: 7223.5791 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.8896  Val_loss: 7209.1753 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -95.9967  Val_loss: 7307.3662 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.5930  Val_loss: 8944.5684 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -98.5401  Val_loss: 9364.5586 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.4870  Val_loss: 10004.3086 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.1640  Val_loss: 9597.2363 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.9428  Val_loss: 9812.7812 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -98.7855  Val_loss: 9376.8740 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.1134  Val_loss: 10457.5654 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.4232  Val_loss: 10274.7979 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.0992  Val_loss: 10452.8730 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -100.0540  Val_loss: 10492.3857 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.8151  Val_loss: 9283.2627 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -100.8584  Val_loss: 7459.7529 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.6550  Val_loss: 7547.6890 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -100.9471  Val_loss: 6896.5967 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -100.1179  Val_loss: 8100.3813 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.6831  Val_loss: 8933.6074 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.6517  Val_loss: 9384.7012 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -100.4761  Val_loss: 10284.1670 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.2494  Val_loss: 10447.4268 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.5964  Val_loss: 9672.2783 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.5607  Val_loss: 11230.1426 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -101.7942  Val_loss: 9608.6729 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -102.0641  Val_loss: 8644.2402 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -100.0106  Val_loss: 7046.6118 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -101.3158  Val_loss: 6650.1338 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -102.0144  Val_loss: 6487.3838 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.1312  Val_loss: 5813.5366 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -101.3304  Val_loss: 6319.9692 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -100.1167  Val_loss: 7355.2729 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -100.7458  Val_loss: 8804.2773 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.7942  Val_loss: 9467.6348 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.1555  Val_loss: 12355.3369 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.7652  Val_loss: 11158.2109 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -101.1520  Val_loss: 11402.0762 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.0633  Val_loss: 11395.0078 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -101.2761  Val_loss: 9790.7031 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -101.8378  Val_loss: 10169.1777 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -103.0014  Val_loss: 9930.1094 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -102.1520  Val_loss: 11168.8350 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -100.8076  Val_loss: 11320.3418 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.9972  Val_loss: 12163.3486 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.1703  Val_loss: 12474.6328 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.5487  Val_loss: 10589.1777 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -101.3424  Val_loss: 10266.5215 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -101.2042  Val_loss: 8937.5723 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -102.2226  Val_loss: 8098.3535 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -100.6534  Val_loss: 9161.8672 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.5798  Val_loss: 10153.7969 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -102.3188  Val_loss: 8652.8740 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.7103  Val_loss: 7037.4087 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -102.2749  Val_loss: 6970.0063 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.1636  Val_loss: 7642.0840 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.9781  Val_loss: 9936.0205 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.4713  Val_loss: 11343.3867 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.3736  Val_loss: 11761.3477 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -102.9295  Val_loss: 11754.8389 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -102.2741  Val_loss: 10910.4971 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -102.7677  Val_loss: 10325.4736 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.7607  Val_loss: 9454.0225 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -102.1479  Val_loss: 7918.0396 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -102.2596  Val_loss: 8628.4883 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -101.5312  Val_loss: 10467.5986 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.7291  Val_loss: 12011.6562 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -102.1256  Val_loss: 12229.8418 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -102.0006  Val_loss: 12986.7656 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -103.2500  Val_loss: 11850.1367 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -102.6303  Val_loss: 10121.1162 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -100.5156  Val_loss: 9479.6436 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.8427  Val_loss: 9940.4434 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -102.3657  Val_loss: 11467.7812 \n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -102.1395  Val_loss: 13151.3691 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -103.1329  Val_loss: 12388.5791 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.2904  Val_loss: 9472.7744 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.3812  Val_loss: 8860.9619 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.5456  Val_loss: 8241.5117 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -102.6214  Val_loss: 8786.1445 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.5878  Val_loss: 10206.3721 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -102.9808  Val_loss: 10354.8623 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -102.8734  Val_loss: 9657.4111 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.6800  Val_loss: 10436.5938 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.6304  Val_loss: 10499.0957 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.6835  Val_loss: 9275.9004 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -100.7529  Val_loss: 8965.7764 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.2636  Val_loss: 10161.7832 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -102.7076  Val_loss: 10738.3115 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -101.4397  Val_loss: 11678.2012 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -102.7100  Val_loss: 10943.2900 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -100.8113  Val_loss: 11188.0303 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -99.8824  Val_loss: 8813.2559 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.6259  Val_loss: 8331.7705 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.4525  Val_loss: 10188.2051 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.6058  Val_loss: 10154.9912 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.6701  Val_loss: 11464.4180 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.8919  Val_loss: 8585.1738 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -101.5645  Val_loss: 7198.4712 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.2856  Val_loss: 5720.3228 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.3238  Val_loss: 6049.9336 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -103.2353  Val_loss: 6608.1855 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.5071  Val_loss: 8724.7295 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.8970  Val_loss: 9199.2549 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.6353  Val_loss: 10466.6670 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.4163  Val_loss: 12398.6094 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -102.8536  Val_loss: 13599.6377 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -102.5787  Val_loss: 11920.3115 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.2132  Val_loss: 9741.8506 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.9678  Val_loss: 8531.6455 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.1054  Val_loss: 9318.5244 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.9780  Val_loss: 9083.3506 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.2958  Val_loss: 9126.7227 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.6998  Val_loss: 9300.1953 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -102.8087  Val_loss: 9571.6719 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.2023  Val_loss: 7240.8120 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -101.6137  Val_loss: 7109.2310 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.2446  Val_loss: 7602.1289 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -103.1873  Val_loss: 8474.2451 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.9302  Val_loss: 9278.4287 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -103.4579  Val_loss: 8328.1523 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -102.4800  Val_loss: 7541.8916 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.3264  Val_loss: 8416.7773 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -103.5607  Val_loss: 9231.7959 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -103.0562  Val_loss: 8800.5762 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 13.6514WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.6514  Val_loss: 579.9417 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 11.9067WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.9067  Val_loss: 499.3145 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 10.4402WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.4402  Val_loss: 436.0240 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 9.1544WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.1544  Val_loss: 390.9359 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 7.0204WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.0204  Val_loss: 372.8230 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 5.3920  Val_loss: 389.0883 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 3.0529  Val_loss: 432.8750 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 2.2040  Val_loss: 487.2746 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 0.2626  Val_loss: 570.9281 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -1.9730  Val_loss: 655.3566 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -2.3959  Val_loss: 756.0876 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -4.3456  Val_loss: 860.8779 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -5.4274  Val_loss: 955.5610 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -6.6579  Val_loss: 1049.5055 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -8.5580  Val_loss: 1184.5386 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -9.1328  Val_loss: 1344.5103 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -10.2001  Val_loss: 1588.1746 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -12.9272  Val_loss: 1924.1418 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -12.7358  Val_loss: 2277.0615 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -15.5301  Val_loss: 2572.9912 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -16.3835  Val_loss: 2733.9031 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -17.6755  Val_loss: 2950.1401 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -17.6644  Val_loss: 3101.5830 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -20.1718  Val_loss: 3370.4202 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -21.3768  Val_loss: 3830.1511 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -24.7753  Val_loss: 4239.1768 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -24.7642  Val_loss: 4706.7476 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -25.2634  Val_loss: 5072.3545 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -26.8875  Val_loss: 5432.1221 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -29.4472  Val_loss: 5926.6997 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -31.6709  Val_loss: 6431.4014 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -32.3082  Val_loss: 7152.6104 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -33.4524  Val_loss: 7674.5449 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -36.6035  Val_loss: 8880.0381 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -39.2029  Val_loss: 9771.2930 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -38.8933  Val_loss: 10630.7705 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -41.1480  Val_loss: 12385.7188 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -44.6313  Val_loss: 13309.4756 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -44.5334  Val_loss: 15492.3154 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -48.0987  Val_loss: 15159.9355 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -50.3043  Val_loss: 17741.7539 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -51.7752  Val_loss: 19040.6992 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -54.1596  Val_loss: 18815.2812 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -57.5751  Val_loss: 19994.6113 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -57.3186  Val_loss: 21172.2480 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -60.7250  Val_loss: 18947.2930 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -61.2147  Val_loss: 24796.8359 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -64.4419  Val_loss: 24657.6230 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -66.2454  Val_loss: 27843.9375 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -68.5498  Val_loss: 24556.3262 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -67.7319  Val_loss: 23900.4902 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -72.2540  Val_loss: 24288.8027 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -73.3845  Val_loss: 25557.1875 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -76.4048  Val_loss: 20973.6504 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -78.3671  Val_loss: 17560.6387 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -80.0647  Val_loss: 14923.6504 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -83.2091  Val_loss: 11080.8877 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.1645  Val_loss: 9628.0293 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -85.2514  Val_loss: 7853.9780 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -86.4475  Val_loss: 6298.3491 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -88.0684  Val_loss: 4058.5068 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -90.0802  Val_loss: 1678.9026 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -90.1517WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.1517  Val_loss: 180.7865 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -91.5802WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.5802  Val_loss: -754.6002 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -91.8424WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -91.8424  Val_loss: -1878.5146 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -93.0057  Val_loss: -1828.3014 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -92.2056  Val_loss: -1628.5820 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -94.3109WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.3109  Val_loss: -2210.9958 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -94.3201  Val_loss: -1713.6492 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.6912  Val_loss: -1537.7628 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -95.2164  Val_loss: -1106.4849 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.1188  Val_loss: -1424.7579 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -96.2251  Val_loss: -1391.7441 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.5139  Val_loss: 540.1505 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.2875  Val_loss: -9.1460 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.2076  Val_loss: 1579.1407 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.6459  Val_loss: 1882.4617 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.6293  Val_loss: 3480.7146 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.1517  Val_loss: 3172.9038 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.8752  Val_loss: 4327.5630 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.6253  Val_loss: 3934.7922 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.9339  Val_loss: 5091.7300 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.7542  Val_loss: 6847.9360 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.3351  Val_loss: 8059.3862 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.4781  Val_loss: 8108.8140 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -99.1913  Val_loss: 8053.5151 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -95.9808  Val_loss: 7491.2612 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.5316  Val_loss: 7239.0942 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -99.9037  Val_loss: 7694.0581 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.5916  Val_loss: 7914.7451 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.1655  Val_loss: 8511.4473 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.7158  Val_loss: 8230.8564 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.6157  Val_loss: 8037.8672 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.7442  Val_loss: 8228.4775 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -100.4983  Val_loss: 9472.7832 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.3474  Val_loss: 8837.6719 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -99.1953  Val_loss: 11316.5576 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.5744  Val_loss: 11696.8018 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -100.4869  Val_loss: 11972.8740 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.3291  Val_loss: 11922.4316 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -99.3014  Val_loss: 11869.5059 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -98.5787  Val_loss: 12569.5059 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.7118  Val_loss: 13031.7725 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.5909  Val_loss: 14257.9521 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.9568  Val_loss: 14734.1416 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -98.3459  Val_loss: 13104.9453 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.3301  Val_loss: 12731.9990 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.3154  Val_loss: 14160.8242 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -99.4272  Val_loss: 17026.1562 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.1030  Val_loss: 16587.6660 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.9510  Val_loss: 19006.5723 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.8115  Val_loss: 16042.0557 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.5109  Val_loss: 17282.3867 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.8216  Val_loss: 16433.4414 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.9174  Val_loss: 15815.9453 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.0070  Val_loss: 13629.0078 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.7180  Val_loss: 13360.5479 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -101.4336  Val_loss: 14032.7754 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -101.0940  Val_loss: 14602.5850 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.5731  Val_loss: 14544.4834 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.0907  Val_loss: 16553.1348 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.0284  Val_loss: 14526.1592 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.0292  Val_loss: 15839.1338 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.4272  Val_loss: 17456.4277 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.0482  Val_loss: 18111.9316 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.8732  Val_loss: 19010.0117 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.6001  Val_loss: 18400.6230 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.9073  Val_loss: 18712.8262 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.4809  Val_loss: 18097.0371 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.7225  Val_loss: 20041.4219 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -102.5755  Val_loss: 20574.3730 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -102.4572  Val_loss: 20961.5977 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.7079  Val_loss: 20065.2559 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -101.6816  Val_loss: 19306.0176 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.9477  Val_loss: 18534.1406 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.4322  Val_loss: 17677.7910 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -100.8135  Val_loss: 15775.7227 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -100.8032  Val_loss: 16754.7480 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -102.3155  Val_loss: 16296.0098 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.6871  Val_loss: 18965.8008 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.3087  Val_loss: 18848.4004 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.6067  Val_loss: 18422.7949 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -101.9565  Val_loss: 15316.6582 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.3963  Val_loss: 15681.2236 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -102.1978  Val_loss: 14205.3242 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -99.5765  Val_loss: 16883.4336 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -101.0175  Val_loss: 18089.1094 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -101.3233  Val_loss: 17824.0137 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -102.3536  Val_loss: 18545.4395 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.4548  Val_loss: 18721.2070 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -101.0845  Val_loss: 19724.4102 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.6495  Val_loss: 18337.6523 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.4612  Val_loss: 17337.3379 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.1167  Val_loss: 14418.4043 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -100.8970  Val_loss: 15810.4238 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.9258  Val_loss: 15060.1494 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -102.2003  Val_loss: 16228.2021 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -102.4344  Val_loss: 15398.2451 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -100.4698  Val_loss: 17708.8984 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -102.3298  Val_loss: 20345.8359 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.6751  Val_loss: 19174.3945 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -101.8750  Val_loss: 17831.5820 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.6573  Val_loss: 17898.3867 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -102.0798  Val_loss: 19894.2617 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -103.0034  Val_loss: 21258.2324 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.3646  Val_loss: 20429.8555 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.9799  Val_loss: 20174.8984 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -103.1726  Val_loss: 19688.3984 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -102.8976  Val_loss: 17931.5703 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -103.5333  Val_loss: 18318.1660 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -100.6636  Val_loss: 18003.0703 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -102.2843  Val_loss: 18876.3125 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -100.9532  Val_loss: 19795.5664 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.7760  Val_loss: 22123.3379 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.3464  Val_loss: 20167.6758 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -102.1199  Val_loss: 19248.7617 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -103.4869  Val_loss: 17790.0879 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.4846  Val_loss: 18980.2988 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -103.5031  Val_loss: 18038.6230 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -103.7196  Val_loss: 18555.7852 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -100.7556  Val_loss: 17968.5215 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -102.6432  Val_loss: 21010.6719 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -102.2495  Val_loss: 21527.7871 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -102.2891  Val_loss: 24007.2812 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.2390  Val_loss: 21711.2559 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.2200  Val_loss: 19996.3516 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -102.4708  Val_loss: 18078.2344 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.0739  Val_loss: 16647.6777 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.3965  Val_loss: 19321.2031 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -103.9110  Val_loss: 19694.4668 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.7538  Val_loss: 19019.4766 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -100.9676  Val_loss: 18906.8301 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -103.6106  Val_loss: 18668.3613 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.9288  Val_loss: 20077.6738 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -103.8531  Val_loss: 21173.2383 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -103.4034  Val_loss: 19643.0156 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -103.3118  Val_loss: 18761.7578 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.6932  Val_loss: 17769.7383 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -102.1777  Val_loss: 18779.6621 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.7109  Val_loss: 18809.4551 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 16.7112WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.7112  Val_loss: 818.5536 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 15.2590WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 15.2590  Val_loss: 742.3434 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 14.3601WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.3601  Val_loss: 672.1094 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 12.2015WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.2015  Val_loss: 613.8893 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 11.4236WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.4236  Val_loss: 575.7488 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 10.1153WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.1153  Val_loss: 557.3664 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 8.7057  Val_loss: 566.0759 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 7.1613  Val_loss: 605.4063 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 6.1486  Val_loss: 680.6624 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 4.5005  Val_loss: 800.1958 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 3.4324  Val_loss: 971.5951 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 2.1904  Val_loss: 1156.6469 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 1.4713  Val_loss: 1306.5681 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -0.2618  Val_loss: 1456.9268 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -1.1570  Val_loss: 1596.5673 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -2.0234  Val_loss: 1684.4229 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -3.6479  Val_loss: 1755.4849 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -4.4796  Val_loss: 1812.0570 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -5.9069  Val_loss: 1869.8409 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -7.3241  Val_loss: 1953.5514 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -7.8510  Val_loss: 2111.6155 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -9.5714  Val_loss: 2222.6733 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -10.3471  Val_loss: 2229.8230 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -12.8377  Val_loss: 2138.7256 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -13.8559  Val_loss: 1993.2521 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -16.2846  Val_loss: 1986.7294 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -16.5887  Val_loss: 2056.4270 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -18.5009  Val_loss: 2137.6182 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -20.3706  Val_loss: 2173.3042 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -21.9136  Val_loss: 2290.2207 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -23.7122  Val_loss: 2291.9045 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -25.2781  Val_loss: 2383.2783 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -27.6398  Val_loss: 2723.3665 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -29.7006  Val_loss: 3245.4277 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -30.5503  Val_loss: 3766.4795 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -33.5362  Val_loss: 4329.4399 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -36.4583  Val_loss: 5002.9058 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -37.7919  Val_loss: 6010.4971 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -40.2084  Val_loss: 7545.3359 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -42.6632  Val_loss: 8063.0488 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -44.8859  Val_loss: 9714.7773 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -47.1586  Val_loss: 11880.7080 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -49.3124  Val_loss: 12921.1943 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -51.1544  Val_loss: 14061.6826 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -54.7533  Val_loss: 15619.8154 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -55.4685  Val_loss: 19272.5859 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -57.9714  Val_loss: 19950.9785 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -60.1003  Val_loss: 23391.1406 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -63.8984  Val_loss: 24212.7324 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -66.1369  Val_loss: 26167.1406 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -67.9700  Val_loss: 27395.9688 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -70.2731  Val_loss: 25102.7148 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -72.2985  Val_loss: 25451.5273 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -73.9338  Val_loss: 24900.4824 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -77.1870  Val_loss: 21202.7852 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -78.4166  Val_loss: 23369.9199 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -81.0416  Val_loss: 22353.5781 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.3385  Val_loss: 15940.7588 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -83.8101  Val_loss: 13864.5732 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -86.4271  Val_loss: 9514.3242 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -86.4368  Val_loss: 9055.1934 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -88.3267  Val_loss: 4387.9175 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -88.7211  Val_loss: 3435.0088 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -91.1627  Val_loss: 2308.0105 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -90.2014  Val_loss: 1630.2874 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -91.7631WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.7631  Val_loss: 427.3632 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -93.9832  Val_loss: 1036.5217 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -94.3909WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -94.3909  Val_loss: 188.8715 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -92.6093WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.6093  Val_loss: -782.4329 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -95.8256WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.8256  Val_loss: -940.4280 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -95.6593WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.6593  Val_loss: -1716.3282 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.0652  Val_loss: -815.1218 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.1253  Val_loss: -1155.7285 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.7782  Val_loss: -471.8120 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.9529  Val_loss: -593.0084 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.6572  Val_loss: 840.1070 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.1435  Val_loss: 1267.7092 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.0433  Val_loss: 3266.1167 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.6449  Val_loss: 3477.4937 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.7338  Val_loss: 4959.6138 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.9749  Val_loss: 6427.1924 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.0242  Val_loss: 6674.9023 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.9887  Val_loss: 6907.6372 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.0301  Val_loss: 7305.9263 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -99.0304  Val_loss: 9361.5303 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.6090  Val_loss: 8943.3301 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.8698  Val_loss: 10074.2139 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.5473  Val_loss: 10792.0830 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.6768  Val_loss: 11845.9561 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.7120  Val_loss: 8408.9121 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.1901  Val_loss: 9770.8682 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.1925  Val_loss: 8955.1787 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.6249  Val_loss: 11665.5352 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.9911  Val_loss: 12588.9004 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -100.5896  Val_loss: 14043.6426 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.9398  Val_loss: 13240.7451 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -100.6521  Val_loss: 13101.8594 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.1790  Val_loss: 12601.6953 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.9786  Val_loss: 14919.3594 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -100.4931  Val_loss: 14844.6201 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.6669  Val_loss: 16329.3887 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.6865  Val_loss: 16910.5898 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.8356  Val_loss: 17044.6133 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -100.0967  Val_loss: 18670.5898 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.6620  Val_loss: 17818.4941 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.1621  Val_loss: 14873.7490 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -100.6389  Val_loss: 13864.9150 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.5697  Val_loss: 15418.7441 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.7049  Val_loss: 17379.1582 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.3917  Val_loss: 17634.6504 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -100.9930  Val_loss: 16371.5645 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.1222  Val_loss: 16969.6543 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.3925  Val_loss: 18665.8828 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.3157  Val_loss: 17618.5371 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -101.8149  Val_loss: 16801.4297 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.2980  Val_loss: 17096.6016 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.6860  Val_loss: 17175.3906 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -101.2586  Val_loss: 18584.8223 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -100.9230  Val_loss: 17568.8301 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.4991  Val_loss: 18272.2656 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.6277  Val_loss: 16255.6562 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -102.2918  Val_loss: 12980.0820 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.1809  Val_loss: 14641.1260 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.8515  Val_loss: 17334.2422 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -100.5927  Val_loss: 19325.6270 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -102.0923  Val_loss: 19493.8086 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.6221  Val_loss: 22059.1270 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -101.9738  Val_loss: 20860.7910 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.2812  Val_loss: 19323.3633 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.4220  Val_loss: 15976.3721 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.2595  Val_loss: 17123.1133 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.8316  Val_loss: 16985.5156 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.7047  Val_loss: 13470.4092 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -101.0295  Val_loss: 15648.1670 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.4338  Val_loss: 17339.3477 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -102.5771  Val_loss: 16209.0615 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -101.7171  Val_loss: 15974.7227 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.5694  Val_loss: 18251.7344 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.8896  Val_loss: 18410.1387 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -102.2916  Val_loss: 18035.9707 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -103.2103  Val_loss: 20024.1953 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -102.7152  Val_loss: 17513.9551 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -100.4781  Val_loss: 16489.9219 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.9635  Val_loss: 14240.8838 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.3014  Val_loss: 16952.6191 \n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -100.6081  Val_loss: 16185.6309 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -101.2268  Val_loss: 19400.1270 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -102.0473  Val_loss: 20935.6816 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.7756  Val_loss: 22697.6309 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -102.0678  Val_loss: 20156.7383 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.2178  Val_loss: 20196.6523 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.6900  Val_loss: 20526.7227 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -101.4085  Val_loss: 21860.6387 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.2119  Val_loss: 20757.8555 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.9425  Val_loss: 20907.5566 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.8044  Val_loss: 18738.7559 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.7091  Val_loss: 19956.3594 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.7088  Val_loss: 20953.5938 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -101.5734  Val_loss: 21001.0312 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -102.3587  Val_loss: 22033.0449 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.2297  Val_loss: 21229.4277 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -102.6971  Val_loss: 19750.7500 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.6472  Val_loss: 21068.5332 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.2334  Val_loss: 19614.5605 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -101.2300  Val_loss: 22782.1348 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.8840  Val_loss: 21724.1523 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -103.4576  Val_loss: 21735.6465 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -102.5515  Val_loss: 19896.5449 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -102.2889  Val_loss: 20237.8086 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.4808  Val_loss: 18332.0781 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -100.8080  Val_loss: 22254.3730 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.7757  Val_loss: 21278.9141 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.6198  Val_loss: 19828.8574 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.9092  Val_loss: 19640.0117 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.1133  Val_loss: 19273.6250 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.9451  Val_loss: 19931.5273 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -103.0486  Val_loss: 18738.4238 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.1683  Val_loss: 17679.6660 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.7415  Val_loss: 19106.9941 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.6887  Val_loss: 19538.6152 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -103.8127  Val_loss: 16517.4238 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -102.4018  Val_loss: 15897.0176 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -102.1306  Val_loss: 16541.1152 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -102.8928  Val_loss: 17328.7871 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.4533  Val_loss: 18203.8418 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.9741  Val_loss: 16344.0723 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.7110  Val_loss: 16732.2012 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -101.3846  Val_loss: 19392.7988 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.1013  Val_loss: 25143.6445 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.9809  Val_loss: 23898.0449 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.1323  Val_loss: 22499.8848 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -102.4177  Val_loss: 18975.5547 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -101.5604  Val_loss: 17202.9590 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.7200  Val_loss: 17094.3184 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -103.0033  Val_loss: 17439.3984 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -101.9458  Val_loss: 18160.0625 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -102.1565  Val_loss: 20152.8340 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -103.2984  Val_loss: 19463.2246 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.9112  Val_loss: 21367.3691 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.6922  Val_loss: 19970.3496 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "3\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 21.0671WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 21.0671  Val_loss: 884.1255 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 20.3430WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 20.3430  Val_loss: 761.5704 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 18.8374WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 18.8374  Val_loss: 640.7850 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 17.8716WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 17.8716  Val_loss: 526.8738 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 16.0920WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.0920  Val_loss: 422.0121 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 14.6065WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.6065  Val_loss: 326.5237 \n",
      "Epoch 6/200\n",
      "96/99 [============================>.] - Loss for batch: 12.6708WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.6708  Val_loss: 242.0982 \n",
      "Epoch 7/200\n",
      "96/99 [============================>.] - Loss for batch: 11.8600WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.8600  Val_loss: 170.3473 \n",
      "Epoch 8/200\n",
      "96/99 [============================>.] - Loss for batch: 10.9508WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.9508  Val_loss: 112.2105 \n",
      "Epoch 9/200\n",
      "96/99 [============================>.] - Loss for batch: 10.2545WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.2545  Val_loss: 71.8261 \n",
      "Epoch 10/200\n",
      "96/99 [============================>.] - Loss for batch: 8.8861WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.8861  Val_loss: 52.2749 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 7.3765  Val_loss: 56.9102 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 5.2273  Val_loss: 81.1791 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 4.2221  Val_loss: 116.8064 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: 2.7749  Val_loss: 147.3535 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: 2.1298  Val_loss: 170.8438 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: 0.7157  Val_loss: 181.7070 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -0.4484  Val_loss: 189.7599 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -1.5834  Val_loss: 193.0799 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -2.8589  Val_loss: 198.0583 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -4.3594  Val_loss: 196.2706 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -5.3699  Val_loss: 202.3064 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -6.7371  Val_loss: 212.3193 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -7.7213  Val_loss: 212.5244 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -8.7408  Val_loss: 211.5523 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -10.6025  Val_loss: 224.1779 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -12.2432  Val_loss: 299.2091 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -13.8603  Val_loss: 426.0090 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -14.8868  Val_loss: 584.3268 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -17.4648  Val_loss: 794.6805 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -18.7836  Val_loss: 1094.4775 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -20.3407  Val_loss: 1435.1766 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -22.6872  Val_loss: 1816.8376 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -23.5737  Val_loss: 2267.5999 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -26.2523  Val_loss: 2648.0227 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -28.1606  Val_loss: 2932.6099 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -30.3104  Val_loss: 3690.6216 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -32.7260  Val_loss: 4324.9521 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -33.9745  Val_loss: 4938.5693 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -35.4125  Val_loss: 5249.0972 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -37.9914  Val_loss: 6907.8906 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -39.9068  Val_loss: 7806.9614 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -42.2108  Val_loss: 7594.9526 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -44.4336  Val_loss: 8971.0947 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -46.6495  Val_loss: 9788.3906 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -49.8493  Val_loss: 10273.2559 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -50.8876  Val_loss: 12319.2471 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -54.4069  Val_loss: 14867.3760 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -56.0822  Val_loss: 15997.1152 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -57.6365  Val_loss: 16655.5742 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -62.3625  Val_loss: 19851.7051 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -64.2417  Val_loss: 20816.4121 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -65.8541  Val_loss: 21801.3105 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -68.5162  Val_loss: 21426.2930 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -72.0736  Val_loss: 21852.4746 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -74.8387  Val_loss: 22784.4844 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -76.7747  Val_loss: 18249.8340 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -78.5782  Val_loss: 12004.4668 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -82.5041  Val_loss: 12067.8447 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -83.7238  Val_loss: 7262.5576 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -85.1572  Val_loss: 5984.0337 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -88.5608  Val_loss: 4287.7285 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -88.4064  Val_loss: 2502.2524 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -90.1540  Val_loss: 485.5677 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -90.5209WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.5209  Val_loss: -2324.3291 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -91.3531  Val_loss: -1029.0853 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -92.4029  Val_loss: -1230.8062 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -93.9765  Val_loss: -1592.8302 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -94.1330WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.1330  Val_loss: -2388.9807 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -94.2181WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.2181  Val_loss: -2782.9414 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.3803  Val_loss: -2291.1604 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -93.4432  Val_loss: -2710.3091 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.1618  Val_loss: -1034.1245 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.3258  Val_loss: -956.3419 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.3936  Val_loss: 821.2140 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -97.9367  Val_loss: 972.8357 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.4211  Val_loss: 1647.5483 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.6235  Val_loss: 3662.9910 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.2529  Val_loss: 4072.1677 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.1530  Val_loss: 6265.2593 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.6900  Val_loss: 4355.4526 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.1007  Val_loss: 6115.9141 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.3235  Val_loss: 5612.6904 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.8384  Val_loss: 7384.6270 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.2829  Val_loss: 8948.8379 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.6079  Val_loss: 10732.9170 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.6160  Val_loss: 11732.3184 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.4301  Val_loss: 11082.5615 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.0120  Val_loss: 11652.9355 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.3462  Val_loss: 10030.7744 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.5651  Val_loss: 12034.0215 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.0557  Val_loss: 13883.4189 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.8078  Val_loss: 15206.2070 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.8351  Val_loss: 14666.7715 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.7296  Val_loss: 13827.5176 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.1996  Val_loss: 14076.3486 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -99.0622  Val_loss: 16191.4531 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.6048  Val_loss: 15904.4209 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -100.0135  Val_loss: 16522.8438 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.4556  Val_loss: 15879.7666 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -100.4003  Val_loss: 13392.8691 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.0664  Val_loss: 14473.8115 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -100.5212  Val_loss: 15043.5615 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -100.9337  Val_loss: 18140.3027 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.9253  Val_loss: 19729.9004 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.3074  Val_loss: 20816.4199 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -100.4477  Val_loss: 18860.4336 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -100.6519  Val_loss: 17945.6445 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -101.3539  Val_loss: 17541.6836 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.6776  Val_loss: 18515.1543 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -101.0272  Val_loss: 16271.3076 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.4249  Val_loss: 15846.4053 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.5811  Val_loss: 14310.7959 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.0645  Val_loss: 16376.8330 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.9915  Val_loss: 18661.5156 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -101.0086  Val_loss: 19462.1074 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.9951  Val_loss: 20734.2734 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -102.1997  Val_loss: 17378.5664 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -102.3854  Val_loss: 17210.5098 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.3338  Val_loss: 14226.5459 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.1947  Val_loss: 15546.8057 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.5100  Val_loss: 16217.2637 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.0639  Val_loss: 17703.4062 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -101.5645  Val_loss: 19258.4863 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.1014  Val_loss: 19394.4883 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -101.6914  Val_loss: 18207.8379 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.2147  Val_loss: 14684.0762 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.9500  Val_loss: 15994.1758 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.0866  Val_loss: 18670.8965 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.4881  Val_loss: 16897.6172 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.5374  Val_loss: 15808.7012 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.5528  Val_loss: 16659.5527 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.7592  Val_loss: 17600.8809 \n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -100.2207  Val_loss: 19961.7227 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.2724  Val_loss: 18162.2559 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.5951  Val_loss: 16854.4453 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -102.4727  Val_loss: 14426.4512 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.6020  Val_loss: 14151.7363 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -102.7065  Val_loss: 15288.6406 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.3329  Val_loss: 17429.9727 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.5588  Val_loss: 17961.4922 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.8380  Val_loss: 18006.1953 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -103.0417  Val_loss: 17794.7520 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.2586  Val_loss: 15727.0938 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.1764  Val_loss: 16319.5742 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.6737  Val_loss: 15418.4814 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -103.2846  Val_loss: 16081.6904 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -101.0764  Val_loss: 16677.9102 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -102.2324  Val_loss: 15006.2158 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -100.6094  Val_loss: 15174.8154 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -101.1517  Val_loss: 15595.3594 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.9036  Val_loss: 16926.8438 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.1639  Val_loss: 16145.2900 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.9676  Val_loss: 17051.0488 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -102.0805  Val_loss: 15809.6953 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -102.8805  Val_loss: 15372.4365 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.3952  Val_loss: 15660.7383 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.8408  Val_loss: 15578.4922 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.3040  Val_loss: 15927.4639 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -102.1459  Val_loss: 15258.2617 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.9746  Val_loss: 15144.7344 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -100.2113  Val_loss: 13618.2930 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.6252  Val_loss: 14754.6807 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -100.6348  Val_loss: 13978.9014 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -103.3569  Val_loss: 13265.7041 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -102.6367  Val_loss: 13258.8887 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -103.0147  Val_loss: 14365.9863 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -101.5811  Val_loss: 15303.7637 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -100.7409  Val_loss: 15544.8438 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -101.4348  Val_loss: 13939.1025 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.6953  Val_loss: 13820.0039 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -103.2933  Val_loss: 12774.5596 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.6898  Val_loss: 13405.6709 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -101.6458  Val_loss: 12081.3145 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -100.4366  Val_loss: 14074.0557 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.8566  Val_loss: 13993.2588 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -102.8333  Val_loss: 15706.9990 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.8262  Val_loss: 13801.9521 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -103.1735  Val_loss: 13737.0010 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.0946  Val_loss: 14968.9727 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.2482  Val_loss: 15590.0420 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -102.6730  Val_loss: 14120.2969 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -103.0729  Val_loss: 14063.9346 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -100.8411  Val_loss: 14450.0547 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -103.3079  Val_loss: 15705.8359 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -101.8418  Val_loss: 15772.3848 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -102.1164  Val_loss: 16150.6348 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -103.1436  Val_loss: 15448.6885 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.3090  Val_loss: 17046.8105 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.9926  Val_loss: 16298.9951 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.5318  Val_loss: 13618.9658 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -102.5807  Val_loss: 11271.7559 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -103.2525  Val_loss: 13093.5732 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -102.4803  Val_loss: 14233.6641 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -101.9322  Val_loss: 15217.7969 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.9150  Val_loss: 14419.1982 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -100.6258  Val_loss: 13303.4688 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.8146  Val_loss: 15375.8066 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.5317  Val_loss: 15467.3701 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.3414  Val_loss: 14428.3438 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 12.7736WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.7736  Val_loss: 1080.7117 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 10.9129  Val_loss: 1123.0209 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 9.7775  Val_loss: 1175.6160 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 8.8820  Val_loss: 1249.1179 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 7.7881  Val_loss: 1342.2140 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 6.9568  Val_loss: 1457.9438 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 6.2235  Val_loss: 1586.5815 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 4.5887  Val_loss: 1718.6088 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 3.0302  Val_loss: 1852.7711 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 1.7515  Val_loss: 1980.8956 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 1.7784  Val_loss: 2109.6392 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 0.5272  Val_loss: 2198.9329 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.1415  Val_loss: 2277.2920 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -2.2947  Val_loss: 2329.3730 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -3.3578  Val_loss: 2375.7959 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -4.5451  Val_loss: 2416.5696 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -5.3259  Val_loss: 2514.8945 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -6.2853  Val_loss: 2645.3257 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -8.0808  Val_loss: 2793.0676 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -8.7155  Val_loss: 2986.4961 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -10.5478  Val_loss: 3182.0142 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -11.0548  Val_loss: 3370.1577 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -13.1033  Val_loss: 3543.5671 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -14.5686  Val_loss: 3695.4329 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -15.5738  Val_loss: 3969.9697 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -17.6949  Val_loss: 4138.5327 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -19.5206  Val_loss: 4408.0913 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -20.9119  Val_loss: 4632.9937 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -22.2516  Val_loss: 5016.9092 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -24.9654  Val_loss: 5207.1152 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -26.1851  Val_loss: 5415.0557 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -28.2492  Val_loss: 5466.1685 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -30.8250  Val_loss: 6056.1035 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -33.2012  Val_loss: 6403.8442 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -34.6122  Val_loss: 6809.7021 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -36.4492  Val_loss: 7694.1450 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -38.9754  Val_loss: 8243.8477 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -41.9038  Val_loss: 9246.2070 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -43.0514  Val_loss: 10223.1396 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -44.4928  Val_loss: 10987.5742 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -47.0802  Val_loss: 12739.8184 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -50.1922  Val_loss: 13878.5830 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -50.9906  Val_loss: 16181.2500 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -54.0940  Val_loss: 17834.5977 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -57.0397  Val_loss: 18974.3145 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -59.0193  Val_loss: 19410.4883 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -60.7046  Val_loss: 22712.8809 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -62.9129  Val_loss: 23485.5254 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -67.5486  Val_loss: 24718.8457 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -68.3730  Val_loss: 26338.7871 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -70.7858  Val_loss: 27119.4062 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -74.1019  Val_loss: 25933.1738 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -73.9912  Val_loss: 24846.7344 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -77.7625  Val_loss: 23189.0371 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -80.7715  Val_loss: 19389.9551 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -82.1491  Val_loss: 17553.1309 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -83.7745  Val_loss: 13616.9473 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -85.8344  Val_loss: 11481.2227 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -88.0206  Val_loss: 8626.4727 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -89.9574  Val_loss: 7335.8735 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -89.3637  Val_loss: 4585.6504 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -91.8175  Val_loss: 2735.4626 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -91.3985WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.3985  Val_loss: 980.3885 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -93.7668WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.7668  Val_loss: -535.1664 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -92.6882WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.6882  Val_loss: -1360.7318 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -94.5579WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.5579  Val_loss: -2178.2837 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -95.5611  Val_loss: -2094.7078 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -92.9659WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.9659  Val_loss: -3657.6653 \n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -94.8426  Val_loss: -3536.2341 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -94.9912WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.9912  Val_loss: -3979.0486 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -95.1303  Val_loss: -3948.6387 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.0868  Val_loss: -3861.1941 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -97.0825  Val_loss: -3867.6260 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -95.6908WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.6908  Val_loss: -4251.8799 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.3431  Val_loss: -3859.9792 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.3214  Val_loss: -3322.5798 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -98.0909  Val_loss: -3505.2539 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.1524  Val_loss: -2981.7439 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -95.9182  Val_loss: -3177.2437 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.9145  Val_loss: -2088.2742 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.7524  Val_loss: -2069.4197 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.7394  Val_loss: -1990.1329 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.3712  Val_loss: -1369.4742 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -96.7974  Val_loss: -1660.3917 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.3456  Val_loss: -1858.1375 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.3754  Val_loss: -1275.0646 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.1814  Val_loss: -1314.5402 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.8080  Val_loss: -1056.0399 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.6349  Val_loss: -996.1068 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.5923  Val_loss: -1076.6111 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.8953  Val_loss: -538.7214 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -99.3786  Val_loss: -1518.6089 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -99.2320  Val_loss: -1202.8582 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.9397  Val_loss: -1438.6224 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.6638  Val_loss: -1566.4058 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.6917  Val_loss: -1177.7747 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -99.4799  Val_loss: -381.0809 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.2158  Val_loss: 500.0168 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.5154  Val_loss: -469.6424 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.8565  Val_loss: -794.9802 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -99.0568  Val_loss: -770.0968 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.3319  Val_loss: -1329.7360 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -100.4161  Val_loss: -1392.8474 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.8826  Val_loss: -1423.8716 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.7834  Val_loss: -1010.7823 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.3469  Val_loss: -1204.2255 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.8434  Val_loss: -1759.6758 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -100.8425  Val_loss: -1239.8140 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -100.5974  Val_loss: -1112.7473 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.5470  Val_loss: -1270.2827 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.5436  Val_loss: -368.3481 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.6975  Val_loss: 387.6969 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -99.5155  Val_loss: 875.7524 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.2588  Val_loss: 1354.8685 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -101.3614  Val_loss: 758.5250 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.9856  Val_loss: 407.5083 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.1017  Val_loss: -252.2293 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -101.3511  Val_loss: 321.0360 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -99.9873  Val_loss: 301.4901 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.5001  Val_loss: 419.6975 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.7100  Val_loss: 379.7610 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.5429  Val_loss: 587.6659 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.1316  Val_loss: 1229.7124 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -101.8362  Val_loss: 104.5772 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -100.6552  Val_loss: 1586.4836 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -101.0653  Val_loss: 1246.1823 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.6335  Val_loss: 1372.4225 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -101.3338  Val_loss: 338.5583 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.0748  Val_loss: 1473.9354 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.5108  Val_loss: 1168.0240 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.5224  Val_loss: 1178.2573 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.4512  Val_loss: 909.6622 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.8808  Val_loss: 748.4844 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -102.2890  Val_loss: 1204.6422 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.2492  Val_loss: 1387.2479 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.3168  Val_loss: 1639.4249 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -100.8608  Val_loss: 2329.1440 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.4959  Val_loss: 987.3944 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -100.5342  Val_loss: 880.6368 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.8145  Val_loss: 921.9879 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.0557  Val_loss: 1787.3479 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -102.9571  Val_loss: 1645.6244 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -102.3468  Val_loss: 3441.1069 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.1334  Val_loss: 3801.6516 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.8686  Val_loss: 3039.9011 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.9931  Val_loss: 3176.0503 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -101.3792  Val_loss: 3196.3845 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -102.6574  Val_loss: 3339.4924 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -100.6531  Val_loss: 3748.0701 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -100.8223  Val_loss: 3035.0725 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -100.8419  Val_loss: 3134.9980 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.7207  Val_loss: 1544.6564 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -100.5956  Val_loss: 1735.6394 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.3656  Val_loss: 1680.9445 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.2942  Val_loss: 3076.2200 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.6764  Val_loss: 3393.7471 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.7097  Val_loss: 3967.9006 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.3414  Val_loss: 4149.5942 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -100.4159  Val_loss: 4374.6484 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.5434  Val_loss: 4702.8740 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -100.9516  Val_loss: 3735.7949 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -101.5291  Val_loss: 3270.1421 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.1582  Val_loss: 4222.3066 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -100.9881  Val_loss: 5211.3379 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.4780  Val_loss: 5985.9263 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.4140  Val_loss: 5376.4038 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -102.2676  Val_loss: 3713.4419 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -101.4269  Val_loss: 3778.8596 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -100.7163  Val_loss: 4429.8501 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.1477  Val_loss: 5383.7319 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.3864  Val_loss: 5930.5396 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -100.5564  Val_loss: 5084.4092 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.1617  Val_loss: 5837.7065 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.1616  Val_loss: 4253.2617 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -101.3920  Val_loss: 4498.7480 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.0894  Val_loss: 5721.1812 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -101.8584  Val_loss: 6864.6016 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.2529  Val_loss: 7795.1445 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -103.0659  Val_loss: 6941.6274 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -103.0774  Val_loss: 5132.5449 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.1440  Val_loss: 5791.7021 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -100.4167  Val_loss: 7061.9551 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -101.2742  Val_loss: 5665.8047 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.8403  Val_loss: 6972.7861 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.2224  Val_loss: 6623.1191 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -101.8359  Val_loss: 6306.1187 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.6808  Val_loss: 7179.9194 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -100.6445  Val_loss: 7053.0244 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -101.8076  Val_loss: 9239.7168 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.4324  Val_loss: 9622.7969 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.7801  Val_loss: 9664.8779 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -102.9165  Val_loss: 9288.0850 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.3832  Val_loss: 8670.0400 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -102.7902  Val_loss: 8990.1475 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -101.9029  Val_loss: 10190.2715 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -103.1614  Val_loss: 12041.1279 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.0244  Val_loss: 11232.4150 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.4971  Val_loss: 10336.0654 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.8970  Val_loss: 10196.4453 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -101.0165  Val_loss: 10042.4863 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5fElEQVR4nO3dd3ycZ5Xo8d8ZjXqvtqxiSZa7HZfYjtNtnBAnlARScHYhAQKGbGgLy5KQ5cLu3tBJILuXQCAhvUFIARJSHOw0N9lxr7J6771rnvvHvCNrrJEsWZoZaXS+n898NH7mfd85M5LnzNPFGINSSinlYvN3AEoppSYXTQxKKaXcaGJQSinlRhODUkopN5oYlFJKubH7O4DxSkpKMllZWf4OQymlppQ9e/bUGWOSPT025RNDVlYWeXl5/g5DKaWmFBEpHu4xbUpSSinlRhODUkopN5oYlFJKudHEoJRSyo0mBqWUUm40MSillHKjiUEppZQbTQxq1P5+qJLypk5/h6GU8jJNDGpUKps7+fITe/nN1lP+DkUp5WWaGNSovHmkGoADZU3+DUQp5XWaGNSovG4lhqOVrfT0OfwcjVLKmzQxqLNq7uxl+6l6shIj6Ol3cLyq1d8hKaW8SBODOqutx2vocxi+ccU8AA6UN/k3IKWUV2liUGe1t7iRqFA7H1s2i7iIYA6WNfs7JKWUF2liUGdVUNdOTnIkQTZhaVos+zUxKBXQNDGosyqobScnKRKAZelxnKhupbOn389RKaW8RRODGlFXbz8VzZ1kJ0UBsDwjjn6H4WC51hqUClSaGNSIius7MAayk501hhWZcQDsKW70Y1RKKW8adWIQkQwR+YeIHBWRwyLydav8ByJSLiL7rNs1g865S0TyReS4iFw1qPx8ETloPXa/iIhVHioiz1rlO0UkawJfqzoHBbVtAANNSYlRoWQlRrC3RBODUoFqLDWGPuBbxpiFwFrgDhFZZD12nzFmuXV7BcB6bBOwGNgI/FpEgqzjHwA2A3Ot20ar/Dag0RiTC9wH/OTcX5qaCAV17QBkW4kBYGVmPB+UNGKM8VdYSikvGnViMMZUGmP2WvdbgaNA2ginXAs8Y4zpNsYUAvnAGhFJBWKMMduN85PlMeC6Qec8at3/E7DBVZtQ/lFY186MmFAiQ+0DZStmx1PX1kNpgy6op1QgOqc+BquJZwWw0yr6iogcEJGHRSTeKksDSgedVmaVpVn3zyx3O8cY0wc0A4nnEqOaGAW1beRYHc8u52c6f8XanKRUYBpzYhCRKOB54BvGmBaczUJzgOVAJfAL16EeTjcjlI90zpkxbBaRPBHJq62tHdsLUGNSWNc+0PHsMn9mNBEhQewrbfJPUEoprxpTYhCRYJxJ4UljzJ8BjDHVxph+Y4wD+B2wxjq8DMgYdHo6UGGVp3sodztHROxALNBwZhzGmAeNMauMMauSk5PH8hLUGNS1ddPY0TvQ8ewSZBNykiMH+h+UUoFlLKOSBHgIOGqMuXdQeeqgwz4BHLLuvwxsskYaZePsZN5ljKkEWkVkrXXNW4CXBp1zq3X/BuAtoz2cfnPImquwJC12yGPZSVEU1rX5OiSllA/Yz37IgIuBzwAHRWSfVfZd4GYRWY6zyacI+BKAMeawiDwHHME5oukOY4xruuztwCNAOPCqdQNn4nlcRPJx1hQ2ncuLUhPDlRgWzYoZ8lh2YgR/O1BBd18/ofagIY8rpaauUScGY8y7eO4DeGWEc+4B7vFQngcs8VDeBdw42piUdx0qbyE7KZKYsOAhj2UnR+IwUNrQQW5KtB+iU0p5i858VsM6VNHMYg+1BWBgiYzCug5fhqSU8gFNDMqjxvYeyho7PfYvAGQnOjuktZ9BqcCjiUF5dLiiBYAlszwnhtiIYBIiQ7TGoFQA0sSgPDo4MCLJc1MSQFZihNYYlApAmhiUR++fqiMnKZK4iJBhj8lOiqJIawxKBRxNDGqI5s5etp+q58pFM0Y8LjspgqqWLjp6+nwUmVLKFzQxqCG2Hq+hz2H48OKZIx6XGhsOQG1rty/CUkr5iCYGNcTrh6tJjg5lRUbciMfFhDvnN7R0ao1BqUCiiUG56e7rZ+vxGq5cNAObbeQVz2OtxNDc2euL0JRSPqKJQbmpbOqivaeflZnxZz02Jtw5cb6lSxODUoFEE4Ny09jRA0BC5NBlMM7kWipDawxKBRZNDMpNU4fzQ36kYaousQN9DJoYlAokmhiUG1eNIX4UiSEiJIggm2hTklIBRhODctNo1RjiI87elCQixITZtSlJqQCjiUG5ae7owSZ4XGrbk9jwYB2uqlSA0cSg3DR29BIbHnzWoaouMeHB2pSkVIDRxKDcNHb0jKrj2SUmLFibkpQKMJoYlJumjl7iRtG/4OJsStLEoFQg0cSg3DR29IxqRJJLTLidli7tY1AqkGhiUG7GWmPQpiSlAo8mBuWmacw1hmB6+hx09fZ7MSqllC9pYlADevoctPf0Exc+hhqDzn5WKuBoYlADmqxZz3GRYxmVpAvpKRVoRp0YRCRDRP4hIkdF5LCIfN0qTxCRN0TkpPUzftA5d4lIvogcF5GrBpWfLyIHrcfuFxGxykNF5FmrfKeIZE3ga1VnMZZZzy6nl97WDmilAsVYagx9wLeMMQuBtcAdIrIIuBPYYoyZC2yx/o312CZgMbAR+LWIBFnXegDYDMy1bhut8tuARmNMLnAf8JNxvDY1RmNZJ8lFm5KUCjyjTgzGmEpjzF7rfitwFEgDrgUetQ57FLjOun8t8IwxptsYUwjkA2tEJBWIMcZsN8YY4LEzznFd60/ABldtQnnfQFPSGEclgTYlKRVIzqmPwWriWQHsBGYYYyrBmTyAFOuwNKB00GllVlmadf/McrdzjDF9QDOQ6OH5N4tInojk1dbWnstLUB6cbkoafY1Bl95WKvCMOTGISBTwPPANY0zLSId6KDMjlI90jnuBMQ8aY1YZY1YlJyefLWQ1Sqf3YhjLqCRn57POZVAqcIwpMYhIMM6k8KQx5s9WcbXVPIT1s8YqLwMyBp2eDlRY5ekeyt3OERE7EAs0jCVGde6aOnoIsdsIDw46+8GWUHsQYcE2nf2sVAAZy6gkAR4Cjhpj7h300MvArdb9W4GXBpVvskYaZePsZN5lNTe1isha65q3nHGO61o3AG9Z/RDKByqau4iPCGas3ToxYcE0d2iNQalAYR/DsRcDnwEOisg+q+y7wI+B50TkNqAEuBHAGHNYRJ4DjuAc0XSHMcY1PfZ24BEgHHjVuoEz8TwuIvk4awqbzu1lqbEqrGvn1YOV3LQ64+wHnyElJpSqli4vRKWU8odRJwZjzLt47gMA2DDMOfcA93gozwOWeCjvwkosyrd+/OpRQu02vnHF3DGfm5kQwbHKVi9EpZTyB535rDhV28Zrh6vZfNkcUqLDxnx+RnwEZY2dOBza6qdUINDEoNhT3AjAR85LPafzMxIi6Ol3UN2qzUlKBQJNDIp9pU1Eh9nJSYo8p/MzEyIAKKnvmMiwlFJ+oolBsb+0iWXpcaPe5/lMA4mhQRODUoFAE8M019nTz7GqVpZnxJ3zNWbFhWMTKG3snLjAlFJ+o4lhmjtc0Uy/w7BsHIkhxG4jNTacUq0xKBUQNDFMc/tKmwBYlhE7rutkJkRoU5JSAUITwzS3v6yZtLjwcxqmOpgmBqUChyaGaS6/po35M6PHfZ2MhHBqW7vp7NG9n5Wa6jQxTGPGGIrq2slKPLdhqoOlxztHJpU3aQe0UlOdJoZprLqlm87efrKTx58Y4q19onX5baWmPk0M01hBXRsA2RNQY4gOcy67pTu5KTX1aWKYxorqnJ3FE1FjGNjiU2sMSk15mhimscK6NkLtNlJjxjciCU7v5KYb9ig19WlimMYKrY7nc10KYzBXjaFVm5KUmvI0MUxjhXXtZJ/jwnlnCgsOIsRuo6VTawxKTXWaGKapvn4HJQ0dZE1QYgCICbNr57NSAUATwzRV0dRFb78556W2PYkJC9bOZ6UCgCaGacq1fEWGtWT2RIgOD9bOZ6UCgCaGaaqqxbnbWmrs+EckucSE2bXzWakAoIlhmqq2EsOMCRiq6qJNSUoFBk0M01RVcxcxYXbCQ4Im7Jox4XZtSlIqAIw6MYjIwyJSIyKHBpX9QETKRWSfdbtm0GN3iUi+iBwXkasGlZ8vIgetx+4XEbHKQ0XkWat8p4hkTdBrVB5UtXQxcwKbkUBrDEoFirHUGB4BNnoov88Ys9y6vQIgIouATcBi65xfi4jrq+kDwGZgrnVzXfM2oNEYkwvcB/xkjK9FjUF1S9eENiMBxIQH093noLtPl95WaiobdWIwxrwNNIzy8GuBZ4wx3caYQiAfWCMiqUCMMWa7McYAjwHXDTrnUev+n4ANrtqEmnhVzV3MnODE4FpIr1Wbk5Sa0iaij+ErInLAamqKt8rSgNJBx5RZZWnW/TPL3c4xxvQBzUDiBMSnztDX76CurdsrTUmgC+kpNdWNNzE8AMwBlgOVwC+sck/f9M0I5SOdM4SIbBaRPBHJq62tHVPACuraenCYiR2RBLqQnlKBYlyJwRhTbYzpN8Y4gN8Ba6yHyoCMQYemAxVWebqHcrdzRMQOxDJM05Ux5kFjzCpjzKrk5OTxvIRpyTWHYaKbkrTGoFRgGFdisPoMXD4BuEYsvQxsskYaZePsZN5ljKkEWkVkrdV/cAvw0qBzbrXu3wC8ZfVDqAlW1WwlholuSgq3EoNOclNqSrOP9kAReRpYBySJSBnwfWCdiCzH2eRTBHwJwBhzWESeA44AfcAdxhjXUJXbcY5wCgdetW4ADwGPi0g+zprCpnG8LjUCb0xuA+18VipQjDoxGGNu9lD80AjH3wPc46E8D1jiobwLuHG08ahzV9XSRXCQkGjt0zxRtClJqcCgM5+noermLlKiwyZkg57BIkKCCLKJNiUpNcVpYpiGyps6mRETOuHXFRHnngy6WY9SU5omhmnG4TAcqWhhYWqMV64fHRasNQalpjhNDNNMQV07rd19LMuI88r14yKCaWjv8cq1lVK+oYlhmtlX2gTACi8lhpkxYQPDYZVSU5Mmhmlmf2kTUaF2cpKjvHL9WXHhVGpiUGpK08QwzewrbeK89FiCJnhEksusuDDauvu0n0GpKUwTwzTS1dvP0coWr/UvAKTGhgNQ2aS1BqWmKk0M08iRyhb6HIblXkwMs+Kcs6krmju99hxKKe/SxDCNnKppA2DBzGivPYfWGJSa+jQxTCPF9R0E2YRZceFee46U6FBsAhVNWmNQaqrSxDCNFNW3kx4fTnCQ937t9iAbM2LCtClJqSlME8M0UtLQQWZChNefJzU2TJuSlJoA/Q7Ds7tLfL6PuiaGaaSorp2sxEivP09qXDiVWmNQatx2FzXwnecP8ue95T59Xk0M00RTRw8tXX3MTvR+jWFWbBiVzV3oPktKjU9JfQcAW45W+/R5NTFME0XWH9hsH9QYZsWF093n0DWTlBqn0kbn/9t38+vo6vVdc5ImhmmiuL4dwCc1hoEhq7o0hlLjUtLgTAxdvQ7ey6/z2fNqYpgmiq0agy86n5OjnXs91LZ1e/25lApkJQ0drJodT2RIEFuO1fjseUe9taea2orrO5gZE0ZYcJDXnyspyrllaH2bNiUpNR6lDZ1csTCFpKhQ/nGsBmMMIt5Z52wwrTFME4V1bWT6oBkJIDHKWWNoaNcag1LnqqOnj7q2bjISIrhsXjKVzV2cqm33yXNrYpgGmjt6OVDWzIrMOJ88X2RIEKF2m9YYlBqHskbnkO+MhAgunZsEwLsna33y3JoYpoG3jlfT5zBctXimT55PREiMDKFOE4NS58w1VDUjPpyMhAhmJ0bwro86oDUxTAOvHaomJTqU5elxPnvOxKhQ6rUpSalz5hqR5BowcuncJLafqqe33+H15x51YhCRh0WkRkQODSpLEJE3ROSk9TN+0GN3iUi+iBwXkasGlZ8vIgetx+4XqydFREJF5FmrfKeIZE3Qa5zWOnv62XailqsWz8Tmpc15PEmMCtF5DEqNQ2ljB5EhQSREOgdzXJKbTHtPP8/uLvX65NGx1BgeATaeUXYnsMUYMxfYYv0bEVkEbAIWW+f8WkRcw2EeADYDc62b65q3AY3GmFzgPuAnY30xaqj38uvo7O33WTOSS2JkqPYxKDUOpQ0dZCREDIxCumxeEssy4viPFw9xy8O7OFXb5rXnHnViMMa8DTScUXwt8Kh1/1HgukHlzxhjuo0xhUA+sEZEUoEYY8x240x5j51xjutafwI2iC/GZQW47QX1hNptrM6OP/vBEygxKoS6tm5dFkOpc3S0spXclNN7s0eE2Pnz7RfxX9cuZl9pExt/+TZ/zCv1ynOPt49hhjGmEsD6mWKVpwGDIy6zytKs+2eWu51jjOkDmoFET08qIptFJE9E8mprfdNLP1XtLKxnRWYcoXbvz18YLDEyhO4+B+09vl0VUqlAUN/WTXlTJ+elx7qVB9mEWy7M4q1vrePa5WleG2norc5nT9/0zQjlI50ztNCYB40xq4wxq5KTk88xxMDX0tXLkYoWLsj2mF+9yjWXoV5nPyvlkcNh2Hq8ht9sO8X+0ia3xw6WNwOwNC3O47nJ0aH8/MZl5KZ4ZzfG8c58rhaRVGNMpdVM5JqzXQZkDDouHaiwytM9lA8+p0xE7EAsQ5uu1BjkFTXgMHBBToLPnzvRNfu5vccnC/cpNdX87PXjPLD1FODc+fCNb15ObHgwAAfLnIlhSVqMX2Ibb43hZeBW6/6twEuDyjdZI42ycXYy77Kam1pFZK3Vf3DLGee4rnUD8JbRBupx2VnQQHCQsCLDt/0L4GxKAl0WQylPDlc08+DbBXxyZRrPbF5LfXsPP3716MDjB8qbyUmOJDos2C/xjWW46tPAdmC+iJSJyG3Aj4ErReQkcKX1b4wxh4HngCPA34E7jDGuxubbgd/j7JA+BbxqlT8EJIpIPvBNrBFO6tztKGxgWXoc4SG+7V8AbUpSaiQ/ePkw8REhfP+ji1mbk8gXLsnm6V2lHKloAeBQeTNL02LPchXvGXVTkjHm5mEe2jDM8fcA93gozwOWeCjvAm4cbTxqZO3dfRwqb+bLl+f45fkHagw6l0EpN/0Ow96SJjZflkNshLNGcPu6Ofzh/SKe3lXCVzfkUtncNTUSg5pa9hQ30u8wful4BggLDiIq1K5NSUqdoa6tm36HYVZc+EBZXEQI1yyZyYv7yokOc34sr8j0fROwiy6JEaB2FtYTZBPOn+2/P66EyBBdFkOpM1Q0ORfHmxUb5lb+qdWZtHb18eutp7h2+SxW+mjRS0+0xhCgdhY0sCQtlshQ//2KE6NCqG3VxKDUYFXWzoYzz0gMa3MSmDcjin6H4YefWOqTfReGo4khAHX29LO/rInPX5zt1zhykqJ420fLBCs1Vbi2vJ0VG+5WLiI896ULCbUH+WXAyGDalBSAPihppLff+GX+wmCLZsVQ29pNTavu/ayUS2VzJ6F2G3ERQ4eixkWE+D0pgCaGgPTivnLCgm2szvJzYkh1Ts45Wtnq1ziUmkwqm7uYFRfu16ais9HEEGDq2rp5cV8F169M99vkGJdFs5yJwTU2WynlTAwzY8LOfqAfaWIIME/sKKanz8HnL/Fv/wJAbHgw6fHhHKnUxKACxzO7SnhyZ/E5n1/V3EVq7ORODNr5HEAcDsNTO0tYPz+ZOclRZz/BBxalxnC4otnfYSg1IYwx3PvGCXr7HWxanUnQGDe/6ncYqlu6SI2b3IlBawwB5EhlCzWt3Xxs2Sx/hzJg0awYCuva6ejp83coSo3bqdo2alq7aezoHVgBdSzq2rrpcxhmnjEiabLRxBBA3jnp3Cj8ktwkP0dy2qLUGIyBY1XaAa2mvvfy6wfubz1eM8KRnp0eqqo1BuUjb5+oZcHMaFImUceWa8lt12xPpaay90/VkR4fzvKMOLYed5+j0+8w9PQ5PJ5njOFfntzDD//mXEH1zMltk40mhgDR0dNHXnEDl82bXBsXJVn7MtTpDGg1xfU7DNtP1XPxnCTWzU9mf1kTjYMWifzxq0e5/oH3AThe1eq27eaxqlZeOVjFrqIGRCAtbnI3JWnnc4DYUVBPb7/h0rmTpxkJID4iBJvoKqtq6jtS0UJLVx8X5SaSFhfOL988SV5xI1cumgE4m5mOVLbQ3t3Hb7ad4oUPyokOC2bjkpm8fcJZu3juSxfS0+cgLiLEny/lrDQxBABjDL/ZVkBcRLDfJ7WdyWYTEiJDqdN9GdQU90FpIwCrshKICHbOTi6ubwegp8/ByRpnP9rJmraBuTvffeEgK2fH8fbJWubNiGJN9uT6/zkcbUoKAC/vr2BXYQP/ftUCwoL9P53+TElRIdTp8ttqijtQ1kxSVAizYsOIiwgmOsxOSUMHACeqW+ntd244ebCsiVO1bWxcPJP27j6+9vQH7C5s5LK5k6uZdySaGKa4po4e7vnbUc5Lj+VTqzPOfoIfJEVpjUFNfQfKmliaFouIICJkJkQMJIbBs/v/cqCSPofhY8tm8d/XLmFHQQM9/Q4un6+JQfmAMYa7XzxEQ3sPP/zE0jFPtvEVZ41BE4Oautq7+8ivaeO89LiBssyECErqnYnhcEUzkSFBLEmLYVdhAwALU6O5aXUGn1qVMSmbeUeiiWEKe+VgFX87UMm/XjmPJX7cBvBskqJCdSc35Te1rd3k14xvHs3hihYcBpZlnP5/lpkYQVljJ/0Ow+GKFhamxrBwpnN9sIiQoIGh2j++finv/Pv6SdnMOxxNDFOUMYYHtuUzNyWKL18+x9/hjCgxKpSOnn6d/az84u4XDnL9A9vp7Okf9piX9pXzoZ9vpaOnj67efradcJ+jcKCsCYClaXEDZZkJEfT0O6hs7uRoZQuLZ8Uwf2Y0APNnRg/U4EXE7wtajpUmhilqf1kzh8pbuOXC2ZO2Ccnl9FwGrTUo3+ro6WPbiVqaO3t55WClx2McDsOv3jxJQV0720/V89C7hdz68K6BZiJwdjzPig0jOTp0oGx2grNGsOVoDe09/SyeFTuQGFxLzk9VmhimqCd2FBMREsR1K9L8HcpZJUU5/zPV6f7PysfePlFHd5+D8OAgnt5V4vGYrSdqKKhzDjvderyWVw85E8jJQc1PB8qaWJru3lybmRABwG+3nSLIJqxbkMziWbGEBdumzLDU4UxIYhCRIhE5KCL7RCTPKksQkTdE5KT1M37Q8XeJSL6IHBeRqwaVn29dJ19E7pfJvJOFnzy9q4Qr793G83vLuG5F2pSoog4kBp39rHzs9SNVxEUE89UNueQVN3Kiemhfw+/fKSQ1Noz185P5y4EKDpU7RxgV1DqTRXNHL0X1HW4dzwCpcWEE2YSK5i4um5tESnQYCZEh7LhrAx+fRAtZnouJrDGsN8YsN8assv59J7DFGDMX2GL9GxFZBGwCFgMbgV+LiKtX5gFgMzDXum2cwPimtJ4+B3e/cJC7/nyQ6DA7/3rFPO66eoG/wxqVRFdTknZAKx/q7Xew5WgNGxbM4Ibz04GhC9/VtXXz/ql6Nq3OZMPCGTR19AIQardRUNcGMLCK6nln1BiCg2wDS1tcb10fnNtzTvXvtN6c+XwtsM66/yiwFfiOVf6MMaYbKBSRfGCNiBQBMcaY7QAi8hhwHfCqF2OcEhrae7j9iT3sLGzg9nVz+LcPz5/0/QqDuRJDvQ5ZVT60v7SJ5s5erliYQkp0GPERwRTWdbgds6PAuVrqZfOSBvoPFqXGEBkaxKkaZ43hQHkTAOcN6nh2mZ0YQWNHD1csnOG9F+IHE5UYDPC6iBjgt8aYB4EZxphKAGNMpYikWMemATsGnVtmlfVa988sn9YcDsOXH9/D/rImfrVpOdcun3pvSag9iJgwu85lUD61o6AeEbhwTiIAWUmRFFl9CS7bT9UTFWpnaVos9iAbN6/JYG1OIu/n17PlWDUAB0qbmZ0YQWzE0Gbbb181n6aO3ik1FHU0JioxXGyMqbA+/N8QkWMjHOvpq64ZoXzoBUQ242xyIjMzc6yxTinP5pWyq6iBn15/3pRMCi5JUaHU6UJ6yguMMZyqbSM3JdqtfEdBAwtmxgwsWJedGMn2gnq3Y7YX1LM6Kx57kLNV/UefPA9wbr/5bF4PzZ3ODXlWzo7HkzP7HQLFhPQxGGMqrJ81wAvAGqBaRFIBrJ+uxr0yYPDaDelAhVWe7qHc0/M9aIxZZYxZlZw8daaZj9XJ6lZ+9MpR1uYkcOOq9LOfMIklRYVq57Pyit++XcAV977N7qKGgbKePgd5xQ2szTk9Oig7KZLK5q6B+QzVLV0U1LYP1CgGy7G2xt1d2EB5UyfnTeIJpN4w7sQgIpEiEu26D3wYOAS8DNxqHXYr8JJ1/2Vgk4iEikg2zk7mXVazU6uIrLVGI90y6JxpZ39pEzf+djuhwUH85PrzpnxnVnJMKFUtXf4OQwWYPcWN/Oy148DpHQzBOby0q9fB2pzTH/pZSc55B0XWiqiu/oWL5gxdqj4n2Xnsg28XAEM7ngPdRDQlzQBesD647MBTxpi/i8hu4DkRuQ0oAW4EMMYcFpHngCNAH3CHMcY1JfF24BEgHGen87TseD5Z3cotD+8iJtzOk7etJTMxwt8hjVtmQgSvHaqi32GmVMe5mrwOVzTzpcfzmBUXRpg9aOCDHk73L1yQ7V5jACiqa2dhagyvHa4iMTKEhR4mo2UmRGC3CbuKGrh0bhLnD9OUFKjGnRiMMQXAMg/l9cCGYc65B7jHQ3kesGS8MU1lRytbuO2R3YTYbTz1hbVkJEz9pAAwOyGCPoehoqkzYF6T8p+tx2v46tMfEB1q55HPreHZ3aU88l4RXb39hAUHDelfgNM1hoK6dpo6enjzSA3/vDbT4xeV4CAbyzPiCA8J4sHPrBrog5gupterneQe31HMtf/7Hj39hkc+tzqgPkBds0RLGzrOcqRSI/v11nw++4fdpMWF88fbL2JOchRrcxLo6Xewt7jRY/8CQFSoneToUIrq2vnL/gp6+h1cv3L4vrtnNq/lsc+vITwksEYcjYbu4DZJvPhBOd978RDr5yfzi5uWkxA5ubf+GytXc1hxQwcX+TkW5VtbjlZjswnr56d4fLy4vp30+IhRNTFWNXfxi9dPcPWSmdz3qeUDw0RXZyVgE2cTUojdNqR/wSU7MZLDFS0crmhhwcxoFs8afk2j6VZLGGz6vvJJwuEwPLa9iG//aT9rcxL4zWfOD7ikAJAaG05wkAxsbKKmh/yaNm5/ci93Pn8Ah2Po6PM9xY2s+/lWHt9eNKrrPbWzGIcxfPeahW5zB6LDglmaHsfrR6p5/9TQ/gWXnORIjlS2cKSyhc9fnD3lB3V4i9YY/Ki0oYNv/2k/OwoauGxeMv9z8wpC7YFZbQ2yCenxEW4rVqrA1tfv4Ft/3E9vv4Pqlm72lTWxMvN0J26/w/D9lw9hDLywr4LPXpw94vW6+/p5alcJGxakeGxmvfXC2Xzzuf1UNHUO6V9wuWN9Lisy41idlTAwJFUNpTUGP3lpXzlX/fJtDpW38ONPLuXRz60mNnzyL4g3HhmDtkJUge/9U/XsL23i+x9dhN0mvHa4auCxvn4Hv3zzBIfKW1g1O579pU1n7X96emcJdW093HJhlsfHr12extyUKFq6+ob0L7hkJETwqdWZmhTOQmsMPtbb7+BHrxzj4fcKWZ0Vz32fWk56fOB0Mo8kMyGcfSWN/g5D+UhBrXMRuo+cN4stx2r4+6EqZsWG8/6pOk5Ut1FY185HlqZy59ULuPSn/+DPe8tZnhnH+bPjiQp1/2g6WNbMD185xmXzkrkkd+i8A3DWSr/14fl8+Yk9XDrX8zFqdDQx+FBdWzd3PLmXnYUNfPaiLO7+yEKCp1EH1+yESFq6+mju6PW47owKLCUNnUSEBJEUFcJVi2fyHy8e4vsvHyY7KZK0uHC+s3E+Vy2eiYiwLCOO+948ATjXH7pjfa7btb71x30kRYXwy08txzZCJ/XGJTN5/V8vY26K1gjGQxODj+wrbeL2J/bQ0N7DfZ9axidWTO0lLs6Fq124pKGDpRHTaybpdFTS0E5mQgQiwseWzeJAWRNXL0ll3fzkIZ2+37hiLi/vq+DtE7VD9kxo7ujlRHUbd169YFQDM+bNiD7rMWpkmhi8rKG9h3vfOM5TO0uYFRfO87dfxJJptu6Ky+yBIavtQ3bDUoGnuL5jYLZxbHgwP71hyDzYAevnp7B+fgqfeWjnwAY5LsetROHaNlN5nyYGL2nu7OXZ3SX871v5tPf085m1s/nXK+d5HCkxXQyuMajAZoyhpKGDdfPHtsjlnOQo/phXijFmoFYxkBi0JuAzmhgmQL/DUFjXzpHKFg5XNHOkooXdRQ109Tq4dG4S3/voIq3e4px5mhQVokNWA0BPn4PCuvZhv8XXtHbT3ecYmPE+WjnJkbT39FPT2s2MmDAAjle1EB1mJzU2bNxxq9HRxHCOevsdvH+qnpf3VfD6kSpau/oACAmyMW9mFDetyuCmVRnTttloODpkNTD87z/yeWBrPrvvvsJjLdj1O85MjBzTdXOSnJ3Gp2rbBhLDiao2FsyM1sloPqSJYYy6+/p5YkcJD2zNp66th+gwOx9eNJO1OQksnhVLbkoUIfbpM9JorGYnRLC7SIesTmXGGF74oIzefsPRylaP+xkUW7XCc6kxABTUtnPRnCSMMRyrauFjy2aNP3A1apoYRsnhMLy0v5yfv3aC8qZOLslN4pYLZ3P5/OSAna3sDZkJEby8v4KePocm0Cnqg9ImShs6AedqwJ4SQ0l9OzaBtLjwMV17ZkwY4cFBAx3Q1S3dtHT1sUA7nn1KE8NZGGPYdqKWn/z9OEcrW1iSFsOPr1/KpXMDd+c4b8pMjMRhoLypc2DEippaXt5XQYjdRnhwEMeqWtweO1bVwneeP0hnTx+pseFjTv42m5CdFMnJmlYe217EyWrnJDnto/MtTQwj2FPcwM9fO8H2gnoyEyK4/+YVfHRp6ogTbNTIMgeNTNLE4Ht/PVBBqD2IKxfNOKfzy5s6eWlfOVcsTKGls49jVe5zDv68t5z9pU0AXJw7tCYxGjnJkfz1QOXAjmzBQcKCmcOvgqomniYGD/YUN/LLN0/wzsk6kqJC+M+PL+bmNZna9DEBXHMZSurbAa11jUVPn4OefseQ5SLG4kevHKO2rZu/fvUSYsODsduExKhQ/vetkxypbOH+TSuGXW66qrmLf/7dDvochq9+aC7P7ynj8R3FbrvybTtey9qcBD53cTbp8WNrRnJZnZXAm0er+dEnl7I6K4GOnn6dKe9jmhgs5U2dvHmkmuf3lnGgrJnEyBC+e80CPr12NhEh+jZNlOSoUELtNh2ZdA6++dw+DpY3s+Wbl49pr4DjVa3EhgcTHWanvMnZN/DPv99JY3sPK2fH89yXLuTPe8spqGtnVuwxvr1xPsE2m1vN+P38Or72zD46e/p47LYLWJgaw8LUGLqtYau5KVFUNXdxvLqVu65ewFWLZ57z6/zM2tlsWpOhfXd+NG0/8Q6VN7PlaA2HKpo5XN5MRbNzo/oFM6P5Px9dxKY1GZoQvMBmEzITIgZGrajROVLRwl8PVAKw9XgtV4yyKairt5+bfrudi+Ykcvu6OQDcvCaTvx2oYHZiBB+UNFLd0kVBXTsp0aH8/t1Cfv9uIbkpUTz1xQtIiQ6jqK6dW/+wi9mJkTz1xQsG2vsXpDp/HqtqITclirdP1AJw+RgntZ3JZhNCbZoU/GnafvLtLGzgl1tOkJMUyersBJamxbJ+QQpzdDler8vUuQxj9qstJ4gOsxMWHMSTO4tHnRjeOFJNc2cve4obOWF15H7h0mx+9MmlvHWsms8/ksdj1iY5P73hPIrrO2ho7+HBtwv43B9289QX1/KLN05gt9kGEoVLbkoUdpvw5I4SYsKCeXFfOTNiQnWGcgCYtonhplXpbFqdQeQ42mvVuclKiuS9U3U4HEY78kfhcEUzrx2u5usb5mKA/3nrJKUNHaPaE/yPe8oA50zkd07WEhwkzLbOOz/TuWfBEztKEIGVs+NZZ22/uSIzji88mseV926jprWbr6zPdUsKAKH2IL714fncv+Uktzy8C4DPXpSlE9ECwLTtTY0OC9ak4Ce5KVF09ToG2rvVyH715kmiw+x8/pJsNq3OwG4TfvjKUYwZulXmYJXNnbxzspbL5zmbdv5+qIqcpKiB/onYiGDmz4imubOXOclRxISd7uBdNz+F52+/iNjwYJKiQtl8eY7H57h93Rx23LWBRz63mq3/to7vf2zRBL1q5U/TNjEo/8m11srPr2nzcyQTp7uvn2888wHHzxi+OV6Hypt5/Ug1t12STWx4MLPiwvnmlfN59VAVL3xQPuT49u4+q9molc2P7cEmwvc+uogQu43uPge5M9ybSldnO7faXJ4RN+RayzLiePXrl7L12+vcksaZYiOCWTc/haykSK0tBIhJ95VZRDYCvwKCgN8bY37s55DUBMtNPp0Y1i9I8XM0E2NnQQMv7qsgMSqU73104r41//btAqLD7Hxu0H7Imy/L4a1j1fzXX49wzdJUTlS38vj2YkLsNl45WEljRy8AESFB/PbT55ObEsXiWTF8UNI0ZAOb1VkJPLGjxGNiALAH2YiaRptJKadJlRhEJAj4f8CVQBmwW0ReNsYc8W9kaiLFR4aQGBkSUDUG14icHQX1E3bNrt5+thyt5hMr0tz2Aw+yCV/90FxueXgXbx2r4fHtxewpbiTEbmNNdgI3nJ9OXVs3F+YkMtfqCF6eEWclBveO4fULUvjkyrRxDS9VgWdSJQZgDZBvjCkAEJFngGsBTQwBZk5KFPm1gZMYXLN0j1S2TNjWpW+fqKWjp5+rl6QOeezi3CRmxITyqzdPcry6lTuvXsCXL58z7LUumpPEo+8XsSTNfQZxTFgw9960fNyxqsAy2eqIaUDpoH+XWWVuRGSziOSJSF5tba3PglMTJzclivyatrN2oE4FroldGxakYAzsKmqYkOv+/XAVseHBXJCTMOSxIJtw3Yo0jle3Emq38alVGSNe64qFKbx/5wZmj3EZbDU9TbbE4KnnasgnhzHmQWPMKmPMquRkXVZhKspNjqK5s5e6th5/hzJu75x0fjn56oa5hNptE9Kc1Nvv4M0j1VyxcAbBw7TxX7/SuW/4x5fNIv4seyGLCDN1oxs1SpOtKakMGPzVJx2o8FMsyosGj0xKjg71czTDa2zvwR4kRI8wKmfbiVqSokJZlh7Lysx43suvc9ua8lzsLmygpauPqxYPP5Ft3oxofvPplazOGlqjUGo8JluNYTcwV0SyRSQE2AS87OeYlBe4llU4XNHs50iG1+8wXP/A+/zbH/cPe0xPn4Ntx2vZsCAFEeGjy1I5VtXKo+8Xjeu538mvw24TLspNGvG4jUtSSYyavIlVTU2TKjEYY/qArwCvAUeB54wxh/0blfKGmbFhzEmOZNuJydtH9PrhKgrq2nkvv56+fofHY3YVNtDa3TewRMU/rclkw4IU7nnlKJ/7wy6+9dx+HI6x96O8c7KWlZnx41pJValzNakSA4Ax5hVjzDxjzBxjzD3+jkd5z4aFM9hRUE9bd5+/QxnQ1t3HOydrOVLRwu/eKcAmzrLDFS0ej3/zaDVhwTYusb7Ziwg/v3EZq7MSKKrv4Pm9ZWw76Z78HA5DYV37sDE0tPdwuKKFS+aOXFtQylsmXWJQ08f6+Sn09hvetYZ6+tsTO4pZ/p+v85mHdnHN/e+wt6SJf1mXC8DOwnqMMW6jqIwxvHGkmktykwkPOb0aaHxkCE99cS2vfeMyUqJD+cN7RW7Pc+8bJ1j/863811+OuNVE9pc2ce8bJ3hmdwnGoIlB+Y3WU5XfrMqKJzrMzlvHqtm4xD8TrIrq2nlqVwlBNuGBrae4fF4yt12STXlTJyeqW7ljfS6vHHLuJrbtRC2dPf08/NnVxEWE8M7JOsqbOvnahlyP1w6x2/j02tnc+8YJDlc0s3hWLMX17Tz4dgHp8eE8/F4hvf0O/vu6Jfz3X4/w0LuFA+dGh9k5Ly3WV2+DUm40MSi/CQ6ycfm8ZN46VuuTlVbbuvu44YH3ueH8dL5wqXNRuJ+9fpy/WfscXJybyG8/cz5hwe57AVyQncjTu0qsmIVND+7g5zcu43svHSI7KZJrlw+ZajPgny7I5DfbTvGR+98lJzmSvn5DcJDw/O0Xcd8bJ3g2r5SPLZvFQ+8W8smVafzLulx+teUkOUmRY9qMR6mJpIlB+dWHFqTw1wOVHKpo5rz0OK8+11/3V3CsqpX/+7ejpMeHszIzntcOVXHbJdl86fIckqNCPQ4xXZuTwNO7SvjsRVlcsXAGtz+xh4/+z7sAPPWFC4YkksGSokL5y1cv4bXDVewraaKiuZN/WTeHGTFhfOHSbJ7ZXcoXHt1NWLCNu69ZSGJUKP9z8wqvvQdKjYYmBuVX6+anIAJbjtZ4PTE8s7uU3JQookLtfO2ZfVyQnUCfw/DptbOH7DUw2DVLnUtSXL0klRC7jW3/vp4HrcXtzjacFGBOctRAX8VguSnRXD4vmW0narnlwtk67FRNGlpXVX6VEBnCiow43jpW49XnOVbVwr7SJm5ek8nDn13Niow43jlZx2XzkslOGnmZiOAgG9cuTyPEbhuI+c6rF3DHes99C2PxlQ/lMjsxgi9e6nm/A6X8QWsMyu82LJzBz147zpaj1YQHB43qW/ho5Ne08pf9lVQ1d/HW8RpCgmx8YkUaCZEhPPGFC3h8e/G49ycer9VZCWz79nq/xqDUmTQxKL/70IIUfvbacW57NA+7TTj0n1eN2G4/Wj9+9RhvHq0hLiKYtdmJfObC2SRYawoFB9n4/CXZZ7mCUtOTJgbldwtmRvPdaxZwqqadZ/NKKaxrZ2FqzNlPHIExhr0lTdx4fjo/u3HZBEWq1PSgfQzK70SEzZfN4ZaLZgNwagL2aSiq76ChvYeVs+PHfS2lphtNDGrSyElyrrhaUDv8chGjtbe4EYCVmZoYlBorTQxq0ggPCSItLnxCagx7SxqJDrUP2eNYKXV22segJpU5KVHjSgwPvVvIscoW9pY0sjwzzuuzqZUKRJoY1KQyJzmSvKKGc9ropr6tm5+9doyuXufCdB85b5Y3QlQq4GliUJNKTnIUHT39VLV0kRobPqpzXvigjLrWHpo7e+nqdfDDTyzlT3tK+Yg1Y1kpNTaaGNSkMifZOQt5V2EDsxMjWZ4RN+LxTR093P3CITp6+gG4YuEM/umCTP7pgkxvh6pUwNLOZzWp5CY7O4u//sw+rvt/77G/tGnE45/cWUJHTz9f+1AuWYkRfH3DXB9EqVRg08SgJpXk6FAun5fMtctnkRQVwg9fOTqwQc6h8mb+cbyG41WtAHT39fPI+0VcOjeJb354Plu/vZ6l6bqHgVLjpU1JalIRER79/BoAHt9exPdeOswXHs2jsK6dgkHbYf7ullUU17dT29rNvTfpzGalJpImBjVpbVqTycv7KzhR00p2UhRfujyH3JRo7n7hIP/x4kFau/r40IKUgf2WlVITQxODmrSCg2z88csXDSn/4SeXcv0D7xNqt/GfH1885mGtSqmRaWJQU87KzHh+8snziIsIJiMhwt/hKBVwxtX5LCI/EJFyEdln3a4Z9NhdIpIvIsdF5KpB5eeLyEHrsfvF+ronIqEi8qxVvlNEssYTmwpsN63O4MOLZ/o7DKUC0kSMSrrPGLPcur0CICKLgE3AYmAj8GsRcS2w/wCwGZhr3TZa5bcBjcaYXOA+4CcTEJtSSqkx8tZw1WuBZ4wx3caYQiAfWCMiqUCMMWa7McYAjwHXDTrnUev+n4ANoo3HSinlcxORGL4iIgdE5GERca1xnAaUDjqmzCpLs+6fWe52jjGmD2gGEicgPqWUUmNw1sQgIm+KyCEPt2txNgvNAZYDlcAvXKd5uJQZoXykczzFtFlE8kQkr7a29mwvQSml1BicdVSSMeaK0VxIRH4H/NX6ZxmQMejhdKDCKk/3UD74nDIRsQOxQMMwMT0IPAiwatUqj8lDKaXUuRnvqKTBy1d+Ajhk3X8Z2GSNNMrG2cm8yxhTCbSKyFqr/+AW4KVB59xq3b8BeMvqh1BKKeVD453H8FMRWY6zyacI+BKAMeawiDwHHAH6gDuMMf3WObcDjwDhwKvWDeAh4HERycdZU9g0ztiUUkqdA5nqX8pXrVpl8vLy/B2GUkpNKSKyxxizyuNjUz0xiEgtUHyOpycBdRMYzkSarLFpXGOjcY3dZI0t0OKabYxJ9vTAlE8M4yEiecNlTH+brLFpXGOjcY3dZI1tOsWl+zEopZRyo4lBKaWUm+meGB70dwAjmKyxaVxjo3GN3WSNbdrENa37GJRSSg013WsMSimlzqCJQSmllJtpmxhEZKO1iVC+iNzpxzgyROQfInJURA6LyNet8mE3QfJhbEXWpkr7RCTPKksQkTdE5KT1M/5s15ngmOYPek/2iUiLiHzDX++XtapwjYgcGlQ27Hs03AZWPorrZyJyzFoN+QURibPKs0Skc9B79xsfxzXmDb98GNuzg+IqEpF9VrlP3rMRPh+8+zdmjJl2NyAIOAXkACHAfmCRn2JJBVZa96OBE8Ai4AfAv/n5fSoCks4o+ylwp3X/TuAnfv49VgGz/fV+AZcBK4FDZ3uPrN/rfiAUyLb+BoN8GNeHAbt1/yeD4soafJwf3i+Pvztfvl/DxXbG478A/o8v37MRPh+8+jc2XWsMa4B8Y0yBMaYHeAbnRkE+Z4ypNMbste63Akc5vUfFZDR4Q6VHOb3Rkj9sAE4ZY8515vu4GWPeZugqwMO9Rx43sPJVXMaY141zrxOAHbivdOwTw7xfw/HZ+3W22KxFP28CnvbW8w8T03CfD179G5uuiWG4jYT8Spz7XK8AdlpFnjZB8iUDvC4ie0Rks1U2wzhXycX6meKHuFw24f4f1d/vl8tw79Fk+rv7PKcXsATIFpEPRGSbiFzqh3jGsuGXP1wKVBtjTg4q8+l7dsbng1f/xqZrYhj1pkC+IiJRwPPAN4wxLQy/CZIvXWyMWQlcDdwhIpf5IQaPRCQE+DjwR6toMrxfZzMp/u5E5G6cqx4/aRVVApnGmBXAN4GnRCTGhyGNdcMvf7gZ9y8hPn3PPHw+DHuoh7Ixv2fTNTEMt5GQX4hIMM5f+pPGmD8DGGOqjTH9xhgH8Du8WIUejjGmwvpZA7xgxVAt1j4c1s8aX8dluRrYa4yptmL0+/s1yHDvkd//7kTkVuCjwD8bq1Haanaot+7vwdkuPc9XMY3wu/P7+wUgzo3DPgk86yrz5Xvm6fMBL/+NTdfEsBuYKyLZ1jfPTTg3CvI5q+3yIeCoMebeQeXDbYLkq7giRSTadR9nx+Uh3DdUupXTGy35mts3OH+/X2cY7j3yuIGVr4ISkY3Ad4CPG2M6BpUni0iQdT/HiqvAh3GNacMvX8U1yBXAMWPMwH71vnrPhvt8wNt/Y97uVZ+sN+AanD38p4C7/RjHJTiregeAfdbtGuBx4KBV/jKQ6uO4cnCObtgPHHa9R0AisAU4af1M8MN7FgHUA7GDyvzyfuFMTpVAL85va7eN9B4Bd1t/c8eBq30cVz7O9mfX39lvrGOvt37H+4G9wMd8HNewvztfvV/DxWaVPwJ8+YxjffKejfD54NW/MV0SQymllJvp2pSklFJqGJoYlFJKudHEoJRSyo0mBqWUUm40MSillHKjiUEppZQbTQxKKaXc/H8PRZ4XhfOQMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 21.8412WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 21.8412  Val_loss: 1263.0085 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 18.8858WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 18.8858  Val_loss: 1207.8788 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 17.0393WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 17.0393  Val_loss: 1193.1483 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 14.7292  Val_loss: 1208.3717 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 13.4756  Val_loss: 1248.6844 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 11.7308  Val_loss: 1290.5153 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 10.6908  Val_loss: 1308.2755 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 8.7989  Val_loss: 1294.2377 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 7.8858  Val_loss: 1252.6017 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 6.2307  Val_loss: 1196.7083 \n",
      "Epoch 10/200\n",
      "96/99 [============================>.] - Loss for batch: 5.3532WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 5.3532  Val_loss: 1150.9133 \n",
      "Epoch 11/200\n",
      "96/99 [============================>.] - Loss for batch: 3.9442WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 3.9442  Val_loss: 1134.4034 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 3.0483  Val_loss: 1144.5688 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 2.1891  Val_loss: 1179.6787 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: 1.1609  Val_loss: 1231.0508 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -0.0195  Val_loss: 1312.3499 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -0.7932  Val_loss: 1421.7480 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -2.1272  Val_loss: 1570.7413 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -3.6299  Val_loss: 1772.0604 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -4.8710  Val_loss: 1985.3220 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -5.6544  Val_loss: 2196.9341 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -6.9818  Val_loss: 2472.5625 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -8.8625  Val_loss: 2747.2070 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -10.5763  Val_loss: 2942.3232 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -11.4132  Val_loss: 3141.0310 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -12.6850  Val_loss: 3237.8828 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -13.9639  Val_loss: 3445.8528 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -15.7860  Val_loss: 3703.8557 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -17.2987  Val_loss: 3745.9490 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -19.5574  Val_loss: 3668.3337 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -20.4914  Val_loss: 3527.8127 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -22.4384  Val_loss: 3418.7141 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -24.1491  Val_loss: 3257.0251 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -25.2684  Val_loss: 3280.8469 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -26.1825  Val_loss: 3278.2654 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -30.7179  Val_loss: 3443.8113 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -29.3510  Val_loss: 3615.9814 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -32.7758  Val_loss: 3649.3342 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -34.6050  Val_loss: 3810.1113 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -37.9850  Val_loss: 4386.1201 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -39.6088  Val_loss: 4782.0464 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -41.8891  Val_loss: 4860.0645 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -44.0727  Val_loss: 4758.0078 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -45.8824  Val_loss: 6463.0620 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -47.3569  Val_loss: 8416.5059 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -50.0836  Val_loss: 9676.3662 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -53.3830  Val_loss: 12136.2754 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -55.3634  Val_loss: 14507.3418 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -57.2309  Val_loss: 15889.7939 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -60.4775  Val_loss: 20535.5879 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -61.8863  Val_loss: 23340.3184 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -64.5150  Val_loss: 31807.4199 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -66.1068  Val_loss: 32879.8828 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -70.4680  Val_loss: 35409.8125 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -69.7440  Val_loss: 36416.4883 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -74.2766  Val_loss: 42726.6719 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -77.2239  Val_loss: 39220.6680 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -78.6434  Val_loss: 36102.0234 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -79.4170  Val_loss: 33479.5820 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -82.4447  Val_loss: 30432.3770 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -81.8394  Val_loss: 32387.3555 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -83.9679  Val_loss: 28883.8711 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -87.2642  Val_loss: 32522.3633 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -87.3944  Val_loss: 29198.5723 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -88.7788  Val_loss: 25267.7168 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -91.1225  Val_loss: 24284.6621 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -90.5410  Val_loss: 18540.7168 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -91.4818  Val_loss: 14313.3623 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -92.5840  Val_loss: 13100.8105 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -91.5049  Val_loss: 14434.3242 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -92.1697  Val_loss: 16853.9043 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -93.4975  Val_loss: 18914.7188 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.1932  Val_loss: 16661.1523 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -94.8934  Val_loss: 17112.3984 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.3491  Val_loss: 13088.2490 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.1506  Val_loss: 11773.6006 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.1223  Val_loss: 10186.0352 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.0428  Val_loss: 11868.4580 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.6301  Val_loss: 13895.2705 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.9448  Val_loss: 19544.0215 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.2603  Val_loss: 20658.3730 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.6625  Val_loss: 21205.6230 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.8254  Val_loss: 21693.7441 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.5967  Val_loss: 24995.7480 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -98.5837  Val_loss: 23955.2168 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.8582  Val_loss: 23677.7305 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.5980  Val_loss: 26518.9727 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.2736  Val_loss: 23304.5762 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.0008  Val_loss: 24873.1562 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.9449  Val_loss: 22441.8379 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.5490  Val_loss: 28208.0117 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.2397  Val_loss: 28425.4277 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -99.5687  Val_loss: 26324.5020 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.2421  Val_loss: 27018.0234 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -100.4907  Val_loss: 27197.6914 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.1095  Val_loss: 31618.7812 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -101.1306  Val_loss: 30452.2598 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.7185  Val_loss: 31575.0410 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.9175  Val_loss: 32392.0508 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.3719  Val_loss: 35287.8906 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.8164  Val_loss: 34710.2148 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.2256  Val_loss: 32592.1211 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -100.8689  Val_loss: 34043.9453 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -100.1145  Val_loss: 33852.5938 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.6170  Val_loss: 35727.3594 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -101.0820  Val_loss: 34785.9023 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.6234  Val_loss: 30180.0059 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.8898  Val_loss: 31586.6797 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -100.6264  Val_loss: 31693.1660 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.4226  Val_loss: 32397.2988 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -101.0267  Val_loss: 36450.0625 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.1955  Val_loss: 35603.9609 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.8805  Val_loss: 39522.5117 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -101.0166  Val_loss: 37182.2734 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.4390  Val_loss: 37854.7734 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -99.0563  Val_loss: 31057.6992 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.2203  Val_loss: 31653.6660 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -100.4872  Val_loss: 33961.4453 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -100.9668  Val_loss: 38999.6875 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.4651  Val_loss: 40686.7344 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -100.2990  Val_loss: 41834.2656 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -102.2243  Val_loss: 40883.3281 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.5435  Val_loss: 41286.1875 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -99.4261  Val_loss: 40358.2617 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -100.3204  Val_loss: 38656.0938 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -100.7311  Val_loss: 36938.4375 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.4559  Val_loss: 35237.8086 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -99.9841  Val_loss: 38169.4336 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -101.8406  Val_loss: 35997.1094 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.2448  Val_loss: 37172.0977 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -99.7316  Val_loss: 36420.2734 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.4826  Val_loss: 37145.1953 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.8500  Val_loss: 35799.0859 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.7227  Val_loss: 37807.8711 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -101.7706  Val_loss: 36188.8828 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.7370  Val_loss: 35692.1328 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -101.8393  Val_loss: 33510.8281 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -99.7046  Val_loss: 35555.3555 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -99.8451  Val_loss: 36203.0586 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.7517  Val_loss: 36823.6680 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -101.9939  Val_loss: 34935.6992 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -103.4240  Val_loss: 33552.0586 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -100.7178  Val_loss: 30823.4297 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -100.7801  Val_loss: 33715.4688 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.7945  Val_loss: 36648.1875 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.6223  Val_loss: 40818.1875 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -100.4028  Val_loss: 39675.7539 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -101.4940  Val_loss: 37891.9180 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -102.1037  Val_loss: 35688.7500 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -100.4606  Val_loss: 34703.1914 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -101.5098  Val_loss: 32968.0156 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.6216  Val_loss: 31778.4199 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -99.4615  Val_loss: 28683.4199 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.0182  Val_loss: 30509.7480 \n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -101.9132  Val_loss: 30870.1289 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.9404  Val_loss: 29657.6309 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -102.1841  Val_loss: 30080.4688 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -102.4285  Val_loss: 31161.7695 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -101.2588  Val_loss: 33090.0000 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.8524  Val_loss: 33854.9805 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.2560  Val_loss: 32718.4805 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -101.3299  Val_loss: 34361.5195 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.0743  Val_loss: 31477.6543 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.3376  Val_loss: 30458.0840 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -101.3477  Val_loss: 31355.3008 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.5516  Val_loss: 32640.2754 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -103.0390  Val_loss: 33658.4531 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -100.8033  Val_loss: 31019.2988 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.1232  Val_loss: 34740.5039 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.0916  Val_loss: 35923.3672 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -101.1617  Val_loss: 35145.6484 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -100.9915  Val_loss: 32855.2148 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.8970  Val_loss: 30749.1875 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.6419  Val_loss: 29494.7188 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.2062  Val_loss: 29811.8184 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -100.9198  Val_loss: 27893.6992 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -102.1614  Val_loss: 31030.5664 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.2084  Val_loss: 28525.0684 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -100.8832  Val_loss: 30199.3809 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -101.1312  Val_loss: 29227.2441 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -102.0554  Val_loss: 29824.5859 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -102.4306  Val_loss: 29605.7734 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -101.4540  Val_loss: 28429.0801 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -102.8625  Val_loss: 28137.8281 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.5117  Val_loss: 27554.1113 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -99.9596  Val_loss: 29654.7930 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -103.1487  Val_loss: 29652.0371 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -101.7019  Val_loss: 26943.9121 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.6149  Val_loss: 28707.9453 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.9687  Val_loss: 30047.7402 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -101.9716  Val_loss: 29386.9023 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -101.4045  Val_loss: 29740.6406 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.5835  Val_loss: 31360.4316 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.8914  Val_loss: 35598.1523 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.3237  Val_loss: 33834.1094 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.5436  Val_loss: 32723.1055 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.1148  Val_loss: 33910.1758 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -103.0165  Val_loss: 33687.3594 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -102.4786  Val_loss: 29542.8535 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.1502  Val_loss: 27890.1445 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "6\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 16.1445WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.1445  Val_loss: 1114.9137 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 13.9645WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.9645  Val_loss: 1040.5026 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 12.8914WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.8914  Val_loss: 966.1487 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 11.4935WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.4935  Val_loss: 893.5076 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 9.88685WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.8868  Val_loss: 824.0969 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 8.4862WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.4862  Val_loss: 750.3642 \n",
      "Epoch 6/200\n",
      "96/99 [============================>.] - Loss for batch: 7.1651WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.1651  Val_loss: 668.0682 \n",
      "Epoch 7/200\n",
      "96/99 [============================>.] - Loss for batch: 5.6262WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 5.6262  Val_loss: 577.0523 \n",
      "Epoch 8/200\n",
      "96/99 [============================>.] - Loss for batch: 4.2443WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 4.2443  Val_loss: 476.8074 \n",
      "Epoch 9/200\n",
      "96/99 [============================>.] - Loss for batch: 3.1886WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 3.1886  Val_loss: 362.3847 \n",
      "Epoch 10/200\n",
      "96/99 [============================>.] - Loss for batch: 1.9177WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 1.9177  Val_loss: 244.4463 \n",
      "Epoch 11/200\n",
      "96/99 [============================>.] - Loss for batch: 0.3114WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.3114  Val_loss: 124.8500 \n",
      "Epoch 12/200\n",
      "96/99 [============================>.] - Loss for batch: -1.1083WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -1.1083  Val_loss: 9.4739 \n",
      "Epoch 13/200\n",
      "96/99 [============================>.] - Loss for batch: -1.9583WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -1.9583  Val_loss: -99.6787 \n",
      "Epoch 14/200\n",
      "96/99 [============================>.] - Loss for batch: -3.1691WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.1691  Val_loss: -195.0920 \n",
      "Epoch 15/200\n",
      "96/99 [============================>.] - Loss for batch: -4.5549WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -4.5549  Val_loss: -266.1702 \n",
      "Epoch 16/200\n",
      "96/99 [============================>.] - Loss for batch: -5.8817WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -5.8817  Val_loss: -312.4900 \n",
      "Epoch 17/200\n",
      "96/99 [============================>.] - Loss for batch: -7.4883WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -7.4883  Val_loss: -348.4991 \n",
      "Epoch 18/200\n",
      "96/99 [============================>.] - Loss for batch: -8.6989WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.6989  Val_loss: -433.0491 \n",
      "Epoch 19/200\n",
      "96/99 [============================>.] - Loss for batch: -9.8100WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -9.8100  Val_loss: -466.4328 \n",
      "Epoch 20/200\n",
      "96/99 [============================>.] - Loss for batch: -11.9969WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -11.9969  Val_loss: -516.9496 \n",
      "Epoch 21/200\n",
      "96/99 [============================>.] - Loss for batch: -13.3017WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -13.3017  Val_loss: -537.3113 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -14.6865  Val_loss: -320.8035 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -17.3495  Val_loss: -180.4246 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -18.2023  Val_loss: -155.8895 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -19.8096  Val_loss: -31.6613 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -22.8217  Val_loss: 582.7168 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -23.8458  Val_loss: 1093.4425 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -25.8897  Val_loss: 1442.0156 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -27.4068  Val_loss: 2525.4978 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -29.2243  Val_loss: 3692.5408 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -32.4818  Val_loss: 5110.3862 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -33.2100  Val_loss: 7273.7593 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -36.0627  Val_loss: 8838.2949 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -37.5051  Val_loss: 10713.3721 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -40.4492  Val_loss: 12019.8711 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -41.5960  Val_loss: 13904.0996 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -45.5180  Val_loss: 16069.4365 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -45.8504  Val_loss: 19135.3223 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -47.8803  Val_loss: 24040.9824 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -50.0529  Val_loss: 27617.3262 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -53.2026  Val_loss: 30182.5078 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -55.2073  Val_loss: 36780.5742 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -57.6532  Val_loss: 37764.1250 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -60.0416  Val_loss: 40860.9844 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -62.0751  Val_loss: 43153.8242 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -64.0430  Val_loss: 51595.9375 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -66.2416  Val_loss: 53539.0391 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -69.0082  Val_loss: 53844.4961 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -70.3203  Val_loss: 59571.8906 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -72.2984  Val_loss: 57019.0195 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -75.5607  Val_loss: 56650.2383 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -76.9336  Val_loss: 49768.3945 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -78.7167  Val_loss: 42350.9258 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -79.9732  Val_loss: 39898.4297 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -82.4713  Val_loss: 33121.6133 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -83.7286  Val_loss: 27704.4570 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -86.3614  Val_loss: 22631.8789 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -86.9482  Val_loss: 17720.5312 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -87.5319  Val_loss: 15643.6982 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -90.2634  Val_loss: 12189.8721 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -90.5074  Val_loss: 9347.6719 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -91.1523  Val_loss: 6506.4531 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -92.3493  Val_loss: 6176.4497 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -92.5396  Val_loss: 4731.0298 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -93.6044  Val_loss: 3363.6743 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -96.1504  Val_loss: 3690.2439 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -93.9896  Val_loss: 4109.0664 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -95.1660  Val_loss: 3120.1111 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.0078  Val_loss: 4199.3076 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.5658  Val_loss: 5995.5386 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -94.0505  Val_loss: 6350.6030 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.8777  Val_loss: 4496.2744 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.0764  Val_loss: 6142.8184 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.7256  Val_loss: 6161.4800 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.5793  Val_loss: 5931.3853 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.7084  Val_loss: 7498.7871 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.1607  Val_loss: 7925.5107 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -98.1755  Val_loss: 9949.0605 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.6067  Val_loss: 11552.0742 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.9433  Val_loss: 12753.0088 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.9227  Val_loss: 11950.2500 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.2795  Val_loss: 14151.6562 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.9162  Val_loss: 15746.7529 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -99.2364  Val_loss: 17124.3340 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.9262  Val_loss: 15460.3242 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -100.0020  Val_loss: 14545.3584 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.1353  Val_loss: 16213.0039 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -99.3522  Val_loss: 17186.0586 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.3644  Val_loss: 18560.8184 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.1041  Val_loss: 18399.7090 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.7647  Val_loss: 15763.7754 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -99.8281  Val_loss: 17780.2695 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.4090  Val_loss: 17236.4766 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.2933  Val_loss: 15731.8096 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -100.3712  Val_loss: 15654.3203 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -100.2345  Val_loss: 17910.5879 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.9240  Val_loss: 14343.8047 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.7153  Val_loss: 16107.2334 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -100.3979  Val_loss: 18345.6191 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -100.1410  Val_loss: 18074.1973 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.9868  Val_loss: 17401.8125 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.8509  Val_loss: 16475.2793 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.8850  Val_loss: 15226.9229 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -102.2957  Val_loss: 13949.4639 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -102.3277  Val_loss: 13825.9141 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -101.4228  Val_loss: 13050.7656 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -101.1352  Val_loss: 13035.0273 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -101.6109  Val_loss: 15187.5137 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.7212  Val_loss: 17599.4336 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.3916  Val_loss: 20227.4727 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.0512  Val_loss: 18548.9902 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.8996  Val_loss: 17972.5703 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.4276  Val_loss: 14747.3936 \n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -100.4570  Val_loss: 16295.7334 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.7687  Val_loss: 13451.6729 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.2503  Val_loss: 15422.0615 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -100.9202  Val_loss: 14544.3438 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.7246  Val_loss: 17596.6562 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.2184  Val_loss: 20636.3984 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -100.3080  Val_loss: 21671.7695 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.9984  Val_loss: 19395.5137 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -101.2428  Val_loss: 14707.6084 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.1129  Val_loss: 14472.8916 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.6574  Val_loss: 15110.3779 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -101.8842  Val_loss: 14493.0264 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.1381  Val_loss: 15169.4639 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -101.1596  Val_loss: 13588.6582 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.6786  Val_loss: 15323.3047 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.5913  Val_loss: 17718.6406 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -100.7911  Val_loss: 19433.3633 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.2130  Val_loss: 16919.3867 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.8226  Val_loss: 14381.3545 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -101.6395  Val_loss: 15032.5332 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -101.9397  Val_loss: 16471.5918 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.8475  Val_loss: 19469.4590 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -102.1533  Val_loss: 21316.9941 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.9990  Val_loss: 20843.3105 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.8992  Val_loss: 19790.1211 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.0825  Val_loss: 19891.9277 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -100.3596  Val_loss: 20749.5762 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -100.2545  Val_loss: 19721.2598 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -101.0538  Val_loss: 19110.2402 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -102.4622  Val_loss: 18048.4805 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.0851  Val_loss: 17341.5254 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.2681  Val_loss: 16563.3945 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -101.6882  Val_loss: 17252.7500 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.9584  Val_loss: 17844.2051 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -102.7814  Val_loss: 19864.2090 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -100.7943  Val_loss: 20431.7129 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.7153  Val_loss: 20088.2520 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.5411  Val_loss: 18711.2695 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.0909  Val_loss: 16385.5488 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.3098  Val_loss: 15734.0576 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.3971  Val_loss: 15542.7158 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.8462  Val_loss: 16957.7012 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.8913  Val_loss: 18327.9512 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -100.0755  Val_loss: 20583.8203 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.9914  Val_loss: 18621.7266 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -100.4664  Val_loss: 17707.2637 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.8106  Val_loss: 20846.0078 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -101.0109  Val_loss: 22680.5977 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.9715  Val_loss: 22088.0508 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -103.9565  Val_loss: 21509.6484 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -101.8996  Val_loss: 19171.1406 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -102.5080  Val_loss: 20200.3672 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -102.1770  Val_loss: 21385.6406 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -102.8060  Val_loss: 21685.0684 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.1926  Val_loss: 24021.8379 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -101.2143  Val_loss: 22477.6191 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -103.5641  Val_loss: 22382.5762 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.2309  Val_loss: 20460.4785 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.6096  Val_loss: 20870.2949 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.2007  Val_loss: 22118.0684 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -101.8964  Val_loss: 23354.7070 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.2980  Val_loss: 24918.2227 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -102.3251  Val_loss: 24536.7324 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -103.0203  Val_loss: 22589.1562 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -101.9305  Val_loss: 22162.3008 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.9805  Val_loss: 22166.6270 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.4190  Val_loss: 25409.1582 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -103.1639  Val_loss: 24968.3945 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -102.8002  Val_loss: 24039.6016 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -100.7362  Val_loss: 25519.3594 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.3786  Val_loss: 25434.0723 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.7881  Val_loss: 23723.0273 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.9659  Val_loss: 24356.3125 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -103.2009  Val_loss: 25554.1953 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.5522  Val_loss: 25658.9238 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -103.3023  Val_loss: 23432.0488 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.5901  Val_loss: 23394.8613 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -102.4748  Val_loss: 24569.7832 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.1846  Val_loss: 24543.7812 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -102.4567  Val_loss: 26065.6699 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -101.5948  Val_loss: 27533.9297 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.4058  Val_loss: 29809.6973 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -103.7638  Val_loss: 28861.9980 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.4580  Val_loss: 28811.1582 \n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -102.5065  Val_loss: 28014.9453 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -104.0942  Val_loss: 26561.1953 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "7\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 13.2387WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.2387  Val_loss: 1279.2102 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 12.1365  Val_loss: 1306.4553 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 11.1427  Val_loss: 1359.5743 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 9.4732  Val_loss: 1418.3765 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 8.4138  Val_loss: 1491.1045 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 7.2098  Val_loss: 1581.0188 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 5.8415  Val_loss: 1725.1704 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 5.0445  Val_loss: 1930.2405 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 4.6480  Val_loss: 2198.9016 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 2.5039  Val_loss: 2482.6658 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 2.0799  Val_loss: 2784.0815 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 1.0346  Val_loss: 3137.4668 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -0.5634  Val_loss: 3545.9436 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -1.7838  Val_loss: 4030.7712 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -2.5786  Val_loss: 4569.7598 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -4.3370  Val_loss: 5100.7070 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -5.3926  Val_loss: 5790.8252 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -6.6779  Val_loss: 6659.0146 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -7.3160  Val_loss: 7586.1138 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -8.8323  Val_loss: 8461.1807 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -10.3629  Val_loss: 9291.9277 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -12.0737  Val_loss: 10238.0205 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -13.5143  Val_loss: 11260.2490 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -14.2946  Val_loss: 12337.6719 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -15.7714  Val_loss: 13073.3760 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -17.2870  Val_loss: 13905.1777 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -19.8639  Val_loss: 15679.1250 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -20.8386  Val_loss: 17075.1699 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -22.9315  Val_loss: 18567.8887 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -25.1095  Val_loss: 18165.6094 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -26.1718  Val_loss: 18522.4902 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -28.0926  Val_loss: 20104.9668 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -30.4963  Val_loss: 21418.4043 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -32.0639  Val_loss: 21745.0547 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -33.3137  Val_loss: 20831.4902 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -36.0603  Val_loss: 19626.0371 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -38.4302  Val_loss: 21004.2695 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -40.1812  Val_loss: 21550.8164 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -42.0017  Val_loss: 24371.6543 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -44.8027  Val_loss: 27054.8633 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -45.7461  Val_loss: 25487.7617 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -48.9371  Val_loss: 28413.4766 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -50.5876  Val_loss: 30336.9746 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -53.4882  Val_loss: 26619.9043 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -54.8914  Val_loss: 26294.4336 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -56.6568  Val_loss: 30503.1562 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -59.3698  Val_loss: 26964.3438 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -62.1511  Val_loss: 27319.9023 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -65.3467  Val_loss: 28377.6719 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -64.6307  Val_loss: 27914.8652 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -69.0731  Val_loss: 23785.2090 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -70.7654  Val_loss: 23829.6387 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -73.5770  Val_loss: 19915.4512 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -74.6095  Val_loss: 16563.5332 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -76.5084  Val_loss: 14292.6514 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -78.6202  Val_loss: 8685.0986 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -79.9564  Val_loss: 5996.6372 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.6535  Val_loss: 3738.6914 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -85.7167WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -85.7167  Val_loss: 1155.3982 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -87.1072WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.1072  Val_loss: -283.1372 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -89.4638WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -89.4638  Val_loss: -3173.2727 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -89.2194WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -89.2194  Val_loss: -3292.8452 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -90.7715WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.7715  Val_loss: -4320.3926 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -92.3822WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.3822  Val_loss: -4909.3516 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -92.5727WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -92.5727  Val_loss: -5630.4146 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -92.6819  Val_loss: -5612.6187 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -93.2952WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.2952  Val_loss: -5816.5449 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -92.9643  Val_loss: -5770.7480 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -93.0404  Val_loss: -5637.3145 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -95.2363  Val_loss: -4480.9712 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -96.3847  Val_loss: -4423.8345 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.9023  Val_loss: -4169.8892 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.0918  Val_loss: -3231.5527 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.8854  Val_loss: -927.3602 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.5317  Val_loss: 234.8644 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -94.9722  Val_loss: -425.0583 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.1311  Val_loss: 1409.6461 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.0617  Val_loss: 3309.0571 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.1581  Val_loss: 3859.4663 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -98.5258  Val_loss: 3839.5063 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.9332  Val_loss: 3847.1289 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.6890  Val_loss: 3088.8545 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.3996  Val_loss: 5382.7578 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -99.0925  Val_loss: 3563.5681 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.5984  Val_loss: 2998.0127 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.2332  Val_loss: 4239.9395 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.8547  Val_loss: 4669.1382 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.4752  Val_loss: 4280.5132 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.0571  Val_loss: 6181.2734 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.1873  Val_loss: 5870.4326 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.5454  Val_loss: 5919.1050 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.6892  Val_loss: 6002.5835 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.9326  Val_loss: 7537.7637 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.4178  Val_loss: 6258.1479 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.8844  Val_loss: 6510.4639 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -100.4021  Val_loss: 6925.3003 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.9641  Val_loss: 4235.5845 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -98.4352  Val_loss: 5708.8013 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.7954  Val_loss: 6699.8472 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -100.7541  Val_loss: 8496.9727 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.6069  Val_loss: 6524.9663 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -99.7967  Val_loss: 6903.5015 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.4704  Val_loss: 7878.0024 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.7851  Val_loss: 9605.6523 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.2620  Val_loss: 11649.4297 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.0940  Val_loss: 10434.4023 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.8167  Val_loss: 8300.0898 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.6905  Val_loss: 9278.6104 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.5641  Val_loss: 9484.6826 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -101.0453  Val_loss: 8327.3691 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.9155  Val_loss: 7558.0366 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.6892  Val_loss: 6674.2148 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.6220  Val_loss: 5765.3413 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.4971  Val_loss: 6277.8794 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -101.0353  Val_loss: 5738.4053 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -99.3986  Val_loss: 6575.5044 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -99.4387  Val_loss: 7141.2998 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -102.2911  Val_loss: 6425.8755 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -99.1552  Val_loss: 6655.5845 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.1189  Val_loss: 7605.4985 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -100.5477  Val_loss: 6417.3579 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.8565  Val_loss: 6983.8105 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.2139  Val_loss: 8173.9805 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.1085  Val_loss: 9539.8369 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -99.0907  Val_loss: 10923.2207 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -99.9160  Val_loss: 11294.2881 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.6582  Val_loss: 9731.0957 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -99.9126  Val_loss: 9621.1836 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.8812  Val_loss: 9204.7041 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.8100  Val_loss: 8216.5674 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -100.5699  Val_loss: 8000.9443 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.8610  Val_loss: 7407.0620 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.9761  Val_loss: 8406.9541 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.6334  Val_loss: 10305.3262 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.2875  Val_loss: 11221.3398 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.1019  Val_loss: 11206.8193 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -102.1398  Val_loss: 9010.4248 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -100.4002  Val_loss: 10242.7295 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -100.1595  Val_loss: 12681.9443 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.6321  Val_loss: 12252.4727 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -100.2589  Val_loss: 10097.1016 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.7209  Val_loss: 8645.5654 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -100.8463  Val_loss: 9800.9043 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -100.5757  Val_loss: 11429.8740 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -99.8784  Val_loss: 11282.3154 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.5339  Val_loss: 10542.0596 \n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -101.3221  Val_loss: 9902.2617 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.8643  Val_loss: 10596.3633 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.4230  Val_loss: 12126.7861 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.5756  Val_loss: 11110.7852 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -101.4708  Val_loss: 9274.8164 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.7241  Val_loss: 10379.0488 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.4287  Val_loss: 9986.6289 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.2441  Val_loss: 10434.9229 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -102.2862  Val_loss: 11214.9922 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.9291  Val_loss: 8358.3428 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -103.7901  Val_loss: 7320.5991 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -100.3697  Val_loss: 6084.8945 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -100.8519  Val_loss: 7935.8003 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -102.2564  Val_loss: 7191.5415 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.7529  Val_loss: 8793.9971 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -101.5446  Val_loss: 8953.2959 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.2939  Val_loss: 9294.5039 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.3517  Val_loss: 9665.6973 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -100.6199  Val_loss: 10472.8818 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -103.2061  Val_loss: 11024.3076 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.4665  Val_loss: 11719.3525 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -103.0014  Val_loss: 12784.0098 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.4507  Val_loss: 10959.5703 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -100.6073  Val_loss: 12654.4014 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.6756  Val_loss: 11627.7168 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.6634  Val_loss: 12021.3691 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.5836  Val_loss: 11120.1631 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.2293  Val_loss: 9668.4492 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.5630  Val_loss: 8768.4297 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.0369  Val_loss: 10872.6406 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -100.7322  Val_loss: 12033.5391 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.1333  Val_loss: 12549.7148 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.1606  Val_loss: 12383.4688 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.8182  Val_loss: 10861.8789 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -102.3837  Val_loss: 9565.0186 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -103.0766  Val_loss: 11187.0508 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -102.3100  Val_loss: 13400.9863 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.3975  Val_loss: 13781.6309 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.5608  Val_loss: 13658.0400 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.3539  Val_loss: 10788.4424 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -103.3011  Val_loss: 10787.2881 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.4590  Val_loss: 11651.6602 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -103.0562  Val_loss: 12561.3262 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -102.5193  Val_loss: 9938.5068 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.4563  Val_loss: 11531.1123 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -101.7092  Val_loss: 12973.9180 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -101.1377  Val_loss: 13874.2109 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.5950  Val_loss: 14781.2461 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -101.2655  Val_loss: 13075.1777 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.8087  Val_loss: 14546.2402 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.2749  Val_loss: 12909.3965 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.3610  Val_loss: 12440.1943 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -102.7476  Val_loss: 14133.9863 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -100.3533  Val_loss: 14193.9512 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 15.5388WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 15.5388  Val_loss: 996.0533 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 14.1918WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.1918  Val_loss: 928.2961 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 13.2592WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.2592  Val_loss: 871.4932 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 11.8405WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.8405  Val_loss: 825.7783 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 9.4545WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.4545  Val_loss: 789.0574 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 9.2281WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.2281  Val_loss: 768.1470 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 8.0879  Val_loss: 771.8707 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 7.3081  Val_loss: 809.6420 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 6.1842  Val_loss: 890.5615 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 4.6224  Val_loss: 1034.7418 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 3.5090  Val_loss: 1226.1973 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 1.8205  Val_loss: 1463.4673 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 0.9015  Val_loss: 1735.9009 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 0.0640  Val_loss: 2030.3265 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -0.9825  Val_loss: 2327.1519 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -2.0821  Val_loss: 2607.0085 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -2.9178  Val_loss: 2862.9680 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -4.2764  Val_loss: 3086.7014 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -5.5476  Val_loss: 3408.7395 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -6.7349  Val_loss: 3720.1177 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -7.3676  Val_loss: 4022.0217 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -9.5915  Val_loss: 4253.3477 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -9.7494  Val_loss: 4533.4980 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -11.5433  Val_loss: 4903.6113 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -12.8449  Val_loss: 5256.8433 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -14.5912  Val_loss: 5565.2847 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -16.3022  Val_loss: 5852.4375 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -18.0498  Val_loss: 6111.5674 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -18.8747  Val_loss: 6507.8291 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -21.2334  Val_loss: 7406.6768 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -23.0288  Val_loss: 8399.2637 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -25.2169  Val_loss: 9244.2070 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -26.5027  Val_loss: 10458.6416 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -28.3368  Val_loss: 11907.4756 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -30.1856  Val_loss: 13862.8525 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -33.4115  Val_loss: 15579.4639 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -34.5197  Val_loss: 16388.2012 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -36.0105  Val_loss: 16016.5264 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -37.9112  Val_loss: 17395.8613 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -41.3900  Val_loss: 21148.8633 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -43.1975  Val_loss: 21411.3770 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -45.6812  Val_loss: 25456.0664 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -47.7803  Val_loss: 27595.0664 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -50.6045  Val_loss: 28910.3633 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -52.5078  Val_loss: 32068.7734 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -54.8213  Val_loss: 35115.6797 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -58.3346  Val_loss: 36572.1641 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -60.1035  Val_loss: 38496.1445 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -63.4971  Val_loss: 37473.0703 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -64.3354  Val_loss: 37086.0156 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -67.9315  Val_loss: 35546.0195 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -70.0325  Val_loss: 34318.1523 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -71.7719  Val_loss: 32395.8535 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -75.2723  Val_loss: 31038.5781 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -76.7160  Val_loss: 28089.5000 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -80.6011  Val_loss: 25661.6816 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -80.7812  Val_loss: 17883.5918 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.9531  Val_loss: 16441.9629 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -85.3438  Val_loss: 15824.4531 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -86.9644  Val_loss: 13555.7402 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -87.6837  Val_loss: 11562.5703 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -88.3412  Val_loss: 10151.4736 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -90.9745  Val_loss: 8742.7432 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -91.3488  Val_loss: 8348.1934 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -92.7080  Val_loss: 6059.3032 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -91.5107  Val_loss: 5726.9268 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -92.4238  Val_loss: 4251.1416 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -93.3700  Val_loss: 4753.7979 \n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -93.7031  Val_loss: 3853.0171 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.5401  Val_loss: 3900.1067 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -95.4609  Val_loss: 4086.7324 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.4815  Val_loss: 3508.7078 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.8527  Val_loss: 4203.5303 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.3109  Val_loss: 3065.8018 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.9752  Val_loss: 3632.7466 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.1642  Val_loss: 4721.6104 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -95.9050  Val_loss: 3894.4697 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.3616  Val_loss: 5945.8726 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -95.6962  Val_loss: 6039.7363 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.1960  Val_loss: 6424.4653 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.2681  Val_loss: 6254.3774 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -94.6726  Val_loss: 6057.6748 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.7441  Val_loss: 8398.8770 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -96.1963  Val_loss: 8998.3643 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.7650  Val_loss: 9199.6611 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.5978  Val_loss: 10120.3633 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.2091  Val_loss: 9325.3916 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.0500  Val_loss: 9597.7295 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -99.3426  Val_loss: 10080.4014 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.9865  Val_loss: 11508.6240 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.1615  Val_loss: 12153.1768 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -96.9333  Val_loss: 13472.4902 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.5116  Val_loss: 13060.8350 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.4454  Val_loss: 13356.5986 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -96.8630  Val_loss: 12180.8408 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.5006  Val_loss: 14381.2451 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.7444  Val_loss: 16178.7344 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.0027  Val_loss: 14299.3535 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.2674  Val_loss: 16822.3730 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.2573  Val_loss: 17061.9102 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.6736  Val_loss: 15622.6455 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.4302  Val_loss: 15810.3486 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.7476  Val_loss: 15708.2021 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.5053  Val_loss: 15831.0098 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.4295  Val_loss: 13808.3057 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.2878  Val_loss: 15132.9453 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.0381  Val_loss: 16349.2373 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.8494  Val_loss: 16759.7812 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -99.7735  Val_loss: 14574.2793 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.9840  Val_loss: 13898.6865 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -101.2132  Val_loss: 12512.1338 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.5757  Val_loss: 13377.1406 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.7611  Val_loss: 13677.7715 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -101.3807  Val_loss: 14283.7080 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -99.3813  Val_loss: 12804.4883 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.8652  Val_loss: 12387.0996 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -99.1213  Val_loss: 12785.1006 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -99.7500  Val_loss: 12981.7451 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -100.4998  Val_loss: 13725.7275 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -99.2723  Val_loss: 15334.3184 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.0906  Val_loss: 13324.8350 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.6834  Val_loss: 11803.5342 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -101.7838  Val_loss: 14154.3145 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.9211  Val_loss: 16129.6611 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -102.0827  Val_loss: 15543.6523 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -99.7854  Val_loss: 13177.3145 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.9341  Val_loss: 13315.4297 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.4157  Val_loss: 12398.6006 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.7211  Val_loss: 11032.1211 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.5976  Val_loss: 11061.1719 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -100.7315  Val_loss: 11643.7188 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.8807  Val_loss: 10370.4209 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.9960  Val_loss: 10212.1533 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.2818  Val_loss: 8811.6787 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.2775  Val_loss: 10412.5098 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.4678  Val_loss: 11251.8330 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.9885  Val_loss: 12426.9756 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -102.8093  Val_loss: 9864.0156 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -100.6750  Val_loss: 9717.7832 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -100.5250  Val_loss: 10279.7920 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.1038  Val_loss: 10596.9746 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -100.8322  Val_loss: 10912.0996 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -102.0091  Val_loss: 9988.4131 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.4513  Val_loss: 11539.6885 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -100.5563  Val_loss: 12248.3916 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -100.5853  Val_loss: 12816.4473 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.5437  Val_loss: 14248.1641 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -103.1632  Val_loss: 12780.2852 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.5735  Val_loss: 10659.5918 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -102.2272  Val_loss: 10410.8506 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.6480  Val_loss: 9782.9189 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -100.9346  Val_loss: 8470.7275 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -101.1171  Val_loss: 10912.9492 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -100.8668  Val_loss: 11813.4531 \n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -101.3980  Val_loss: 12580.9902 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.5583  Val_loss: 12126.5908 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.4859  Val_loss: 13001.9863 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -100.4643  Val_loss: 14062.0820 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.6168  Val_loss: 16550.5332 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.2224  Val_loss: 17046.5625 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -100.9290  Val_loss: 14457.6592 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -100.9527  Val_loss: 11848.4600 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -100.3722  Val_loss: 13434.7148 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.1667  Val_loss: 12678.4609 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -101.8193  Val_loss: 12300.4648 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.4732  Val_loss: 10704.7314 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -100.5512  Val_loss: 11749.0312 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -101.9495  Val_loss: 10163.2432 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.4632  Val_loss: 10397.2334 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -101.1789  Val_loss: 8571.6260 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -100.5875  Val_loss: 11941.5771 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.6222  Val_loss: 11342.9014 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -103.2836  Val_loss: 10135.6025 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.5176  Val_loss: 8915.2793 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.3439  Val_loss: 10190.0059 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.5005  Val_loss: 9476.7588 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -101.5117  Val_loss: 9575.5713 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -103.4855  Val_loss: 6864.1938 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -103.0230  Val_loss: 6041.8105 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.8067  Val_loss: 7362.7622 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -102.0285  Val_loss: 8732.8721 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -101.5039  Val_loss: 9824.6064 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -103.2173  Val_loss: 9025.3477 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.7070  Val_loss: 8393.3389 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -103.0181  Val_loss: 8565.1592 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.3491  Val_loss: 9166.2588 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.6052  Val_loss: 10884.7168 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.6029  Val_loss: 12089.0420 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.9443  Val_loss: 12316.6494 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -104.6156  Val_loss: 9849.5000 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -102.4703  Val_loss: 8429.7070 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -101.4640  Val_loss: 8262.3428 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -101.8212  Val_loss: 11200.6025 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.7280  Val_loss: 11929.8926 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -101.6307  Val_loss: 12105.1797 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.0440  Val_loss: 12102.5732 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -102.4485  Val_loss: 12118.5830 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.0208  Val_loss: 12040.5703 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.6913  Val_loss: 12338.8184 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.3342  Val_loss: 12735.2861 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "9\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 15.5477WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 15.5477  Val_loss: 979.1281 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 14.5819WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.5819  Val_loss: 886.6677 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 12.9914WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.9914  Val_loss: 812.2580 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 10.7329WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.7329  Val_loss: 754.3768 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 9.4962WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.4962  Val_loss: 718.1462 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 7.9964WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.9964  Val_loss: 705.8596 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 6.4103  Val_loss: 713.4639 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 5.1641  Val_loss: 739.0724 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 3.8389  Val_loss: 781.1129 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 2.7600  Val_loss: 840.7330 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 0.9298  Val_loss: 915.8985 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -0.8697  Val_loss: 999.8341 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.8345  Val_loss: 1094.8748 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -3.2750  Val_loss: 1198.2269 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -3.9238  Val_loss: 1304.0167 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -6.4113  Val_loss: 1421.2062 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -6.9336  Val_loss: 1517.4072 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -8.8531  Val_loss: 1624.8951 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -10.4159  Val_loss: 1724.4740 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -11.4864  Val_loss: 1895.0065 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -13.1503  Val_loss: 2164.5149 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -15.7827  Val_loss: 2520.7195 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -16.0596  Val_loss: 2776.9873 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -17.3411  Val_loss: 2989.5039 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -19.6656  Val_loss: 3370.7163 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -21.1060  Val_loss: 3723.9043 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -23.1850  Val_loss: 3750.9534 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -24.5202  Val_loss: 3522.0181 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -26.5199  Val_loss: 3915.5208 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -28.6519  Val_loss: 4126.1807 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -30.4208  Val_loss: 4367.2866 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -32.6267  Val_loss: 4415.1831 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -34.5228  Val_loss: 5378.5415 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -36.8398  Val_loss: 6151.3550 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -39.4346  Val_loss: 6768.6201 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -41.1364  Val_loss: 6584.2739 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -43.7702  Val_loss: 8121.8081 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -47.1233  Val_loss: 9850.9775 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -49.3754  Val_loss: 10794.8867 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -50.6336  Val_loss: 13213.0898 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -54.9454  Val_loss: 14281.7041 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -57.0946  Val_loss: 16687.7109 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -59.1569  Val_loss: 18891.4590 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -61.0843  Val_loss: 20578.7676 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -62.7900  Val_loss: 21132.4922 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -66.5458  Val_loss: 23794.4395 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -68.3384  Val_loss: 25695.8105 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -70.5124  Val_loss: 24625.9629 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -73.9011  Val_loss: 22714.5156 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -75.5912  Val_loss: 20406.6172 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -77.1637  Val_loss: 20032.4766 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -80.0877  Val_loss: 19178.8496 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -82.4743  Val_loss: 16290.4971 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -83.8845  Val_loss: 13402.8232 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -87.6142  Val_loss: 10994.5029 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -88.0095  Val_loss: 7713.2432 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -89.2015  Val_loss: 5949.8154 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -88.9655  Val_loss: 4397.9824 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -90.6032  Val_loss: 1484.7623 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -92.5520  Val_loss: 1898.1637 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -92.0963  Val_loss: 877.0593 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -93.4934WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.4934  Val_loss: 300.2073 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -93.2228WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.2228  Val_loss: -701.9929 \n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/99 [============================>.] - Loss for batch: -95.3995WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.3995  Val_loss: -1047.5459 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -94.2533  Val_loss: -732.0831 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -93.5308WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.5308  Val_loss: -1439.0370 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -94.0034  Val_loss: -646.9384 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -94.4874  Val_loss: 197.9653 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -95.6475  Val_loss: 1215.4673 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -96.9157  Val_loss: 1744.6620 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -96.3320  Val_loss: 3843.2314 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -96.8947  Val_loss: 4902.9712 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -96.4962  Val_loss: 3796.8560 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.8455  Val_loss: 4646.1523 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -97.1156  Val_loss: 6311.7607 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.7779  Val_loss: 8582.9600 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -97.0331  Val_loss: 8963.6709 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.3412  Val_loss: 9668.9561 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -98.3929  Val_loss: 12004.5332 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.9625  Val_loss: 13870.2881 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -99.7646  Val_loss: 13674.7256 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.8451  Val_loss: 14401.0430 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.9822  Val_loss: 14054.6562 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -99.3796  Val_loss: 17148.5020 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.3140  Val_loss: 19128.8066 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.9581  Val_loss: 19776.2012 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.8305  Val_loss: 19307.2305 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.7090  Val_loss: 22575.9883 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -99.2321  Val_loss: 21381.4746 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.3425  Val_loss: 23156.2148 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.5727  Val_loss: 24197.4844 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -99.1887  Val_loss: 24717.4629 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -100.2028  Val_loss: 23716.2051 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.9097  Val_loss: 25056.8086 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.7353  Val_loss: 25734.4629 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.2027  Val_loss: 29131.6191 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.6534  Val_loss: 30005.6582 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.8783  Val_loss: 30766.4141 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.5514  Val_loss: 30614.3945 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -100.4693  Val_loss: 34021.5156 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -99.4475  Val_loss: 33976.6562 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -99.9375  Val_loss: 33585.3398 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.3764  Val_loss: 37831.8359 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.9951  Val_loss: 38638.9688 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.8865  Val_loss: 37741.8945 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.9813  Val_loss: 41258.4922 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.5815  Val_loss: 40900.9102 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -100.6782  Val_loss: 38154.4922 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.4629  Val_loss: 40198.3906 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.9167  Val_loss: 41574.7227 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.9216  Val_loss: 38592.3047 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.8356  Val_loss: 42093.0195 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -101.4734  Val_loss: 40724.0938 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -101.6140  Val_loss: 37336.5234 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -99.2588  Val_loss: 36799.0352 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.2546  Val_loss: 35590.8516 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.2676  Val_loss: 38064.0039 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -101.0614  Val_loss: 38000.8711 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -99.4234  Val_loss: 37465.6641 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.1610  Val_loss: 35924.9219 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -99.2608  Val_loss: 42431.2539 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -99.9711  Val_loss: 40188.3281 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -99.6699  Val_loss: 41069.6250 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -99.3601  Val_loss: 44999.2812 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.7493  Val_loss: 45150.0117 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -99.9268  Val_loss: 45246.1055 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.1615  Val_loss: 43425.4453 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.3525  Val_loss: 43373.5195 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -101.2133  Val_loss: 45815.3828 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -99.8502  Val_loss: 48177.2383 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -102.1088  Val_loss: 48033.6875 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.0520  Val_loss: 51161.7031 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.9277  Val_loss: 49437.1328 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -99.9365  Val_loss: 48420.9258 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -102.4504  Val_loss: 48965.2617 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.1830  Val_loss: 52204.3750 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.6771  Val_loss: 54688.9023 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.1099  Val_loss: 54640.7109 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -99.9198  Val_loss: 52970.1172 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -100.9011  Val_loss: 52416.0703 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.2253  Val_loss: 50888.5508 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -100.8153  Val_loss: 49934.2188 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -99.7227  Val_loss: 51918.7812 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -100.7353  Val_loss: 54802.8750 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.4208  Val_loss: 48280.2617 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.1921  Val_loss: 48268.6836 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.0590  Val_loss: 52594.0117 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -101.5710  Val_loss: 54913.8320 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -100.6013  Val_loss: 58567.7773 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.1062  Val_loss: 56461.4648 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -100.7716  Val_loss: 58412.1211 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.0098  Val_loss: 59987.4453 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -101.0756  Val_loss: 53243.8086 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.3536  Val_loss: 52182.6211 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.5647  Val_loss: 54846.3242 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.9553  Val_loss: 60497.3047 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.4808  Val_loss: 58625.8633 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.8174  Val_loss: 56536.3242 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.6214  Val_loss: 56007.7930 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.9709  Val_loss: 53657.6016 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.1628  Val_loss: 57453.3672 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -102.3486  Val_loss: 55719.9492 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -101.6372  Val_loss: 54775.4102 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -100.4176  Val_loss: 55024.8945 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.4173  Val_loss: 57102.2969 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -100.1971  Val_loss: 59313.6250 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.9053  Val_loss: 56686.6914 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -102.0310  Val_loss: 55870.5547 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -102.5115  Val_loss: 56472.9766 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -101.4149  Val_loss: 59633.7930 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -103.6166  Val_loss: 55158.7539 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -102.9976  Val_loss: 59597.4375 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -101.2695  Val_loss: 56698.8164 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -101.9582  Val_loss: 54668.9258 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.2794  Val_loss: 55982.8164 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.6138  Val_loss: 56138.0664 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -101.2573  Val_loss: 58140.3281 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.8912  Val_loss: 60149.3555 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.0185  Val_loss: 58029.6211 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -101.8351  Val_loss: 58008.3398 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -100.3028  Val_loss: 56249.0117 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -101.8804  Val_loss: 55453.3672 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -100.5827  Val_loss: 52687.2578 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -103.2425  Val_loss: 45335.4141 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -99.8964  Val_loss: 47790.2578 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -101.7908  Val_loss: 50347.6172 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -100.8622  Val_loss: 54756.7383 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -101.8839  Val_loss: 56426.1602 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -103.3879  Val_loss: 54277.4023 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -102.2480  Val_loss: 55479.9648 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -101.4682  Val_loss: 54863.2109 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -103.0591  Val_loss: 53836.9023 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.7509  Val_loss: 51513.4453 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.2692  Val_loss: 52404.5391 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.8065  Val_loss: 51451.8047 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -101.5103  Val_loss: 52683.6875 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.0394  Val_loss: 52328.9258 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.8316  Val_loss: 50498.1250 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.9942  Val_loss: 47857.8477 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -100.9172  Val_loss: 47453.5859 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "10\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 11.6248WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.6248  Val_loss: 988.2342 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 10.5041WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.5041  Val_loss: 961.6490 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 9.4048WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.4048  Val_loss: 936.9701 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 8.2161WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.2161  Val_loss: 912.2953 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 7.7721WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.7721  Val_loss: 895.2020 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 7.1244WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.1244  Val_loss: 886.9310 \n",
      "Epoch 6/200\n",
      "96/99 [============================>.] - Loss for batch: 6.2748WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 6.2748  Val_loss: 884.3890 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 4.8218  Val_loss: 902.0522 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 4.0448  Val_loss: 951.5645 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 3.0177  Val_loss: 1022.4464 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 2.1434  Val_loss: 1100.4374 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 1.3512  Val_loss: 1189.0859 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -0.3325  Val_loss: 1298.1957 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -0.8607  Val_loss: 1418.4045 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -2.0379  Val_loss: 1586.2233 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -3.1261  Val_loss: 1800.3213 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -4.0045  Val_loss: 2036.5764 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -5.4524  Val_loss: 2324.3330 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -6.5126  Val_loss: 2609.3298 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -7.7558  Val_loss: 2858.9438 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -9.0167  Val_loss: 3090.3552 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -10.7505  Val_loss: 3435.8613 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -12.1493  Val_loss: 3768.2336 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -13.8585  Val_loss: 4018.8215 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -15.1191  Val_loss: 4232.7456 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -16.2150  Val_loss: 4456.1909 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -18.3895  Val_loss: 4733.7808 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -20.0869  Val_loss: 4963.0322 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -21.4149  Val_loss: 5123.4717 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -23.1649  Val_loss: 5103.0181 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -24.9002  Val_loss: 5286.1787 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -27.3835  Val_loss: 5564.3110 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -29.7011  Val_loss: 5560.5664 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -32.0316  Val_loss: 5599.2974 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -33.9955  Val_loss: 5682.9390 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -36.4045  Val_loss: 5454.5586 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -37.8915  Val_loss: 5907.0967 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -40.9739  Val_loss: 6552.3872 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -43.7002  Val_loss: 6934.0815 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -47.1002  Val_loss: 8223.3809 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -48.3484  Val_loss: 9591.2461 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -51.8235  Val_loss: 9591.0527 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -54.4550  Val_loss: 11285.0342 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -56.8749  Val_loss: 15035.7256 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -58.9944  Val_loss: 15146.8877 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -62.3118  Val_loss: 13755.7168 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -64.5363  Val_loss: 14687.0518 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -67.1982  Val_loss: 15294.2246 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -70.7461  Val_loss: 14429.5459 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -73.3697  Val_loss: 10172.5186 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -75.3902  Val_loss: 10440.9854 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -77.9078  Val_loss: 9065.8877 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -80.7395  Val_loss: 6424.6978 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -82.7223  Val_loss: 2885.5542 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -84.2659  Val_loss: 2080.9539 \n",
      "Epoch 55/200\n",
      "96/99 [============================>.] - Loss for batch: -86.5213WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -86.5213  Val_loss: -251.7469 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -87.6734  Val_loss: 593.5321 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -89.5998WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -89.5998  Val_loss: -2038.4380 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -89.9501  Val_loss: -1620.6632 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -91.4456WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -91.4456  Val_loss: -2827.9727 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -92.1193WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.1193  Val_loss: -3339.6272 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -93.2362WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.2362  Val_loss: -3533.7146 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -93.5019WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.5019  Val_loss: -4107.6660 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -94.2461  Val_loss: -3888.9297 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -94.9634WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.9634  Val_loss: -4137.9209 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -93.8458  Val_loss: -2902.6777 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -94.5128  Val_loss: -3152.3105 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -95.5095  Val_loss: -2880.2141 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -95.3208  Val_loss: -2786.7805 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.4747  Val_loss: -2433.2717 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.5505  Val_loss: -1949.2324 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -96.4169  Val_loss: -1844.8400 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -96.6842  Val_loss: 9.2565 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.2436  Val_loss: -350.3580 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.7120  Val_loss: 1410.5625 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.3778  Val_loss: 1432.5096 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.0413  Val_loss: 3775.1289 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.5598  Val_loss: 2575.9988 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -98.3482  Val_loss: 4834.8481 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.2107  Val_loss: 5232.1772 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.8365  Val_loss: 6960.5195 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.6422  Val_loss: 7652.1548 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.3763  Val_loss: 9196.0117 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -99.9061  Val_loss: 9320.3213 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -98.5236  Val_loss: 8759.7217 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.5502  Val_loss: 9395.4561 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.5678  Val_loss: 10124.0293 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.6505  Val_loss: 12354.0508 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.7471  Val_loss: 14150.6982 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.0333  Val_loss: 14273.7314 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.5958  Val_loss: 14237.7842 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.3293  Val_loss: 15473.1895 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.5320  Val_loss: 15416.2422 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.5558  Val_loss: 14766.9111 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.8384  Val_loss: 15605.3779 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.0095  Val_loss: 15919.5078 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -99.4169  Val_loss: 14594.8096 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.4385  Val_loss: 15575.4131 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.1449  Val_loss: 15426.4092 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.3159  Val_loss: 14212.5088 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.3261  Val_loss: 15678.5557 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.4078  Val_loss: 18079.1152 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.6784  Val_loss: 18364.9551 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.0560  Val_loss: 19201.4160 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.7843  Val_loss: 18485.1406 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.0849  Val_loss: 18469.7793 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.7732  Val_loss: 18147.6387 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.7157  Val_loss: 19880.9395 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -99.6501  Val_loss: 20587.8184 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.6061  Val_loss: 20847.4043 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.3916  Val_loss: 18735.0840 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -101.0848  Val_loss: 18169.3633 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.8647  Val_loss: 17042.6875 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -99.6805  Val_loss: 16706.8828 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -99.7512  Val_loss: 16554.7363 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -101.8291  Val_loss: 18134.5996 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -99.6826  Val_loss: 21432.4297 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -98.4679  Val_loss: 22631.5508 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -101.4023  Val_loss: 20632.9355 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.3316  Val_loss: 20734.9668 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -100.6538  Val_loss: 16971.0273 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.4311  Val_loss: 13935.2617 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.8661  Val_loss: 17251.5430 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.9845  Val_loss: 17209.4336 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -98.5713  Val_loss: 21454.2578 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -100.1164  Val_loss: 22880.8125 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.1480  Val_loss: 21785.0977 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -102.4020  Val_loss: 21376.6738 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.3120  Val_loss: 18670.3633 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.2372  Val_loss: 17246.9004 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.0366  Val_loss: 19127.4727 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.5836  Val_loss: 20244.6348 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.6243  Val_loss: 22765.8730 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.9629  Val_loss: 22414.2148 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.9901  Val_loss: 24983.1133 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.7182  Val_loss: 23476.5020 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -100.8878  Val_loss: 21799.8340 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.8030  Val_loss: 20739.9297 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.2881  Val_loss: 21541.7090 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -102.0746  Val_loss: 22493.4473 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -101.8090  Val_loss: 19132.2344 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -100.5397  Val_loss: 18123.4590 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -100.3690  Val_loss: 18375.1230 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -100.5621  Val_loss: 20100.8770 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -102.3187  Val_loss: 20273.6816 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.7617  Val_loss: 22136.5586 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.6202  Val_loss: 21187.5605 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.8905  Val_loss: 18994.1836 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.1901  Val_loss: 21645.5918 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.9525  Val_loss: 24971.8418 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.0301  Val_loss: 25736.5879 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.0548  Val_loss: 23285.7090 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -100.0482  Val_loss: 20899.0605 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.1673  Val_loss: 20076.6641 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -100.7759  Val_loss: 21626.1699 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.0488  Val_loss: 24340.2695 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -102.2006  Val_loss: 28558.9043 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -102.2467  Val_loss: 26311.3809 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -100.9072  Val_loss: 22004.6348 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.3885  Val_loss: 22455.6895 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -104.0598  Val_loss: 22764.2656 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -100.9750  Val_loss: 23027.9199 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.4013  Val_loss: 24456.6992 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -102.6623  Val_loss: 24201.2617 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.6631  Val_loss: 24731.7520 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.1129  Val_loss: 23724.8984 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.5816  Val_loss: 21419.6836 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -103.3572  Val_loss: 22699.0762 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.8595  Val_loss: 24262.8086 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.4856  Val_loss: 25494.5938 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -103.0250  Val_loss: 28390.1641 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.8464  Val_loss: 28234.1953 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -103.7948  Val_loss: 26787.0371 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -100.9104  Val_loss: 27074.4238 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.1914  Val_loss: 26438.4219 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -102.7167  Val_loss: 24378.9512 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -101.9352  Val_loss: 24227.5547 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -103.0197  Val_loss: 22697.0000 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.3007  Val_loss: 26029.6094 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.2139  Val_loss: 28212.1738 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -104.1198  Val_loss: 27964.6797 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -101.9419  Val_loss: 24916.4141 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -103.6523  Val_loss: 24922.2852 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -102.3576  Val_loss: 27284.2695 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.6414  Val_loss: 27694.3418 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -103.1156  Val_loss: 25384.5254 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -103.5651  Val_loss: 23412.1445 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -101.0647  Val_loss: 24146.2422 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.7691  Val_loss: 22383.3691 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.5416  Val_loss: 28015.1191 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.3658  Val_loss: 29389.6699 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -104.4847  Val_loss: 29259.1719 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -101.1814  Val_loss: 26410.1309 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -103.2991  Val_loss: 27881.5801 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.1439  Val_loss: 29144.4766 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -101.9249  Val_loss: 30804.6484 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.8404  Val_loss: 30875.2559 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.3507  Val_loss: 27937.6562 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -102.4626  Val_loss: 29486.4141 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -103.9993  Val_loss: 30566.5449 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "11\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 13.5909WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.5909  Val_loss: 968.4585 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 12.7975WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.7975  Val_loss: 910.0858 \n",
      "Epoch 2/200\n",
      "96/99 [============================>.] - Loss for batch: 11.0612WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.0612  Val_loss: 852.6724 \n",
      "Epoch 3/200\n",
      "96/99 [============================>.] - Loss for batch: 10.7413WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.7413  Val_loss: 799.5847 \n",
      "Epoch 4/200\n",
      "96/99 [============================>.] - Loss for batch: 8.5100WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.5100  Val_loss: 752.3946 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 7.3981WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.3981  Val_loss: 712.7988 \n",
      "Epoch 6/200\n",
      "96/99 [============================>.] - Loss for batch: 5.6397WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 5.6397  Val_loss: 684.2155 \n",
      "Epoch 7/200\n",
      "96/99 [============================>.] - Loss for batch: 4.9072WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 4.9072  Val_loss: 662.1549 \n",
      "Epoch 8/200\n",
      "96/99 [============================>.] - Loss for batch: 3.6523WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 3.6523  Val_loss: 651.0499 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 2.0236  Val_loss: 656.8854 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 0.9349  Val_loss: 683.0475 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -0.4429  Val_loss: 720.5779 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.1525  Val_loss: 767.2220 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -2.2237  Val_loss: 842.5421 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -4.2779  Val_loss: 927.7495 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -5.1192  Val_loss: 1011.9952 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -6.2013  Val_loss: 1135.9150 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -7.8192  Val_loss: 1349.7301 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -8.8629  Val_loss: 1560.1498 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -11.3436  Val_loss: 1823.8215 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -11.8403  Val_loss: 2186.5635 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -12.6638  Val_loss: 2580.8118 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -14.8469  Val_loss: 2950.0403 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -16.6441  Val_loss: 3405.0640 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -18.2646  Val_loss: 3962.7458 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -20.0739  Val_loss: 4692.1646 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -20.7648  Val_loss: 5470.7388 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -23.3829  Val_loss: 6413.8857 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -25.4139  Val_loss: 7614.1641 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -27.4837  Val_loss: 9206.5176 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -29.7385  Val_loss: 10573.0977 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -30.4593  Val_loss: 11725.6953 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -34.0185  Val_loss: 13860.3809 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -35.7464  Val_loss: 16389.0938 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -37.5068  Val_loss: 18432.3711 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -38.6601  Val_loss: 20380.5547 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -41.9590  Val_loss: 20926.2617 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -43.0610  Val_loss: 24774.6016 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -46.1059  Val_loss: 28523.8125 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -47.7480  Val_loss: 29907.3438 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -48.0455  Val_loss: 34127.5195 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -50.9309  Val_loss: 35693.7383 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -54.7365  Val_loss: 35331.0312 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -54.5511  Val_loss: 39976.5938 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -57.2655  Val_loss: 46546.2109 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -59.0136  Val_loss: 44672.8281 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -61.5956  Val_loss: 45149.9766 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -64.1351  Val_loss: 37014.3750 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -65.5195  Val_loss: 32089.4648 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -67.6634  Val_loss: 41015.7656 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -71.4681  Val_loss: 36495.7461 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -72.1114  Val_loss: 36891.4141 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -73.9069  Val_loss: 32955.4609 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -75.4710  Val_loss: 29694.3535 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -78.6631  Val_loss: 25890.1523 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -79.2433  Val_loss: 24356.4824 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -82.0129  Val_loss: 19068.0879 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.7136  Val_loss: 13163.7285 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -85.7028  Val_loss: 11057.6885 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -85.3334  Val_loss: 10428.9004 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -87.2304  Val_loss: 7950.5044 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -90.1489  Val_loss: 4881.5288 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -89.5391  Val_loss: 4307.8872 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -90.5179  Val_loss: 2830.0449 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -90.8792  Val_loss: 1388.7495 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -92.8329  Val_loss: 2077.3337 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -93.3741  Val_loss: 770.7776 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -94.0763WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.0763  Val_loss: 331.9071 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -95.0287  Val_loss: 579.2912 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -94.5546WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.5546  Val_loss: -170.3406 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -95.4113  Val_loss: 623.1909 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -95.6420WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.6420  Val_loss: -257.3891 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.7275  Val_loss: 46.5402 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.8399  Val_loss: 771.5999 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.5258  Val_loss: 2312.6829 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.8891  Val_loss: 3553.3848 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -98.0888  Val_loss: 3437.1990 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.9865  Val_loss: 3742.6506 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.4719  Val_loss: 3791.2737 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -98.4614  Val_loss: 4084.5786 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.6824  Val_loss: 5059.2290 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.1681  Val_loss: 7068.6011 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -99.7268  Val_loss: 6519.7612 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.9809  Val_loss: 10295.0791 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -98.2039  Val_loss: 9618.3184 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -100.4483  Val_loss: 7882.7710 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.9245  Val_loss: 8880.4775 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.5110  Val_loss: 8644.6484 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.8297  Val_loss: 6847.3271 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.7708  Val_loss: 7989.1060 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.7504  Val_loss: 8826.0684 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -99.0329  Val_loss: 8926.5654 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -101.2098  Val_loss: 10099.0234 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.8327  Val_loss: 10793.6299 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.5701  Val_loss: 11448.1631 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.5641  Val_loss: 11032.6611 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -100.9867  Val_loss: 9432.3281 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.4066  Val_loss: 9134.3740 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -99.8458  Val_loss: 9714.7100 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -101.6004  Val_loss: 8889.5332 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -101.6214  Val_loss: 9584.3545 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -101.8695  Val_loss: 8362.0439 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.8681  Val_loss: 6002.1328 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -101.9773  Val_loss: 4853.6387 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.7601  Val_loss: 6718.0732 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -101.5215  Val_loss: 7926.0864 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -100.5873  Val_loss: 8534.7256 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -100.4520  Val_loss: 8419.8076 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -101.2731  Val_loss: 8034.6138 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.5567  Val_loss: 10095.0225 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -100.5086  Val_loss: 9257.9814 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -101.3244  Val_loss: 9044.5977 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.6711  Val_loss: 10010.4453 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -102.2293  Val_loss: 10356.5293 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.2441  Val_loss: 9429.1113 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.6222  Val_loss: 8276.4990 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -101.4922  Val_loss: 7296.4380 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -101.2130  Val_loss: 9211.0332 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -100.1390  Val_loss: 11424.6006 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.5143  Val_loss: 12242.2188 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.2940  Val_loss: 12885.1113 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -101.4812  Val_loss: 12881.4531 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -101.5345  Val_loss: 12605.4209 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -101.4591  Val_loss: 12612.9219 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.8756  Val_loss: 12329.1680 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -101.2981  Val_loss: 10878.7803 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -101.9656  Val_loss: 11941.7334 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -101.2512  Val_loss: 12005.8174 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -102.0357  Val_loss: 12560.3174 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.9767  Val_loss: 13185.1094 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.3259  Val_loss: 12075.7197 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -101.8261  Val_loss: 12372.9355 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.4017  Val_loss: 10509.3994 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.5639  Val_loss: 8851.2314 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -102.2152  Val_loss: 10075.7412 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.5423  Val_loss: 12452.3096 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -101.3479  Val_loss: 14528.6328 \n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -102.5976  Val_loss: 13326.2246 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.7099  Val_loss: 11434.0732 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.8189  Val_loss: 11132.1846 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -101.2986  Val_loss: 11622.5693 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.6286  Val_loss: 10865.9795 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -101.7909  Val_loss: 12494.1084 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -102.6779  Val_loss: 13270.5439 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -102.4162  Val_loss: 11858.1885 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -102.1584  Val_loss: 7858.6763 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.0735  Val_loss: 11042.1475 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.3731  Val_loss: 11895.6514 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.8699  Val_loss: 11309.4541 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.0964  Val_loss: 11955.1094 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.1690  Val_loss: 12825.8008 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.4208  Val_loss: 12481.7324 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -100.9454  Val_loss: 13307.5303 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -102.7221  Val_loss: 13129.6777 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.6944  Val_loss: 12897.8838 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.7066  Val_loss: 12770.6377 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.9940  Val_loss: 10773.4277 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -102.1402  Val_loss: 9471.6016 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.7725  Val_loss: 9432.9688 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -102.2700  Val_loss: 9955.0850 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.3591  Val_loss: 11448.6348 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -102.7141  Val_loss: 14508.3271 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -103.2368  Val_loss: 13496.8564 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -100.8624  Val_loss: 12334.9824 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -103.3392  Val_loss: 9272.6797 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -102.5212  Val_loss: 9070.2422 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -102.6453  Val_loss: 10811.6895 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -100.8090  Val_loss: 10929.8623 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -102.2847  Val_loss: 12906.0225 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.4411  Val_loss: 13621.6494 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.2174  Val_loss: 14670.9395 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -102.9095  Val_loss: 12733.6855 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.6111  Val_loss: 13770.3076 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -103.0853  Val_loss: 12019.6201 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.8415  Val_loss: 12110.3105 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -102.8000  Val_loss: 12115.2139 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -101.8663  Val_loss: 12879.5684 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.5383  Val_loss: 11991.9492 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.2072  Val_loss: 11333.1982 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.7537  Val_loss: 12275.6494 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.9163  Val_loss: 11526.3652 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -103.3986  Val_loss: 10897.6855 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -103.5188  Val_loss: 12586.6152 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -103.0948  Val_loss: 12121.6133 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -104.0935  Val_loss: 13291.0596 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -101.1390  Val_loss: 12588.9580 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.3758  Val_loss: 14278.2500 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -103.3591  Val_loss: 13432.5703 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -102.8889  Val_loss: 12285.8887 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -102.3048  Val_loss: 9605.3203 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.9176  Val_loss: 8107.4629 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -103.5286  Val_loss: 9857.8291 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -103.3274  Val_loss: 12055.0439 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -103.7103  Val_loss: 13464.7529 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.4081  Val_loss: 13735.5518 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.1996  Val_loss: 14306.7236 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -103.3269  Val_loss: 12479.2852 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.4969  Val_loss: 14320.2939 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -103.2252  Val_loss: 10966.1562 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -100.9799  Val_loss: 10433.8174 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "12\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 15.3020WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 15.3020  Val_loss: 562.6075 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 13.6524WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.6524  Val_loss: 519.3614 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 11.8162  Val_loss: 525.4003 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 9.9751  Val_loss: 572.4268 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 7.7668  Val_loss: 628.3113 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 7.2166  Val_loss: 647.7601 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 6.4248  Val_loss: 623.8147 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 5.5760  Val_loss: 576.1851 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 4.8185  Val_loss: 533.0575 \n",
      "Epoch 9/200\n",
      "96/99 [============================>.] - Loss for batch: 3.6621WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 3.6621  Val_loss: 511.9911 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 2.5062  Val_loss: 525.6394 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 1.9889  Val_loss: 575.7786 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 0.6442  Val_loss: 654.9039 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 0.2374  Val_loss: 752.9391 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -0.6830  Val_loss: 868.3680 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -1.5151  Val_loss: 980.2630 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -2.2773  Val_loss: 1088.3141 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -3.3543  Val_loss: 1198.9363 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -4.5121  Val_loss: 1327.3508 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -5.5623  Val_loss: 1478.4050 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -6.5763  Val_loss: 1653.6550 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -7.3566  Val_loss: 1880.4218 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -8.2766  Val_loss: 2161.3247 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -9.8518  Val_loss: 2478.8472 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -10.7450  Val_loss: 2794.7273 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -11.9960  Val_loss: 3119.4731 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -13.4815  Val_loss: 3359.9373 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -14.4631  Val_loss: 3482.5859 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -15.9523  Val_loss: 3638.0671 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -17.6027  Val_loss: 3839.0300 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -18.7277  Val_loss: 3977.3601 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -20.3868  Val_loss: 4114.1982 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -22.0266  Val_loss: 4343.4131 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -23.7865  Val_loss: 4510.1060 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -26.3486  Val_loss: 4585.5771 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -27.9152  Val_loss: 4684.0410 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -30.1229  Val_loss: 4468.9478 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -31.7398  Val_loss: 4762.6616 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -34.4612  Val_loss: 4724.4253 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -36.4953  Val_loss: 5031.1187 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -39.1728  Val_loss: 5436.6440 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -42.4594  Val_loss: 5626.5156 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -44.8256  Val_loss: 6433.6221 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -47.6398  Val_loss: 7709.5444 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -50.0292  Val_loss: 8519.3975 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -52.6292  Val_loss: 9723.2188 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -55.8172  Val_loss: 10442.1367 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -58.0016  Val_loss: 15364.3877 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -60.3571  Val_loss: 14975.4658 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -63.9802  Val_loss: 19468.7734 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -65.5864  Val_loss: 20860.2324 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -68.2422  Val_loss: 21051.5859 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -71.8924  Val_loss: 23501.4941 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -73.6487  Val_loss: 21072.3125 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -75.9053  Val_loss: 16378.5898 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -77.6577  Val_loss: 19155.7656 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -80.1705  Val_loss: 16150.9570 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -82.6934  Val_loss: 12589.8271 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -84.1748  Val_loss: 10970.0645 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -84.9350  Val_loss: 6276.7324 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -88.0008  Val_loss: 4739.3525 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -88.3841  Val_loss: 2666.1338 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -88.7767WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.7767  Val_loss: -886.4608 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -91.0526  Val_loss: -762.4265 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -91.9487WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.9487  Val_loss: -2193.2141 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -92.0421WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.0421  Val_loss: -2300.9692 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -92.9972WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -92.9972  Val_loss: -2474.0107 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -94.0591WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.0591  Val_loss: -3042.2722 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -94.4075WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.4075  Val_loss: -3143.4680 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -92.8422WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.8422  Val_loss: -3495.8169 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.9865  Val_loss: -2849.8547 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -94.8418  Val_loss: -3451.4971 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.5552  Val_loss: -3246.5486 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -97.0248  Val_loss: -3457.3494 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -95.6189WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.6189  Val_loss: -4052.2866 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.8542  Val_loss: -3311.1326 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -97.5726  Val_loss: -3279.8811 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.4755  Val_loss: -2972.2620 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.2185  Val_loss: -3052.8347 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.1429  Val_loss: -2116.3464 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -98.4512  Val_loss: -1415.3206 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.2686  Val_loss: -727.6067 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.5888  Val_loss: -105.3957 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.9167  Val_loss: -1107.5135 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.1610  Val_loss: 388.9249 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.2731  Val_loss: 1398.6466 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.3942  Val_loss: 1213.2333 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.5824  Val_loss: -33.7338 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.1285  Val_loss: 135.8789 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.8119  Val_loss: 505.5632 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.7571  Val_loss: 1319.6061 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.0659  Val_loss: 1883.5330 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.9872  Val_loss: 2051.7532 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.1263  Val_loss: 3334.7930 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.4476  Val_loss: 4776.3921 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.9473  Val_loss: 4240.8613 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.5704  Val_loss: 3765.1550 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.6445  Val_loss: 1925.5028 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.8589  Val_loss: 1822.2822 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.3757  Val_loss: 1476.7991 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -100.1976  Val_loss: 1930.2925 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.0458  Val_loss: 2122.1750 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.7545  Val_loss: 2179.6863 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -99.3392  Val_loss: 2531.2717 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -99.0148  Val_loss: 2106.9280 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.8598  Val_loss: 4760.8438 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -100.3245  Val_loss: 4866.8193 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -102.3226  Val_loss: 5477.6621 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.2821  Val_loss: 5169.4092 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -100.9690  Val_loss: 6712.6255 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.5498  Val_loss: 8450.0000 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -100.0634  Val_loss: 8258.5381 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -101.0891  Val_loss: 7040.9941 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -99.0075  Val_loss: 4082.2529 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -98.2571  Val_loss: 6727.0654 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.5238  Val_loss: 5824.7002 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -100.0222  Val_loss: 6285.1987 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -100.3281  Val_loss: 5871.3516 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -101.5380  Val_loss: 5264.1470 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -102.3298  Val_loss: 1902.3738 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.9385  Val_loss: 2442.3848 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.0177  Val_loss: 3069.2061 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -102.1655  Val_loss: 4476.6963 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.9894  Val_loss: 6819.3569 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.5696  Val_loss: 7097.6899 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -103.6017  Val_loss: 7594.3130 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.5757  Val_loss: 8024.2700 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.8998  Val_loss: 7855.4155 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.0811  Val_loss: 7297.2676 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.7925  Val_loss: 6715.8730 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.1201  Val_loss: 7078.6343 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.9944  Val_loss: 7583.1694 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.7330  Val_loss: 6516.1406 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.8521  Val_loss: 8235.8457 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -101.3796  Val_loss: 9075.9404 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.7122  Val_loss: 8453.9414 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.9722  Val_loss: 7374.1914 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.2625  Val_loss: 5719.2500 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.3750  Val_loss: 7462.5352 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -100.7984  Val_loss: 8466.6719 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -103.3348  Val_loss: 7314.8174 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -100.4134  Val_loss: 7194.4531 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -100.7648  Val_loss: 8181.0962 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -100.7622  Val_loss: 8484.0635 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -102.4656  Val_loss: 9432.8809 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.0509  Val_loss: 9543.4463 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.0987  Val_loss: 9470.3682 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -102.6406  Val_loss: 7612.2354 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.8993  Val_loss: 7577.2993 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -101.4437  Val_loss: 9835.4629 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -101.4887  Val_loss: 10745.1289 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -102.2735  Val_loss: 9329.6201 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.7554  Val_loss: 6922.7432 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.5391  Val_loss: 5657.2461 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.0418  Val_loss: 5532.6372 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.8811  Val_loss: 7836.6953 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -99.8736  Val_loss: 8097.4863 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.7652  Val_loss: 8552.9795 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -101.0356  Val_loss: 8557.8154 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.8474  Val_loss: 8489.4434 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.2851  Val_loss: 5707.7095 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -102.8042  Val_loss: 5011.6948 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -99.7649  Val_loss: 3975.1292 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.2661  Val_loss: 4491.7246 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.0316  Val_loss: 4027.5774 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.6399  Val_loss: 5119.7788 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -102.7086  Val_loss: 8492.0518 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -101.3290  Val_loss: 9190.4834 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -100.3316  Val_loss: 8333.1191 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -103.1898  Val_loss: 5964.4810 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -100.3663  Val_loss: 5622.2280 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -102.2636  Val_loss: 7723.1328 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -101.2977  Val_loss: 7844.6309 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -102.3650  Val_loss: 7321.5532 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -101.8922  Val_loss: 6640.0000 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -102.6215  Val_loss: 7921.5005 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -100.9512  Val_loss: 7148.2192 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.9744  Val_loss: 7691.0103 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -101.3901  Val_loss: 7437.5405 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -101.2604  Val_loss: 7127.2334 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.6860  Val_loss: 5148.6050 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -101.9017  Val_loss: 4358.7070 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -101.0060  Val_loss: 6400.0513 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.5206  Val_loss: 7304.3989 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.7588  Val_loss: 9351.2119 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -102.5203  Val_loss: 8280.3613 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.7246  Val_loss: 8411.8027 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -104.6981  Val_loss: 6779.1709 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -103.5828  Val_loss: 6796.1855 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -101.2131  Val_loss: 6136.6162 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.2100  Val_loss: 7384.2241 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -102.3868  Val_loss: 6083.9331 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -101.4520  Val_loss: 4959.4443 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.1739  Val_loss: 5610.3726 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.1081  Val_loss: 6544.7031 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -101.5697  Val_loss: 7749.7065 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -102.5020  Val_loss: 7349.4888 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -102.5576  Val_loss: 6290.8555 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -102.6822  Val_loss: 4869.7534 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -103.2234  Val_loss: 5262.4097 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "13\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 16.0614WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.0614  Val_loss: 1333.5598 \n",
      "Epoch 1/200\n",
      "96/99 [============================>.] - Loss for batch: 15.1692WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 15.1692  Val_loss: 1325.8940 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 13.4663  Val_loss: 1328.1853 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 11.2541  Val_loss: 1332.0653 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 11.1585  Val_loss: 1331.5060 \n",
      "Epoch 5/200\n",
      "96/99 [============================>.] - Loss for batch: 9.2392WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.2392  Val_loss: 1309.5959 \n",
      "Epoch 6/200\n",
      "96/99 [============================>.] - Loss for batch: 8.8594WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.8594  Val_loss: 1287.7104 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 7.8367  Val_loss: 1288.7458 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 6.3810  Val_loss: 1302.1425 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 5.3504  Val_loss: 1335.6913 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 4.3633  Val_loss: 1391.2972 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 3.2225  Val_loss: 1467.2595 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 2.0537  Val_loss: 1585.8008 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 0.1996  Val_loss: 1724.8859 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -1.5402  Val_loss: 1928.3003 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -3.0924  Val_loss: 2204.5862 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -3.8307  Val_loss: 2558.9680 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -5.2065  Val_loss: 2966.8877 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -6.8935  Val_loss: 3412.0129 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -9.0230  Val_loss: 3873.1238 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -10.2968  Val_loss: 4328.1709 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -11.9108  Val_loss: 4719.2075 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -13.2277  Val_loss: 5042.0156 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -15.1915  Val_loss: 5496.8022 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -16.8812  Val_loss: 6348.4937 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -17.6215  Val_loss: 7226.3042 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -19.9902  Val_loss: 7875.9570 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -21.1578  Val_loss: 8402.8848 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -23.8441  Val_loss: 8551.5537 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -24.5965  Val_loss: 9573.3281 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -26.7505  Val_loss: 11374.1523 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -28.5412  Val_loss: 12608.8887 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -30.7468  Val_loss: 12663.8271 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -31.8316  Val_loss: 13586.8057 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -34.2628  Val_loss: 14627.5273 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -36.5473  Val_loss: 17357.4512 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -37.5680  Val_loss: 15696.9648 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -40.3269  Val_loss: 19580.5039 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -42.4267  Val_loss: 20566.5469 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -44.5510  Val_loss: 19473.0840 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -45.5427  Val_loss: 26530.2168 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -48.1648  Val_loss: 27198.3984 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -51.3841  Val_loss: 28614.8438 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -52.0614  Val_loss: 31567.5059 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -54.8642  Val_loss: 28984.6094 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -56.4838  Val_loss: 29310.3105 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -59.6367  Val_loss: 31612.4199 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -62.4111  Val_loss: 34448.8398 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -63.3768  Val_loss: 34467.1094 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -66.2822  Val_loss: 32296.7754 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -68.7385  Val_loss: 32876.2695 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -71.4683  Val_loss: 36350.4688 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -72.2520  Val_loss: 31450.7383 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -75.9287  Val_loss: 26821.8340 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -77.3218  Val_loss: 33654.8672 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -79.4476  Val_loss: 29624.5586 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -82.1782  Val_loss: 28230.1348 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.8495  Val_loss: 24057.2227 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -86.1104  Val_loss: 19596.7051 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -87.2983  Val_loss: 14811.0654 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -88.8954  Val_loss: 11439.5352 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -89.4665  Val_loss: 9727.7451 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -91.9178  Val_loss: 7985.4390 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -91.3158  Val_loss: 6059.4771 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -93.2596  Val_loss: 5173.5513 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -93.9953  Val_loss: 5195.8291 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -92.7567  Val_loss: 3796.9368 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -96.6129  Val_loss: 3566.7644 \n",
      "Epoch 68/200\n",
      "99/99 [==============================] - trainLoss: -94.5711  Val_loss: 2776.5354 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -94.7601  Val_loss: 2739.9360 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.2764  Val_loss: 1937.4907 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.7863  Val_loss: 2740.3684 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -94.8648  Val_loss: 4053.7104 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -96.0331  Val_loss: 5279.1514 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -94.9791  Val_loss: 6855.2397 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.2933  Val_loss: 9933.8545 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -97.1164  Val_loss: 11753.3545 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.6282  Val_loss: 13033.3447 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.6975  Val_loss: 13636.8535 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.9963  Val_loss: 14395.8115 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.0129  Val_loss: 17022.0273 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.1478  Val_loss: 19533.9121 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.0801  Val_loss: 19060.4043 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.2858  Val_loss: 20049.4707 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.4072  Val_loss: 18328.6016 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.4501  Val_loss: 17553.1348 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.2618  Val_loss: 18325.5449 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.4120  Val_loss: 18193.0703 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.2733  Val_loss: 18077.6719 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.6929  Val_loss: 18971.3613 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.5190  Val_loss: 19092.2168 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -100.4137  Val_loss: 18451.9004 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -100.6027  Val_loss: 17469.1523 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -100.0091  Val_loss: 16762.3203 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.2398  Val_loss: 16906.8750 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -99.0765  Val_loss: 16537.9766 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.3945  Val_loss: 13743.8389 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.6071  Val_loss: 14961.9746 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -100.3091  Val_loss: 13847.2939 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.6333  Val_loss: 13881.7246 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -101.2798  Val_loss: 14262.7041 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -101.3860  Val_loss: 14099.9092 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.8196  Val_loss: 14715.6934 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -100.2224  Val_loss: 13726.2139 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.1444  Val_loss: 15396.9385 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.3480  Val_loss: 16380.2861 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.9672  Val_loss: 16619.6523 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.9539  Val_loss: 17020.2656 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -100.3450  Val_loss: 14579.6465 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.8525  Val_loss: 16337.5469 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -100.4356  Val_loss: 15571.3838 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.6832  Val_loss: 13083.9521 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.1687  Val_loss: 15189.3936 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.0011  Val_loss: 16067.3154 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.8671  Val_loss: 16846.7773 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.4856  Val_loss: 15354.1602 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -101.0812  Val_loss: 15231.1855 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -99.4660  Val_loss: 14744.9395 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -101.3385  Val_loss: 15012.5996 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -101.4786  Val_loss: 16507.3652 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -101.0438  Val_loss: 15987.7803 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -102.6601  Val_loss: 14974.7012 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -102.4919  Val_loss: 14077.4238 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.9283  Val_loss: 13872.6455 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -101.8798  Val_loss: 14268.9062 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -101.3918  Val_loss: 15377.3174 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.0803  Val_loss: 15728.0859 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -99.8884  Val_loss: 13881.3594 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -100.5468  Val_loss: 15162.2168 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -100.5572  Val_loss: 16908.7012 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.5303  Val_loss: 13587.8584 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.9410  Val_loss: 14972.7490 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.1067  Val_loss: 14090.6992 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -101.7316  Val_loss: 15503.6348 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -102.4162  Val_loss: 15531.0938 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -102.7043  Val_loss: 13031.4941 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -100.8692  Val_loss: 12094.7412 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.1351  Val_loss: 14300.7656 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -101.8319  Val_loss: 14366.8564 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -99.6827  Val_loss: 14662.9688 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -101.9520  Val_loss: 16130.8633 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.7361  Val_loss: 18169.9961 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -102.0113  Val_loss: 16913.5156 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -101.2563  Val_loss: 17626.0410 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -101.8807  Val_loss: 18683.1367 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.3982  Val_loss: 15959.2773 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.5230  Val_loss: 14350.7363 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -102.2459  Val_loss: 14593.6309 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -100.5986  Val_loss: 14466.7715 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -102.0832  Val_loss: 15334.5176 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.5409  Val_loss: 14835.2422 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -100.2759  Val_loss: 15748.6328 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.5060  Val_loss: 15030.4531 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -100.8390  Val_loss: 15141.3232 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.9345  Val_loss: 15797.2979 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -101.9031  Val_loss: 15766.1211 \n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -100.7300  Val_loss: 18044.7012 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.2500  Val_loss: 19010.3242 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -102.1813  Val_loss: 17810.1055 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -103.0244  Val_loss: 16723.1133 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -101.7936  Val_loss: 17814.9785 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -102.7465  Val_loss: 16150.6279 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.0567  Val_loss: 14790.4658 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -102.3174  Val_loss: 16435.9609 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.6977  Val_loss: 16484.2285 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -101.4780  Val_loss: 15543.4316 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.6999  Val_loss: 15942.0312 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -100.9740  Val_loss: 16795.6113 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -102.3735  Val_loss: 16197.4492 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -100.9436  Val_loss: 15923.2012 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -102.7628  Val_loss: 16481.5117 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -102.7613  Val_loss: 16334.4941 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -101.3780  Val_loss: 16161.9844 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -100.5786  Val_loss: 18219.8418 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.6270  Val_loss: 17182.0488 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -102.3398  Val_loss: 14599.5488 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -102.6083  Val_loss: 15740.5605 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -102.9563  Val_loss: 18019.2676 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -102.3389  Val_loss: 16957.5020 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -101.8830  Val_loss: 18069.8672 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.0808  Val_loss: 16582.2598 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -103.1389  Val_loss: 16899.0840 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -101.7066  Val_loss: 16794.3379 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -102.2598  Val_loss: 17004.0977 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.0687  Val_loss: 14796.8906 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -103.0528  Val_loss: 15371.5049 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.4193  Val_loss: 19117.5449 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.6612  Val_loss: 19892.1367 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -101.8635  Val_loss: 19118.5586 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -102.4762  Val_loss: 17028.7051 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -103.0699  Val_loss: 15132.5156 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -103.6351  Val_loss: 14627.1953 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -102.7285  Val_loss: 13668.6045 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -101.3090  Val_loss: 15937.8184 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.4951  Val_loss: 15169.9873 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -102.9922  Val_loss: 16121.2031 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -102.2012  Val_loss: 15845.1670 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.5180  Val_loss: 13756.9453 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -101.7339  Val_loss: 12367.4053 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -102.1172  Val_loss: 15478.9258 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "14\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "96/99 [============================>.] - Loss for batch: 9.7370WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.7370  Val_loss: 1615.7382 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 9.0721  Val_loss: 1617.9414 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 7.7041  Val_loss: 1621.0793 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 6.6173  Val_loss: 1636.9073 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 5.3938  Val_loss: 1677.0983 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 4.5012  Val_loss: 1718.4344 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 3.7966  Val_loss: 1773.4937 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 2.1549  Val_loss: 1824.8831 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 1.4309  Val_loss: 1906.7412 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -0.1137  Val_loss: 2048.0923 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -1.2027  Val_loss: 2234.5828 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -2.2447  Val_loss: 2473.2825 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -3.1769  Val_loss: 2734.9695 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -4.6342  Val_loss: 2964.9785 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -6.1211  Val_loss: 3202.6355 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -7.6732  Val_loss: 3502.6394 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -8.2273  Val_loss: 3792.5884 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -10.4863  Val_loss: 4114.8379 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -10.9263  Val_loss: 4498.5293 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -12.8631  Val_loss: 4767.2808 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -14.1651  Val_loss: 4916.4468 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -15.2525  Val_loss: 5077.4453 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -16.8810  Val_loss: 5221.2124 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -17.7327  Val_loss: 5413.9360 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -20.4827  Val_loss: 5719.4507 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -20.9807  Val_loss: 6128.2881 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -23.4102  Val_loss: 6392.8755 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -24.4063  Val_loss: 6818.0396 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -26.0898  Val_loss: 7104.5303 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -28.1424  Val_loss: 7195.5190 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -28.9340  Val_loss: 7718.3857 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -30.4609  Val_loss: 7963.9980 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -32.1473  Val_loss: 7910.7622 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -34.3589  Val_loss: 8665.0166 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -35.1030  Val_loss: 9275.2812 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -36.7241  Val_loss: 9928.7295 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -38.5591  Val_loss: 11020.9365 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -40.2403  Val_loss: 13168.3408 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -43.5534  Val_loss: 14532.3975 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -44.3503  Val_loss: 14834.3525 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -47.0536  Val_loss: 17037.5664 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -47.9947  Val_loss: 17837.7324 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -50.0419  Val_loss: 18167.3281 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -52.2841  Val_loss: 20295.3574 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -54.5276  Val_loss: 21671.2129 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -56.6757  Val_loss: 22817.1152 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -59.2482  Val_loss: 23487.0195 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -62.0381  Val_loss: 22573.8789 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -64.2346  Val_loss: 27259.8340 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -65.2738  Val_loss: 29134.9375 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -70.2655  Val_loss: 29284.0879 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -70.4422  Val_loss: 25580.5508 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -73.6241  Val_loss: 25486.4121 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -74.3674  Val_loss: 21512.1641 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -76.3468  Val_loss: 18266.4297 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -78.6722  Val_loss: 18353.9531 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -81.9457  Val_loss: 14408.1045 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -83.2910  Val_loss: 9909.4004 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -85.0129  Val_loss: 8602.6777 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -86.1217  Val_loss: 6774.0435 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -87.1208  Val_loss: 3832.4763 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -89.5526  Val_loss: 3464.9543 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -88.6500WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.6500  Val_loss: 1460.2806 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -90.9604WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.9604  Val_loss: 782.8933 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -91.5929WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.5929  Val_loss: -425.0853 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -93.2670  Val_loss: 23.4234 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -94.6198WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.6198  Val_loss: -1278.2189 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -95.4859WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.4859  Val_loss: -1349.6056 \n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/99 [============================>.] - Loss for batch: -95.4399WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.4399  Val_loss: -2347.1589 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -93.4596WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.4596  Val_loss: -2383.4998 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -96.7006WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.7006  Val_loss: -3877.9529 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -94.3636  Val_loss: -3337.9524 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.6220  Val_loss: -3324.8738 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -94.7554WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.7554  Val_loss: -4481.2061 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -97.8934  Val_loss: -3242.5039 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.0042  Val_loss: -3299.3042 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.5859  Val_loss: -1427.5334 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -95.2325  Val_loss: -1109.6332 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.9756  Val_loss: 1639.2039 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.6979  Val_loss: 2034.8120 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.6312  Val_loss: 4472.9326 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.4099  Val_loss: 6207.6548 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.1714  Val_loss: 6261.0352 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.6764  Val_loss: 5287.8198 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.3434  Val_loss: 6920.1279 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.4930  Val_loss: 6674.1729 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.2062  Val_loss: 7193.5200 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.9284  Val_loss: 7910.7300 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -99.4099  Val_loss: 10520.2275 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.3016  Val_loss: 9839.2275 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.2839  Val_loss: 8986.2100 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -99.5361  Val_loss: 9284.9902 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -100.2699  Val_loss: 9747.3965 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.8586  Val_loss: 9754.9131 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -100.5230  Val_loss: 8721.5127 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -101.0307  Val_loss: 9017.9189 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -100.7365  Val_loss: 8321.1514 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -100.5537  Val_loss: 9615.8975 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -100.8135  Val_loss: 10302.5352 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.8611  Val_loss: 12369.8330 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -100.4970  Val_loss: 11082.7539 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -100.5472  Val_loss: 12010.0957 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.6120  Val_loss: 10830.3457 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.6273  Val_loss: 13452.1309 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -100.0574  Val_loss: 14907.6719 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -100.7780  Val_loss: 12547.2959 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -100.9685  Val_loss: 13141.7988 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.6979  Val_loss: 13779.1377 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -100.9500  Val_loss: 15337.2139 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.6578  Val_loss: 14474.5645 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -101.7136  Val_loss: 17044.4863 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.7347  Val_loss: 14814.7148 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -101.1105  Val_loss: 17108.5312 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -99.9129  Val_loss: 16529.8281 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -100.7352  Val_loss: 18053.1211 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -101.5725  Val_loss: 15300.3506 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -101.2571  Val_loss: 15855.1816 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -100.4685  Val_loss: 14206.1689 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -101.5469  Val_loss: 17861.7129 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.6535  Val_loss: 16999.7402 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -102.0852  Val_loss: 16598.1602 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -100.4855  Val_loss: 14488.1611 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -100.8750  Val_loss: 16381.4600 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -101.9191  Val_loss: 16599.6641 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -100.3393  Val_loss: 13927.0059 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -100.4545  Val_loss: 16350.0264 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -100.5039  Val_loss: 16702.0977 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -100.6477  Val_loss: 16666.5312 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -101.8386  Val_loss: 18394.4180 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -101.2243  Val_loss: 19008.9199 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -101.2671  Val_loss: 16324.0479 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -100.1989  Val_loss: 19553.5156 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -101.2363  Val_loss: 17249.9883 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.9762  Val_loss: 20235.1367 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -100.3628  Val_loss: 19804.6289 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -101.5416  Val_loss: 19299.3867 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -100.5867  Val_loss: 19757.8086 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -101.5141  Val_loss: 19451.6074 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -100.4323  Val_loss: 18550.9824 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -101.1824  Val_loss: 18461.0430 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -102.2314  Val_loss: 16454.3418 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -101.7155  Val_loss: 17778.4375 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -102.0073  Val_loss: 17602.5273 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -102.0237  Val_loss: 20890.5625 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -100.0248  Val_loss: 23286.3848 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -101.3451  Val_loss: 23778.8730 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -102.1692  Val_loss: 22529.2168 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -101.1095  Val_loss: 20313.8281 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -101.5855  Val_loss: 20667.0176 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -100.4681  Val_loss: 28871.6836 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -102.7692  Val_loss: 28883.8418 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -101.5701  Val_loss: 28936.7070 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -102.9605  Val_loss: 26936.9629 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -101.9897  Val_loss: 25072.9453 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -100.9800  Val_loss: 24951.7324 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -100.2910  Val_loss: 26160.6562 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -101.7731  Val_loss: 25192.7402 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -101.5560  Val_loss: 25149.9082 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -103.0487  Val_loss: 22620.4023 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -101.0569  Val_loss: 24128.1914 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -102.2777  Val_loss: 23321.9238 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -100.9296  Val_loss: 24426.9199 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -102.0546  Val_loss: 24261.3789 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -101.5039  Val_loss: 24351.1719 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -102.4555  Val_loss: 24260.0352 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -102.1624  Val_loss: 23195.4219 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -101.9150  Val_loss: 25366.8203 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -102.3297  Val_loss: 24844.1270 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -101.5792  Val_loss: 26972.8730 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -102.1997  Val_loss: 28214.4121 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -101.9703  Val_loss: 28313.3633 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -101.8864  Val_loss: 26571.4277 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -102.2309  Val_loss: 24783.0020 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -99.6866  Val_loss: 25248.7500 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -102.6855  Val_loss: 24371.2246 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -101.8394  Val_loss: 21634.0840 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -103.0946  Val_loss: 23519.7754 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -101.8785  Val_loss: 25702.6387 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -101.6069  Val_loss: 27057.0625 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -102.4252  Val_loss: 27692.6348 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -101.9711  Val_loss: 28693.5547 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -103.5058  Val_loss: 26006.7246 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -100.6933  Val_loss: 24440.9883 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -101.8367  Val_loss: 26215.2266 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -102.8978  Val_loss: 23375.5508 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -101.7187  Val_loss: 26679.3633 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -101.3010  Val_loss: 25518.0449 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -102.4795  Val_loss: 25328.1113 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -101.9149  Val_loss: 24014.4453 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -103.3739  Val_loss: 22519.3555 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -101.8189  Val_loss: 24218.6406 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -101.9134  Val_loss: 23132.0234 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -103.6925  Val_loss: 27372.4590 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -102.8520  Val_loss: 26895.0078 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -102.4892  Val_loss: 27783.2129 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -103.3328  Val_loss: 28594.8359 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -101.2399  Val_loss: 29122.2266 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -101.3161  Val_loss: 30267.6719 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -103.0481  Val_loss: 27826.2441 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -100.6446  Val_loss: 24168.8477 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "test_loglik_list = []\n",
    "val_loglik_list = []\n",
    "\n",
    "for i in range(15):\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state = keras.layers.GRU(hidden_state_size,return_sequences=True,return_state=True)(inputs=x_in,initial_state=hidden_state_in)\n",
    "\n",
    "    hidden_model = keras.models.Model(inputs=[x_in,x_out,hidden_state_in],outputs=[output2,state])\n",
    "\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "    hr_out = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "    hr_in = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state= hidden_model([x_in,x_out,hidden_state_in])\n",
    "\n",
    "    layer_hr = keras.layers.Dropout(0.3)(output2)\n",
    "    layer_hr = keras.layers.Dense(16,activation=\"elu\")(layer_hr)\n",
    "    layer_hr = keras.layers.Dropout(0.3)(layer_hr)\n",
    "    final_hr_mean = keras.layers.TimeDistributed(keras.layers.Dense(num_dims_hr,bias_initializer='zeros'))(layer_hr) + hr_in\n",
    "    sigma_mle_hr = (K.mean((final_hr_mean- hr_out)**2))**0.5\n",
    "\n",
    "    loglik_hr = loglik_gaussian_hr(hr_out,final_hr_mean,sigma_mle_hr)\n",
    "\n",
    "    nloglik_hr = loss(loglik_hr)\n",
    "\n",
    "    rnn_training_hr = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[nloglik_hr])\n",
    "    rnn_generate_hr = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[final_hr_mean,sigma_mle_hr,state])\n",
    "\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "    hr_out = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "    hr_in = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state = hidden_model([x_in,x_out,hidden_state_in],training=False)\n",
    "\n",
    "    layer = keras.layers.Dropout(0.3)(output2)\n",
    "    layer = keras.layers.Dense(8,activation=\"elu\")(layer)\n",
    "    layer = keras.layers.Dropout(0.3)(layer)\n",
    "    final_x_mean = keras.layers.TimeDistributed(keras.layers.Dense(num_dims,bias_initializer='zeros'))(layer) + x_in #this means we predict the residuals (better for learning)\n",
    "    sigma_mle_x = (K.mean((final_x_mean- x_out)**2))**0.5\n",
    "\n",
    "\n",
    "    loglik_x = loglik_gaussian_x(x_out,final_x_mean,sigma_mle_x)\n",
    "\n",
    "    nloglikx = loss(loglik_x)\n",
    "\n",
    "    rnn_training_x = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[nloglikx])\n",
    "    rnn_generate_x = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[final_x_mean,sigma_mle_x,state])\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(inputs,model):\n",
    "        \"\"\"Decorated train_step function which applies a gradient update to the parameters\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model(inputs,training=True)\n",
    "            loss = tf.add_n([loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    def fit_model(input_list,epochs,model,simulator,history,validation_loss\n",
    "                  ,valid_list,hr_toggle,index,batch_size=32):\n",
    "\n",
    "        start = time.time()\n",
    "        K.clear_session()\n",
    "\n",
    "        batch_loss = []\n",
    "        batches_per_epoch = int(np.ceil(input_list[0].shape[0]/batch_size))\n",
    "        \n",
    "        rnn_generate_x.save(\"no_tl_models/{}.h5\".format(index))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "                print(\"Epoch {}/{}\".format(epoch,epochs))\n",
    "                for i in range(batches_per_epoch):\n",
    "                    batch_list= create_batch(\n",
    "                        input_list,batch_size)\n",
    "                    loss = train_step(batch_list,model)\n",
    "                    batch_loss.append(loss)\n",
    "                    average_batch_loss = list_average(batch_loss)\n",
    "                    print_status_bar(i*batch_size,input_list[0].shape[0],average_batch_loss)\n",
    "\n",
    "                training_loss_for_epoch = list_average(batch_loss)\n",
    "                batch_loss = []\n",
    "                history.append(training_loss_for_epoch)\n",
    "\n",
    "                sigma_mle = simulator(input_list)[1]\n",
    "\n",
    "                val_loss = valid_loss(valid_list,simulator=simulator,sigma_x = sigma_mle,hr=hr_toggle)\n",
    "\n",
    "                validation_loss.append(val_loss)\n",
    "                if val_loss == min(validation_loss):\n",
    "                    rnn_generate_x.save(\"no_tl_models/{}.h5\".format(index))\n",
    "\n",
    "                print_status_bar_epoch(input_list[0].shape[0]\n",
    "                                 ,input_list[0].shape[0],training_loss_for_epoch,val_loss )\n",
    "\n",
    "        done = time.time()\n",
    "        elapsed = done-start\n",
    "        \n",
    "        plt.plot(validation_loss,label=\"validation\")\n",
    "        plt.show()\n",
    "        \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    fit_model(input_list,200,rnn_training_x,rnn_generate_x,training_losses,validation_losses\n",
    "              ,valid_list,hr_toggle=False,index=i,batch_size=32)\n",
    "  \n",
    "\n",
    "    rnn_generate_x = keras.models.load_model(\"no_tl_models/{}.h5\".format(i))\n",
    "    \n",
    "    sigma_x = rnn_generate_x(input_list)[1]\n",
    "    mean = rnn_generate_x(test_list)[0]\n",
    "    loglik = np.mean(loglik_gaussian_x(test_nn_output,mean,sigma_x))\n",
    "\n",
    "    test_loglik_list.append(loglik)\n",
    "    \n",
    "    mean = rnn_generate_x(valid_list)[0]\n",
    "    loglik = np.mean(loglik_gaussian_x(valid_nn_output,mean,sigma_x))\n",
    "\n",
    "    val_loglik_list.append(loglik)\n",
    "    \n",
    "a = np.array(test_loglik_list)\n",
    "b = np.array(val_loglik_list)\n",
    "array_loglik = np.stack([b,a],axis=1)\n",
    "np.save(\"no_tl_models/loglik_array.npy\",array_loglik)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6753729e+03,  1.3989975e+06],\n",
       "       [ 2.2109958e+03,  1.9560465e+06],\n",
       "       [ 1.7163282e+03,  1.6983150e+06],\n",
       "       [ 2.7829414e+03,  1.4063108e+06],\n",
       "       [ 4.2518799e+03,  1.4718738e+06],\n",
       "       [-1.1344034e+03, -9.0117445e+04],\n",
       "       [ 5.3731134e+02, -2.9211159e+05],\n",
       "       [ 5.8165449e+03,  2.1455115e+06],\n",
       "       [-7.6814703e+02, -2.1399133e+05],\n",
       "       [ 1.4390370e+03,  7.1822850e+05],\n",
       "       [ 4.1379209e+03,  1.4822712e+06],\n",
       "       [ 2.5738913e+02,  1.8782148e+06],\n",
       "       [ 4.0522866e+03,  1.9413259e+06],\n",
       "       [-1.2877104e+03, -1.9659972e+05],\n",
       "       [ 4.4812061e+03,  1.6783796e+06]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_loglik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 28.1946WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 28.1946  Val_loss: 1511.9872 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 20.6384WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 20.6384  Val_loss: 1290.7662 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 12.1494WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.1494  Val_loss: 1109.4271 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: 4.8178WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 4.8178  Val_loss: 978.0610 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -2.3020WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -2.3020  Val_loss: 916.9691 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -11.0092WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -11.0092  Val_loss: 905.8869 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -17.7586  Val_loss: 956.1406 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -27.3164  Val_loss: 1134.6870 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -33.8881  Val_loss: 1391.8813 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -45.4999  Val_loss: 1854.6831 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -49.6203  Val_loss: 2447.8733 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -59.3914  Val_loss: 2927.2190 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -69.4885  Val_loss: 3637.9041 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -76.9852  Val_loss: 4379.7119 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -86.2429  Val_loss: 5197.9561 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -97.0142  Val_loss: 6256.7798 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -105.3324  Val_loss: 7519.7153 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -117.4100  Val_loss: 8816.8936 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -127.7922  Val_loss: 9911.0635 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -137.8787  Val_loss: 11344.0996 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 5.7843  Val_loss: 1112.1704 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 5.7418  Val_loss: 1086.4878 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 5.0634  Val_loss: 1058.3334 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 4.3340  Val_loss: 1029.1567 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 3.2508  Val_loss: 1006.7361 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 2.3416  Val_loss: 984.1381 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 1.6627  Val_loss: 957.2750 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 1.8581  Val_loss: 930.0930 \n",
      "Epoch 8/200\n",
      "96/99 [============================>.] - Loss for batch: 1.7220WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 1.7220  Val_loss: 898.2148 \n",
      "Epoch 9/200\n",
      "96/99 [============================>.] - Loss for batch: 1.3313WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 1.3313  Val_loss: 871.8975 \n",
      "Epoch 10/200\n",
      "96/99 [============================>.] - Loss for batch: 0.03088WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.0308  Val_loss: 842.9830 \n",
      "Epoch 11/200\n",
      "96/99 [============================>.] - Loss for batch: -0.0122WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -0.0122  Val_loss: 808.0132 \n",
      "Epoch 12/200\n",
      "96/99 [============================>.] - Loss for batch: -1.4630WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -1.4630  Val_loss: 766.6304 \n",
      "Epoch 13/200\n",
      "96/99 [============================>.] - Loss for batch: -1.9442WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -1.9442  Val_loss: 722.8130 \n",
      "Epoch 14/200\n",
      "96/99 [============================>.] - Loss for batch: -2.5534WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -2.5534  Val_loss: 685.2635 \n",
      "Epoch 15/200\n",
      "96/99 [============================>.] - Loss for batch: -3.5727WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.5727  Val_loss: 664.3320 \n",
      "Epoch 16/200\n",
      "96/99 [============================>.] - Loss for batch: -3.8785WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.8785  Val_loss: 643.4882 \n",
      "Epoch 17/200\n",
      "96/99 [============================>.] - Loss for batch: -3.7726WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.7726  Val_loss: 612.7792 \n",
      "Epoch 18/200\n",
      "96/99 [============================>.] - Loss for batch: -4.6447WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -4.6447  Val_loss: 570.2330 \n",
      "Epoch 19/200\n",
      "96/99 [============================>.] - Loss for batch: -4.4805WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -4.4805  Val_loss: 524.7630 \n",
      "Epoch 20/200\n",
      "96/99 [============================>.] - Loss for batch: -5.7648WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -5.7648  Val_loss: 475.8034 \n",
      "Epoch 21/200\n",
      "96/99 [============================>.] - Loss for batch: -6.4780WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -6.4780  Val_loss: 421.7739 \n",
      "Epoch 22/200\n",
      "96/99 [============================>.] - Loss for batch: -8.2365WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.2365  Val_loss: 352.4030 \n",
      "Epoch 23/200\n",
      "96/99 [============================>.] - Loss for batch: -8.0616WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.0616  Val_loss: 268.0667 \n",
      "Epoch 24/200\n",
      "96/99 [============================>.] - Loss for batch: -8.8958WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.8958  Val_loss: 190.5852 \n",
      "Epoch 25/200\n",
      "96/99 [============================>.] - Loss for batch: -9.0391WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -9.0391  Val_loss: 113.1790 \n",
      "Epoch 26/200\n",
      "96/99 [============================>.] - Loss for batch: -10.3721WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -10.3721  Val_loss: 48.2900 \n",
      "Epoch 27/200\n",
      "96/99 [============================>.] - Loss for batch: -10.9688WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -10.9688  Val_loss: -6.2997 \n",
      "Epoch 28/200\n",
      "96/99 [============================>.] - Loss for batch: -11.6872WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -11.6872  Val_loss: -63.7356 \n",
      "Epoch 29/200\n",
      "96/99 [============================>.] - Loss for batch: -11.8572WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -11.8572  Val_loss: -127.2280 \n",
      "Epoch 30/200\n",
      "96/99 [============================>.] - Loss for batch: -12.7906WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -12.7906  Val_loss: -188.6725 \n",
      "Epoch 31/200\n",
      "96/99 [============================>.] - Loss for batch: -14.3495WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -14.3495  Val_loss: -251.0202 \n",
      "Epoch 32/200\n",
      "96/99 [============================>.] - Loss for batch: -14.3307WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -14.3307  Val_loss: -313.6548 \n",
      "Epoch 33/200\n",
      "96/99 [============================>.] - Loss for batch: -14.9374WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -14.9374  Val_loss: -378.9497 \n",
      "Epoch 34/200\n",
      "96/99 [============================>.] - Loss for batch: -16.2508WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -16.2508  Val_loss: -467.5710 \n",
      "Epoch 35/200\n",
      "96/99 [============================>.] - Loss for batch: -16.4541WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -16.4541  Val_loss: -568.5506 \n",
      "Epoch 36/200\n",
      "96/99 [============================>.] - Loss for batch: -17.3372WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -17.3372  Val_loss: -670.2700 \n",
      "Epoch 37/200\n",
      "96/99 [============================>.] - Loss for batch: -19.1384WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.1384  Val_loss: -735.9806 \n",
      "Epoch 38/200\n",
      "96/99 [============================>.] - Loss for batch: -19.4475WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.4475  Val_loss: -745.6536 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -19.9904  Val_loss: -727.7775 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -20.9748  Val_loss: -742.3203 \n",
      "Epoch 41/200\n",
      "96/99 [============================>.] - Loss for batch: -22.3570WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -22.3570  Val_loss: -783.6093 \n",
      "Epoch 42/200\n",
      "96/99 [============================>.] - Loss for batch: -23.1816WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -23.1816  Val_loss: -881.1905 \n",
      "Epoch 43/200\n",
      "96/99 [============================>.] - Loss for batch: -23.8942WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -23.8942  Val_loss: -978.1873 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -25.4674  Val_loss: -958.0615 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -26.4952  Val_loss: -968.6381 \n",
      "Epoch 46/200\n",
      "96/99 [============================>.] - Loss for batch: -27.2955WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -27.2955  Val_loss: -1015.4871 \n",
      "Epoch 47/200\n",
      "96/99 [============================>.] - Loss for batch: -28.4042WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -28.4042  Val_loss: -1155.4017 \n",
      "Epoch 48/200\n",
      "96/99 [============================>.] - Loss for batch: -29.7606WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -29.7606  Val_loss: -1300.0914 \n",
      "Epoch 49/200\n",
      "96/99 [============================>.] - Loss for batch: -30.6319WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -30.6319  Val_loss: -1429.5215 \n",
      "Epoch 50/200\n",
      "96/99 [============================>.] - Loss for batch: -31.9408WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -31.9408  Val_loss: -1533.3428 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -33.7990  Val_loss: -1503.2469 \n",
      "Epoch 52/200\n",
      "96/99 [============================>.] - Loss for batch: -34.0995WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -34.0995  Val_loss: -1564.1321 \n",
      "Epoch 53/200\n",
      "96/99 [============================>.] - Loss for batch: -35.9592WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -35.9592  Val_loss: -1710.5693 \n",
      "Epoch 54/200\n",
      "96/99 [============================>.] - Loss for batch: -36.9408WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -36.9408  Val_loss: -1839.3309 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -38.8533  Val_loss: -1796.5853 \n",
      "Epoch 56/200\n",
      "96/99 [============================>.] - Loss for batch: -40.6839WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -40.6839  Val_loss: -2142.3362 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -41.5644WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -41.5644  Val_loss: -2359.6716 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -43.8228WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -43.8228  Val_loss: -2575.0474 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -44.9916WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -44.9916  Val_loss: -2742.5181 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -47.0098WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -47.0098  Val_loss: -2776.7046 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -48.5749WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -48.5749  Val_loss: -3616.5149 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -51.1720WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -51.1720  Val_loss: -3929.5466 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -53.5462WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -53.5462  Val_loss: -4380.2090 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -56.1563WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -56.1563  Val_loss: -5094.3281 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -60.4839WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -60.4839  Val_loss: -5478.4844 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -62.1719WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.1719  Val_loss: -6516.6030 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -66.2440  Val_loss: -6318.6006 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -69.9487WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -69.9487  Val_loss: -7610.3604 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -72.7282  Val_loss: -7551.7285 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -77.4826WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -77.4826  Val_loss: -8405.0459 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -82.6952  Val_loss: -8234.2920 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -87.1885WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.1885  Val_loss: -9040.7188 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -89.8996  Val_loss: -8903.4541 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -91.8493WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.8493  Val_loss: -9267.9277 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -94.3790  Val_loss: -9117.0879 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -95.9395WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.9395  Val_loss: -9447.3525 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.0254  Val_loss: -9291.2383 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.8056  Val_loss: -9389.9414 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -95.7481  Val_loss: -9187.5938 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.5957  Val_loss: -9398.2031 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.1759  Val_loss: -9160.9580 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.1351  Val_loss: -9244.9883 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -96.0591  Val_loss: -8968.0039 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.6819  Val_loss: -9040.9863 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.8035  Val_loss: -9259.2236 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.8080  Val_loss: -9248.7100 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.2166  Val_loss: -9166.5684 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -96.2585  Val_loss: -9337.4961 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.6654  Val_loss: -9169.3701 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.5206  Val_loss: -9317.9648 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -96.8217  Val_loss: -9294.9727 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.2474  Val_loss: -9170.7969 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.1088  Val_loss: -9244.2764 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.1215  Val_loss: -9290.7920 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -96.8499  Val_loss: -9253.1650 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -96.9569  Val_loss: -9210.9609 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -96.0753  Val_loss: -9190.9180 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.0106  Val_loss: -9217.3115 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.5541  Val_loss: -9262.8887 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.2464  Val_loss: -9176.8291 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -98.4358  Val_loss: -9140.7305 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.3386  Val_loss: -9260.5352 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.5397  Val_loss: -9303.3486 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.1541  Val_loss: -9156.5576 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -96.3247  Val_loss: -9023.8115 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -97.4591  Val_loss: -8945.9121 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -96.4853  Val_loss: -8884.0791 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -97.8988  Val_loss: -8928.6309 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.0960  Val_loss: -8997.5098 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -96.3088  Val_loss: -8839.5117 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -97.7794  Val_loss: -8795.1582 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -96.4816  Val_loss: -8952.8711 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -97.4541  Val_loss: -8541.7637 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -97.9244  Val_loss: -8637.2764 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.9760  Val_loss: -9011.2100 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -97.6579  Val_loss: -9103.9863 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.2505  Val_loss: -8928.2578 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -96.4326  Val_loss: -8884.9834 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -97.5380  Val_loss: -8870.2148 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.4508  Val_loss: -8791.2383 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -97.2243  Val_loss: -8898.0977 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.2759  Val_loss: -8828.7959 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -97.3015  Val_loss: -8785.7764 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.9386  Val_loss: -9012.4424 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.3926  Val_loss: -8964.8545 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.0344  Val_loss: -8915.3535 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.3601  Val_loss: -8820.2305 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -96.7321  Val_loss: -8614.5566 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.1640  Val_loss: -8619.2705 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -97.1009  Val_loss: -8712.3740 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -97.8788  Val_loss: -8989.4404 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -97.4246  Val_loss: -8996.5361 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -98.7239  Val_loss: -9001.2148 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.0618  Val_loss: -9042.8154 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.2659  Val_loss: -8850.3174 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -97.7010  Val_loss: -8877.4971 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.6365  Val_loss: -8950.7617 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.6802  Val_loss: -8860.8887 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.2624  Val_loss: -8904.3076 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -96.8205  Val_loss: -9035.8389 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.7277  Val_loss: -8972.6514 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -99.1706  Val_loss: -9046.6689 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -97.6562  Val_loss: -8997.7080 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -97.3038  Val_loss: -9017.8867 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.7680  Val_loss: -8681.8936 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.4705  Val_loss: -8959.6924 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -95.9807  Val_loss: -8905.0488 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.4581  Val_loss: -8704.9326 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.2043  Val_loss: -8741.3711 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -99.3380  Val_loss: -9035.7598 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -96.8038  Val_loss: -9036.9453 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -97.7367  Val_loss: -8715.7031 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -99.0139  Val_loss: -8764.3564 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.2867  Val_loss: -8840.0361 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.6526  Val_loss: -8795.5967 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.7524  Val_loss: -8643.5957 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.9266  Val_loss: -8719.2578 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.5395  Val_loss: -8981.5244 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -97.8653  Val_loss: -8971.6797 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -96.9480  Val_loss: -8829.7959 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.8335  Val_loss: -8570.3838 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.3492  Val_loss: -8741.8770 \n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -97.0167  Val_loss: -8890.0156 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -96.9870  Val_loss: -8854.7656 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.5195  Val_loss: -8707.4648 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -97.5796  Val_loss: -8853.5850 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.2489  Val_loss: -9030.5410 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -97.6385  Val_loss: -8782.6367 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -98.4286  Val_loss: -8707.9678 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -97.3855  Val_loss: -8752.6934 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.9984  Val_loss: -8561.8750 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -96.6007  Val_loss: -8497.9238 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -99.4126  Val_loss: -8698.8730 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -98.5490  Val_loss: -8995.2617 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -96.2926  Val_loss: -8824.6348 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -99.1077  Val_loss: -8644.3291 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.3521  Val_loss: -8810.3994 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -97.5938  Val_loss: -9041.9863 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -98.7020  Val_loss: -8991.2988 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -96.6526  Val_loss: -8889.0635 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.1881  Val_loss: -8866.0918 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -97.0977  Val_loss: -8872.6436 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.7452  Val_loss: -8752.2598 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -98.4554  Val_loss: -8810.2559 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -96.9617  Val_loss: -8861.7441 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.4627  Val_loss: -8695.6201 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.3367  Val_loss: -8651.4980 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -96.6865  Val_loss: -8621.7676 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.4821  Val_loss: -8566.1436 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -96.8599  Val_loss: -8392.1250 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -96.8295  Val_loss: -8320.9814 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -96.6975  Val_loss: -8614.5703 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -96.2195  Val_loss: -8706.2002 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.8735  Val_loss: -8363.9365 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -97.1369  Val_loss: -8618.1846 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -99.2819  Val_loss: -8871.8926 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -97.6805  Val_loss: -8910.5225 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.7204  Val_loss: -8879.2959 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -99.2196  Val_loss: -8794.7256 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "1\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 10.2197WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.2197  Val_loss: -2186.4194 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 0.4327WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.4327  Val_loss: -2772.8879 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: -8.3467WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.3467  Val_loss: -3276.3774 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -19.6955WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.6955  Val_loss: -3685.3423 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -24.3486WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -24.3486  Val_loss: -4061.0913 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -34.5637WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -34.5637  Val_loss: -4340.1069 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -39.9152WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -39.9152  Val_loss: -4532.8506 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -49.6411WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -49.6411  Val_loss: -4623.7085 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -57.1234  Val_loss: -4623.4336 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -63.8437  Val_loss: -4554.7681 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -73.5142  Val_loss: -4411.9570 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -83.2773  Val_loss: -4243.0996 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -89.3851  Val_loss: -4142.5229 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -95.9963  Val_loss: -3967.9011 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -108.0167  Val_loss: -3546.5190 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -117.9223  Val_loss: -3147.5107 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -125.0418  Val_loss: -2849.7141 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -134.3045  Val_loss: -2675.4336 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -142.3749  Val_loss: -2731.4248 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -158.9291  Val_loss: -2853.1543 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 3.2231  Val_loss: 1209.0974 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 2.1768  Val_loss: 1199.5352 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 0.7393  Val_loss: 1193.2650 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 0.9152  Val_loss: 1189.8989 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: -0.4416  Val_loss: 1192.0559 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 0.1469  Val_loss: 1195.4832 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -0.2198  Val_loss: 1205.4794 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -1.0188  Val_loss: 1212.2673 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -1.8891  Val_loss: 1223.4282 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -1.4807  Val_loss: 1244.7639 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -2.9261  Val_loss: 1273.6692 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -4.0652  Val_loss: 1299.7148 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -6.0027  Val_loss: 1333.0808 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -5.5209  Val_loss: 1366.7161 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -6.2816  Val_loss: 1405.4427 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -6.2890  Val_loss: 1441.8657 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -7.1475  Val_loss: 1489.1099 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -7.3188  Val_loss: 1547.8859 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -10.0799  Val_loss: 1595.3162 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -8.5426  Val_loss: 1649.0367 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -9.8415  Val_loss: 1706.0541 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -10.4529  Val_loss: 1765.1923 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -10.9390  Val_loss: 1827.8939 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -11.7840  Val_loss: 1901.6895 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -11.6806  Val_loss: 1968.6068 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -13.8480  Val_loss: 2035.2220 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -14.9267  Val_loss: 2095.5283 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -14.3232  Val_loss: 2163.4028 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -15.5065  Val_loss: 2232.7087 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -15.9048  Val_loss: 2297.1177 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -17.0098  Val_loss: 2344.5654 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -18.0704  Val_loss: 2362.4099 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -18.3990  Val_loss: 2370.9954 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -18.7878  Val_loss: 2407.4460 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -20.1990  Val_loss: 2435.3926 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -20.4597  Val_loss: 2444.0510 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -21.0160  Val_loss: 2432.6348 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -21.2680  Val_loss: 2452.7239 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -23.7986  Val_loss: 2441.4517 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -23.5026  Val_loss: 2408.8198 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -25.9421  Val_loss: 2416.1560 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -25.6635  Val_loss: 2417.4509 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -26.7773  Val_loss: 2319.0117 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -28.4182  Val_loss: 2255.4819 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -28.8994  Val_loss: 2209.6572 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -29.8363  Val_loss: 2151.2852 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -30.5080  Val_loss: 2070.9612 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -32.4658  Val_loss: 2051.0078 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -33.1846  Val_loss: 1939.0168 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -34.8259  Val_loss: 1720.5475 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -34.5560  Val_loss: 1385.1287 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -37.2811  Val_loss: 1477.2941 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -37.2932  Val_loss: 1473.8492 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -39.8063  Val_loss: 1366.9994 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -41.4579  Val_loss: 1159.8135 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -42.9318  Val_loss: 515.2887 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -44.2890  Val_loss: 302.8629 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -44.8402  Val_loss: 230.6858 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -46.5489  Val_loss: -120.2751 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -47.5811  Val_loss: -895.5544 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -49.7460  Val_loss: -1596.6909 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -52.6517  Val_loss: -1484.8175 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -52.9717  Val_loss: -1854.5481 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -57.4393  Val_loss: -2668.3301 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -58.9103  Val_loss: -3509.0884 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -61.3059  Val_loss: -4159.2529 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -62.9696WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.9696  Val_loss: -4682.4604 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -66.9635WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.9635  Val_loss: -6101.3594 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -68.8399WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -68.8399  Val_loss: -6540.4854 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -71.7593WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -71.7593  Val_loss: -7622.5015 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -76.2043WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -76.2043  Val_loss: -8049.9023 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -79.8860WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.8860  Val_loss: -8465.0977 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -84.2351WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -84.2351  Val_loss: -8504.2061 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -87.0681WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.0681  Val_loss: -8946.8096 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -90.2540  Val_loss: -8658.1475 \n",
      "Epoch 75/200\n",
      "96/99 [============================>.] - Loss for batch: -91.8738WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.8738  Val_loss: -9129.0264 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.2345  Val_loss: -9040.5840 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -94.3620  Val_loss: -8910.7441 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.0512  Val_loss: -9002.5713 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -95.5215  Val_loss: -8561.8701 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -95.3299  Val_loss: -8353.5078 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.5744  Val_loss: -8737.2744 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.0338  Val_loss: -8845.9648 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.4229  Val_loss: -8773.4746 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.7015  Val_loss: -8911.3809 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.1393  Val_loss: -8750.9951 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.7288  Val_loss: -8971.8213 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.3957  Val_loss: -8716.3623 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.1365  Val_loss: -8820.7188 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -95.6340  Val_loss: -8530.4814 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.0637  Val_loss: -8715.4248 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.6856  Val_loss: -8699.6670 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -96.6245  Val_loss: -8985.1738 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.9345  Val_loss: -8366.8398 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.7531  Val_loss: -8636.8936 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.9324  Val_loss: -9007.0938 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.4453  Val_loss: -8622.7070 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -98.3728  Val_loss: -8499.3232 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -96.2123  Val_loss: -8711.8154 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.4998  Val_loss: -8840.5146 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.8911  Val_loss: -8656.4629 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.3430  Val_loss: -8696.2881 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -95.7416  Val_loss: -8860.9971 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.7016  Val_loss: -8181.7944 \n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -96.6995  Val_loss: -8583.7295 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -98.2188  Val_loss: -8474.6406 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.1657  Val_loss: -8320.9668 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -97.6215  Val_loss: -8781.6826 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -95.3564  Val_loss: -8875.0156 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.9613  Val_loss: -8254.7637 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -97.9163  Val_loss: -8764.6855 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.1427  Val_loss: -8941.5439 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -98.9668  Val_loss: -8693.7275 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -97.2861  Val_loss: -8752.6328 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -97.6847  Val_loss: -8833.8926 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -99.3495  Val_loss: -8791.4453 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -97.5706  Val_loss: -8681.5391 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -99.2301  Val_loss: -8386.3584 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.7523  Val_loss: -8125.8940 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -97.5930  Val_loss: -8487.8672 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.9985  Val_loss: -8798.8330 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.3215  Val_loss: -8985.4893 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -99.5373  Val_loss: -8665.6885 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.2517  Val_loss: -8807.5264 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -99.7336  Val_loss: -8764.9551 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.0130  Val_loss: -8613.9219 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.6416  Val_loss: -8542.2852 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.8128  Val_loss: -8511.2520 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.9758  Val_loss: -8648.7627 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -98.0152  Val_loss: -8813.6846 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -99.0615  Val_loss: -8959.8262 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.8228  Val_loss: -8948.0576 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -98.7921  Val_loss: -8807.1484 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.1143  Val_loss: -8872.8486 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -99.8208  Val_loss: -8837.6279 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.8403  Val_loss: -8805.6367 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -98.6860  Val_loss: -8779.0547 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.8470  Val_loss: -8455.1064 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.6441  Val_loss: -8698.2129 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -99.4513  Val_loss: -8624.8613 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.7350  Val_loss: -8435.0752 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -99.7132  Val_loss: -8459.9951 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.4152  Val_loss: -8711.3086 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -96.9382  Val_loss: -8705.0439 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -100.5009  Val_loss: -8486.6172 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.0716  Val_loss: -8681.3838 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.7622  Val_loss: -8797.0781 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -97.7859  Val_loss: -8258.1260 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.2406  Val_loss: -8440.6572 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.8548  Val_loss: -8437.1309 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -99.1297  Val_loss: -8808.1514 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.6324  Val_loss: -8620.7168 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -96.9227  Val_loss: -8275.4961 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -97.1138  Val_loss: -8400.5869 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.3584  Val_loss: -8582.9424 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.9196  Val_loss: -8467.7256 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -98.0112  Val_loss: -8513.5010 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.6474  Val_loss: -8504.6797 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -99.2872  Val_loss: -8606.5361 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.1696  Val_loss: -8590.2500 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.0854  Val_loss: -8578.1484 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.9086  Val_loss: -8672.0703 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.6169  Val_loss: -8643.5439 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.6666  Val_loss: -8483.2988 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.8134  Val_loss: -8140.9316 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.2068  Val_loss: -8409.5322 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -99.4974  Val_loss: -8953.5479 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -99.4422  Val_loss: -8876.9727 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -98.4822  Val_loss: -8757.5762 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -97.9248  Val_loss: -8667.2178 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -96.9139  Val_loss: -8377.8682 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -98.9310  Val_loss: -8192.9395 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.2686  Val_loss: -8482.4492 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.2605  Val_loss: -8641.2705 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.9031  Val_loss: -8458.7148 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -99.3229  Val_loss: -8289.8760 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.3963  Val_loss: -8448.2773 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.1182  Val_loss: -8562.4658 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.0440  Val_loss: -8541.1611 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.8154  Val_loss: -8559.9033 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.2742  Val_loss: -8275.7432 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -97.5976  Val_loss: -8303.2119 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -97.7545  Val_loss: -8351.8740 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -99.6401  Val_loss: -8711.2881 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -100.4833  Val_loss: -8812.4971 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -98.2613  Val_loss: -8933.2021 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.5595  Val_loss: -8417.8262 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.6857  Val_loss: -8066.5088 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -97.3874  Val_loss: -8403.2744 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.4450  Val_loss: -8218.2031 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.3280  Val_loss: -8290.0518 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -99.0424  Val_loss: -8359.0459 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -97.4240  Val_loss: -8554.0547 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.7682  Val_loss: -8474.8574 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -99.7766  Val_loss: -8428.2061 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.7629  Val_loss: -8537.4512 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.9382  Val_loss: -8494.2852 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -97.6086  Val_loss: -8609.8154 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.4670  Val_loss: -8214.3994 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -97.8819  Val_loss: -8331.8662 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 30.5286WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 30.5286  Val_loss: 159.1742 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 20.8818WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 20.8818  Val_loss: -423.0255 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 11.1453WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 11.1453  Val_loss: -912.7476 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: 0.3740WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.3740  Val_loss: -1358.0615 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -8.9588WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.9588  Val_loss: -1774.8599 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -14.1255WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -14.1255  Val_loss: -2173.0420 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -25.0451WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -25.0451  Val_loss: -2496.9846 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -32.0514WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -32.0514  Val_loss: -2751.8606 \n",
      "Epoch 8/20\n",
      "96/99 [============================>.] - Loss for batch: -42.7590WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -42.7590  Val_loss: -2918.4956 \n",
      "Epoch 9/20\n",
      "96/99 [============================>.] - Loss for batch: -49.8513WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -49.8513  Val_loss: -2989.8779 \n",
      "Epoch 10/20\n",
      "96/99 [============================>.] - Loss for batch: -60.3784WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -60.3784  Val_loss: -3006.9971 \n",
      "Epoch 11/20\n",
      "96/99 [============================>.] - Loss for batch: -67.4760WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -67.4760  Val_loss: -3067.8838 \n",
      "Epoch 12/20\n",
      "96/99 [============================>.] - Loss for batch: -77.8178WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -77.8178  Val_loss: -3260.1436 \n",
      "Epoch 13/20\n",
      "96/99 [============================>.] - Loss for batch: -84.4222WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -84.4222  Val_loss: -3681.2756 \n",
      "Epoch 14/20\n",
      "96/99 [============================>.] - Loss for batch: -93.3849WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.3849  Val_loss: -4331.9766 \n",
      "Epoch 15/20\n",
      "96/99 [============================>.] - Loss for batch: -100.6233WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -100.6233  Val_loss: -5066.9360 \n",
      "Epoch 16/20\n",
      "96/99 [============================>.] - Loss for batch: -110.4303WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -110.4303  Val_loss: -5800.5386 \n",
      "Epoch 17/20\n",
      "96/99 [============================>.] - Loss for batch: -124.1901WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -124.1901  Val_loss: -6546.9932 \n",
      "Epoch 18/20\n",
      "96/99 [============================>.] - Loss for batch: -129.6654WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -129.6654  Val_loss: -7340.4873 \n",
      "Epoch 19/20\n",
      "96/99 [============================>.] - Loss for batch: -133.7650WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -133.7650  Val_loss: -7954.7607 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 3.5583  Val_loss: 2545.8936 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 1.8563  Val_loss: 2561.6326 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 1.4800  Val_loss: 2580.4902 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 0.9463  Val_loss: 2606.9626 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 0.1304  Val_loss: 2636.4080 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 0.8372  Val_loss: 2666.1196 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -1.2654  Val_loss: 2693.7910 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -1.7874  Val_loss: 2725.9038 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -2.2616  Val_loss: 2746.8774 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -1.9814  Val_loss: 2748.4387 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -3.6531  Val_loss: 2721.0686 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -3.7664  Val_loss: 2708.3611 \n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -4.4614  Val_loss: 2704.6187 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -5.8052  Val_loss: 2732.5100 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -5.9623  Val_loss: 2777.4116 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -6.3459  Val_loss: 2809.1873 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -6.6143  Val_loss: 2829.2051 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -8.0188  Val_loss: 2834.9185 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -7.9398  Val_loss: 2840.8835 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -9.6026  Val_loss: 2833.5002 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -10.3061  Val_loss: 2811.0183 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -10.5213  Val_loss: 2756.8154 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -11.1740  Val_loss: 2704.0181 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -12.4504  Val_loss: 2678.1130 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -11.5441  Val_loss: 2645.9414 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -13.1630  Val_loss: 2606.6172 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -14.3413  Val_loss: 2561.8215 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -14.0965  Val_loss: 2516.4458 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -14.9264  Val_loss: 2445.0720 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -16.0445  Val_loss: 2383.6948 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -17.2683  Val_loss: 2322.9246 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -17.7867  Val_loss: 2287.6277 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -19.0053  Val_loss: 2240.2979 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -19.6394  Val_loss: 2204.3521 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -19.8480  Val_loss: 2096.8308 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -20.5516  Val_loss: 1950.8966 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -21.9064  Val_loss: 1766.1233 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -22.9565  Val_loss: 1645.5172 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -23.4739  Val_loss: 1542.9800 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -24.5490  Val_loss: 1343.8315 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -25.8019  Val_loss: 1174.5442 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -26.9735  Val_loss: 1044.9766 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -27.2360  Val_loss: 862.7712 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -28.5702  Val_loss: 728.8033 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -30.5693  Val_loss: 526.5359 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -31.9291  Val_loss: 404.7412 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -32.0249  Val_loss: 135.7551 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -33.4622  Val_loss: -188.0190 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -34.4648  Val_loss: -713.1635 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -36.4070  Val_loss: -1101.0132 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -37.9426  Val_loss: -1408.2151 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -39.1192  Val_loss: -1630.7382 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -40.0922  Val_loss: -2121.5330 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -42.0375  Val_loss: -2648.4709 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -43.6431  Val_loss: -2883.5896 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -44.7736  Val_loss: -3205.5615 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -46.7521  Val_loss: -3656.1311 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -49.1771  Val_loss: -3774.1560 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -50.7707  Val_loss: -4418.4658 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -53.2749  Val_loss: -4981.7539 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -55.3723  Val_loss: -5418.5610 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -58.4518  Val_loss: -5895.8408 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -60.9984  Val_loss: -6616.5566 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -63.8328  Val_loss: -6658.8604 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -67.0200  Val_loss: -7504.4663 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -71.3836  Val_loss: -7932.8818 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -75.0963WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -75.0963  Val_loss: -8421.3564 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -79.9888WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.9888  Val_loss: -8766.2363 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -84.1312WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -84.1312  Val_loss: -8920.7480 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -89.3050WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -89.3050  Val_loss: -9420.5674 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -92.9467  Val_loss: -9223.6260 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -94.9576  Val_loss: -9362.7275 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -95.6057  Val_loss: -9288.5693 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -93.0729  Val_loss: -9365.9805 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.1081  Val_loss: -9141.0068 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.8439  Val_loss: -9239.9727 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.3001  Val_loss: -9247.1016 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -95.0340  Val_loss: -9296.7627 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.0773  Val_loss: -9235.4492 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.4371  Val_loss: -8810.9062 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -95.6873  Val_loss: -9223.0459 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.1959  Val_loss: -8988.3975 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.6996  Val_loss: -9047.0615 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.3908  Val_loss: -8778.2793 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.7419  Val_loss: -8328.8184 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.1523  Val_loss: -8928.5254 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.5453  Val_loss: -9015.6172 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.0475  Val_loss: -8895.3701 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.9208  Val_loss: -8812.7998 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.5465  Val_loss: -8878.0693 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.9753  Val_loss: -8547.6611 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.5983  Val_loss: -8735.3330 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.0981  Val_loss: -9265.0762 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.5348  Val_loss: -9081.4395 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -96.4764  Val_loss: -8659.2559 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.2299  Val_loss: -8829.5371 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.4220  Val_loss: -8957.4609 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -98.6500  Val_loss: -8767.0654 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.6460  Val_loss: -8697.7578 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.9486  Val_loss: -8671.4990 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.4583  Val_loss: -8945.1699 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.8793  Val_loss: -8663.7441 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.3897  Val_loss: -8674.6396 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.7828  Val_loss: -8917.2490 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.5263  Val_loss: -8995.0498 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -96.8493  Val_loss: -8931.1475 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -97.7023  Val_loss: -8546.9316 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -97.0607  Val_loss: -8685.5879 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -97.3149  Val_loss: -8152.3628 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.6579  Val_loss: -8650.5029 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -97.6275  Val_loss: -8951.7441 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.0721  Val_loss: -8771.8691 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -98.3355  Val_loss: -8729.6846 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.3469  Val_loss: -8518.9482 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -96.8052  Val_loss: -7923.0518 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.3114  Val_loss: -8279.0996 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -99.3050  Val_loss: -8644.0996 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.7848  Val_loss: -8889.1201 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -99.2546  Val_loss: -8957.2959 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -98.7768  Val_loss: -8731.0869 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -99.2441  Val_loss: -8922.8936 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -97.9237  Val_loss: -8966.2314 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -97.3750  Val_loss: -8386.0410 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.3916  Val_loss: -8360.8008 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -98.2488  Val_loss: -8921.6758 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -99.4947  Val_loss: -8860.5254 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -99.4154  Val_loss: -8492.9326 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.9613  Val_loss: -8661.6602 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.4767  Val_loss: -8882.4395 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -99.2412  Val_loss: -8833.8789 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.5552  Val_loss: -8475.5117 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.1666  Val_loss: -8496.3779 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -97.9979  Val_loss: -8522.8154 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.1272  Val_loss: -8422.4131 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.5149  Val_loss: -8452.9492 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.4333  Val_loss: -8879.3564 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -97.1993  Val_loss: -8503.7900 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -98.0442  Val_loss: -8630.8779 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.9487  Val_loss: -8726.7676 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.5919  Val_loss: -8357.1221 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.1764  Val_loss: -8262.1768 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.0237  Val_loss: -8326.2441 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -96.6506  Val_loss: -8492.2441 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -97.2336  Val_loss: -8253.6426 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -97.7425  Val_loss: -8016.1592 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.1657  Val_loss: -8471.5293 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -97.3139  Val_loss: -8637.9922 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.2291  Val_loss: -8634.2920 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -100.1281  Val_loss: -8694.1650 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.5446  Val_loss: -8187.7197 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.9572  Val_loss: -8296.1631 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.2446  Val_loss: -8549.3477 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -97.5066  Val_loss: -8430.1367 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -97.8644  Val_loss: -8503.0117 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -97.5775  Val_loss: -8630.4648 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -98.3538  Val_loss: -8087.1792 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -99.6018  Val_loss: -8818.4541 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.1946  Val_loss: -8958.4082 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.1072  Val_loss: -8665.5566 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -97.9002  Val_loss: -8650.3867 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -98.0082  Val_loss: -8447.8818 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -97.4973  Val_loss: -8322.2295 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.8368  Val_loss: -8705.6973 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -98.0298  Val_loss: -8884.6123 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -99.3655  Val_loss: -8550.8066 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -100.3459  Val_loss: -8447.4863 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.5652  Val_loss: -8648.6250 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.2206  Val_loss: -8222.5205 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -97.5220  Val_loss: -8039.4634 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -99.0494  Val_loss: -8335.4102 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -99.3156  Val_loss: -8659.9072 \n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -100.6447  Val_loss: -8725.8662 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.4253  Val_loss: -8626.5078 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -99.6123  Val_loss: -8374.9424 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.8068  Val_loss: -8740.9248 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -99.6873  Val_loss: -8862.4844 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.4776  Val_loss: -8374.3076 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -97.5852  Val_loss: -8507.7510 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -99.3439  Val_loss: -8556.0879 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.7424  Val_loss: -8223.9775 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -100.1228  Val_loss: -8517.3506 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.9776  Val_loss: -8592.0811 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -96.5440  Val_loss: -8549.0244 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -99.4732  Val_loss: -8468.1904 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -97.2760  Val_loss: -8532.1387 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -100.2524  Val_loss: -8855.1025 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.1102  Val_loss: -8061.0654 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.9316  Val_loss: -8177.4971 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -99.2311  Val_loss: -8697.0176 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -99.0792  Val_loss: -8584.1904 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -99.4849  Val_loss: -8403.2188 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.3759  Val_loss: -8480.7773 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.1725  Val_loss: -8095.6846 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.2126  Val_loss: -8159.1792 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -98.6871  Val_loss: -8315.4541 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -97.6370  Val_loss: -8367.0898 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -97.6987  Val_loss: -7961.9502 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -97.7002  Val_loss: -8050.4951 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -97.8119  Val_loss: -8432.4775 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -99.3386  Val_loss: -8631.0176 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "3\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 26.8871WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 26.8871  Val_loss: -631.5390 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 18.4501WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 18.4501  Val_loss: -1173.2382 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 9.3484WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 9.3484  Val_loss: -1579.2672 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: 0.1626WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.1626  Val_loss: -1815.5442 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -5.2921WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -5.2921  Val_loss: -1915.8903 \n",
      "Epoch 5/20\n",
      "99/99 [==============================] - trainLoss: -16.6063  Val_loss: -1814.9735 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -25.5037  Val_loss: -1523.6429 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -36.8840  Val_loss: -1005.9311 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -41.9380  Val_loss: -332.0587 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -54.5118  Val_loss: 506.4174 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -61.4849  Val_loss: 1454.1108 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -73.1253  Val_loss: 2469.0215 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -81.1695  Val_loss: 3660.2090 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -89.6247  Val_loss: 5371.6250 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -94.7409  Val_loss: 7235.0234 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -103.3194  Val_loss: 9250.2061 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -115.5400  Val_loss: 11528.7100 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -122.9688  Val_loss: 13634.1123 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -138.2030  Val_loss: 15621.0059 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -142.7841  Val_loss: 17605.6406 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 1.8959  Val_loss: 3317.1350 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 0.6764  Val_loss: 3394.7190 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 0.2738  Val_loss: 3499.4172 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: -0.6164  Val_loss: 3584.8127 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: -1.4151  Val_loss: 3673.7034 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: -1.8487  Val_loss: 3760.5913 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -1.0421  Val_loss: 3825.8364 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -3.0164  Val_loss: 3883.3674 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -3.9565  Val_loss: 3944.8025 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -3.9017  Val_loss: 3997.5278 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -3.7757  Val_loss: 4030.8020 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -6.1151  Val_loss: 4066.9956 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -7.1342  Val_loss: 4128.0327 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -6.4942  Val_loss: 4208.2500 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -7.1698  Val_loss: 4288.5059 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -8.1139  Val_loss: 4343.1504 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -8.0780  Val_loss: 4395.5112 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -9.0535  Val_loss: 4433.1318 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -10.0321  Val_loss: 4441.7266 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -10.7821  Val_loss: 4456.3066 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -11.2372  Val_loss: 4470.9819 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -12.1588  Val_loss: 4457.8916 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -12.9118  Val_loss: 4491.2637 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -12.7836  Val_loss: 4491.5410 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -13.7677  Val_loss: 4472.6753 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -14.8605  Val_loss: 4459.0024 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -15.4569  Val_loss: 4490.5830 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -16.3691  Val_loss: 4563.8423 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -16.7655  Val_loss: 4618.6558 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -18.0471  Val_loss: 4662.9658 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -18.9321  Val_loss: 4653.3301 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -19.4132  Val_loss: 4600.7969 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -19.9305  Val_loss: 4556.6099 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -21.7816  Val_loss: 4542.2451 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -21.4107  Val_loss: 4493.8091 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -22.9184  Val_loss: 4310.3979 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -23.4433  Val_loss: 4200.3643 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -24.6205  Val_loss: 4271.3682 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -25.3388  Val_loss: 4330.8325 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -26.7432  Val_loss: 4147.9561 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -27.0677  Val_loss: 3723.8459 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -28.4608  Val_loss: 3333.6294 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -30.2965  Val_loss: 3314.4512 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -30.3656  Val_loss: 3355.2043 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -32.3209  Val_loss: 3100.1775 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -33.1740  Val_loss: 2676.5054 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -34.7399  Val_loss: 2654.9465 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -36.0750  Val_loss: 2421.5532 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -37.9512  Val_loss: 1970.2339 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -38.8230  Val_loss: 1742.0490 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -39.5914  Val_loss: 1301.1387 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -41.8143  Val_loss: 714.6373 \n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -42.3462  Val_loss: 394.7378 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -44.3919  Val_loss: 307.6764 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -46.9086  Val_loss: -102.1283 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -48.3024  Val_loss: -630.1086 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -49.9999  Val_loss: -1507.0074 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -52.3548WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -52.3548  Val_loss: -2385.7590 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -54.1354WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -54.1354  Val_loss: -2552.3730 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -57.7519  Val_loss: -2543.5144 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -60.8325WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -60.8325  Val_loss: -3775.4307 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -63.5663WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -63.5663  Val_loss: -3834.9829 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -67.0658WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -67.0658  Val_loss: -4336.8584 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -71.5444WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -71.5444  Val_loss: -4924.0728 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -74.7213WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -74.7213  Val_loss: -5494.5195 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -79.4949WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.4949  Val_loss: -6234.4678 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -83.6882WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -83.6882  Val_loss: -7567.3428 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -87.1970WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.1970  Val_loss: -7975.7803 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -90.5705WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.5705  Val_loss: -8404.6934 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -93.2499  Val_loss: -8364.7314 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -94.1655  Val_loss: -8259.0117 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -95.4905  Val_loss: -8296.2637 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -96.0349  Val_loss: -7934.0396 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -95.8046WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.8046  Val_loss: -8459.4297 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -96.6940WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.6940  Val_loss: -8560.9277 \n",
      "Epoch 75/200\n",
      "96/99 [============================>.] - Loss for batch: -98.0787WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -98.0787  Val_loss: -8754.2363 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.0199  Val_loss: -8748.7031 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.8537  Val_loss: -8471.3037 \n",
      "Epoch 78/200\n",
      "96/99 [============================>.] - Loss for batch: -97.3691WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.3691  Val_loss: -8814.6924 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.1428  Val_loss: -8610.5947 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -98.1924  Val_loss: -8269.3779 \n",
      "Epoch 81/200\n",
      "96/99 [============================>.] - Loss for batch: -97.7184WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.7184  Val_loss: -8889.9365 \n",
      "Epoch 82/200\n",
      "96/99 [============================>.] - Loss for batch: -99.2654WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -99.2654  Val_loss: -8978.1963 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.1215  Val_loss: -8504.5430 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.4952  Val_loss: -8095.3862 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.3324  Val_loss: -8074.0024 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.4495  Val_loss: -8702.3184 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.6203  Val_loss: -8346.7979 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.3904  Val_loss: -8110.4097 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.0223  Val_loss: -8883.3418 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.6919  Val_loss: -8541.0918 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.1332  Val_loss: -8181.3550 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.0882  Val_loss: -8596.2422 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.0547  Val_loss: -8895.1689 \n",
      "Epoch 94/200\n",
      "96/99 [============================>.] - Loss for batch: -98.3461WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.3461  Val_loss: -9018.4814 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.2183  Val_loss: -8973.6904 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.4261  Val_loss: -8903.7344 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.3929  Val_loss: -8380.7490 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -96.7864  Val_loss: -8489.5244 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.4776  Val_loss: -8620.5254 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -96.6987  Val_loss: -8473.5693 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.4112  Val_loss: -8504.2139 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.1539  Val_loss: -8548.9277 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.5564  Val_loss: -8412.8867 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.9098  Val_loss: -8359.8984 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -96.7673  Val_loss: -8616.0176 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.4864  Val_loss: -8743.4395 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -97.3582  Val_loss: -8825.4053 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.7952  Val_loss: -8652.4727 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.9062  Val_loss: -8862.7920 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.1793  Val_loss: -8980.1875 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -97.8419  Val_loss: -8448.0938 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -97.9711  Val_loss: -8275.3818 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -99.2469  Val_loss: -8950.1924 \n",
      "Epoch 114/200\n",
      "96/99 [============================>.] - Loss for batch: -97.5175WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.5175  Val_loss: -9119.2334 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -99.5326  Val_loss: -8852.5889 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -97.8445  Val_loss: -8741.4238 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.3606  Val_loss: -8759.4023 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.2338  Val_loss: -8635.6562 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -96.9690  Val_loss: -8346.8320 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.9541  Val_loss: -8490.0996 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.7500  Val_loss: -8637.1387 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -99.0258  Val_loss: -8787.4043 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.6343  Val_loss: -8908.2578 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.4597  Val_loss: -8781.4668 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -96.0312  Val_loss: -8310.6191 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -96.4980  Val_loss: -7866.0737 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.6753  Val_loss: -8087.8901 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.0547  Val_loss: -8766.0977 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -98.6082  Val_loss: -8917.5674 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.6693  Val_loss: -8873.9512 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -96.8256  Val_loss: -8666.7061 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.1842  Val_loss: -8914.4727 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -96.7946  Val_loss: -8706.2441 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.5103  Val_loss: -8154.7202 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -98.1977  Val_loss: -8594.0576 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.4114  Val_loss: -8884.9795 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -96.7023  Val_loss: -8781.8799 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.9993  Val_loss: -8436.7002 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.6620  Val_loss: -8532.2559 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -96.7995  Val_loss: -8575.2852 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.3130  Val_loss: -8959.8115 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.6361  Val_loss: -8915.4531 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -98.2502  Val_loss: -8895.7617 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.1562  Val_loss: -8602.5039 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.2738  Val_loss: -8614.5205 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -97.9992  Val_loss: -8688.4541 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.6203  Val_loss: -8848.3379 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.3369  Val_loss: -8845.3584 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -99.2526  Val_loss: -8662.4482 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -96.5927  Val_loss: -8486.9150 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -98.2183  Val_loss: -8345.0947 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -100.0607  Val_loss: -8773.8994 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -98.8386  Val_loss: -9038.3672 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -100.1684  Val_loss: -9024.6006 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.6807  Val_loss: -8843.8760 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.3114  Val_loss: -8432.0879 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.3307  Val_loss: -8648.1133 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -97.8932  Val_loss: -8913.5059 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.4323  Val_loss: -8977.0957 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.9987  Val_loss: -8819.6777 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -99.3435  Val_loss: -8659.6523 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.8891  Val_loss: -8712.0498 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.7787  Val_loss: -8634.9375 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.4021  Val_loss: -8528.9355 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.3598  Val_loss: -8551.3291 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.2147  Val_loss: -8486.5986 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -97.0626  Val_loss: -8263.4424 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.0808  Val_loss: -8554.9629 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -96.2802  Val_loss: -8537.7295 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -99.3061  Val_loss: -8847.0098 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.3609  Val_loss: -8805.8496 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -97.9535  Val_loss: -8427.3623 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -97.9017  Val_loss: -8535.2832 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.1146  Val_loss: -8436.1152 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -97.6336  Val_loss: -8361.5596 \n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -99.8236  Val_loss: -8571.5215 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.4510  Val_loss: -8550.2344 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.6972  Val_loss: -8587.7178 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -98.5396  Val_loss: -8934.2832 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -97.7156  Val_loss: -8927.4121 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.5341  Val_loss: -8916.5518 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -98.0867  Val_loss: -8440.7031 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -98.6489  Val_loss: -8318.8799 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -97.6419  Val_loss: -8653.0059 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -97.1011  Val_loss: -8852.3281 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.7984  Val_loss: -8722.8291 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.5285  Val_loss: -8637.9600 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.5406  Val_loss: -8537.3877 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -98.3034  Val_loss: -8576.4834 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.5121  Val_loss: -8557.4512 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -97.3790  Val_loss: -8683.3848 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.6389  Val_loss: -8761.0576 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -97.8641  Val_loss: -8766.4795 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.9973  Val_loss: -8751.4492 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.6566  Val_loss: -8727.9570 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -96.7212  Val_loss: -8536.9170 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.5369  Val_loss: -8623.0371 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -97.4911  Val_loss: -8407.3066 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -98.0042  Val_loss: -8369.7832 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "4\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 26.9951WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 26.9951  Val_loss: 1310.3550 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 17.2656WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 17.2656  Val_loss: 1084.7046 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 7.5048WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.5048  Val_loss: 1001.9009 \n",
      "Epoch 3/20\n",
      "99/99 [==============================] - trainLoss: -2.8621  Val_loss: 1077.3746 \n",
      "Epoch 4/20\n",
      "99/99 [==============================] - trainLoss: -9.6217  Val_loss: 1263.8389 \n",
      "Epoch 5/20\n",
      "99/99 [==============================] - trainLoss: -17.8202  Val_loss: 1564.4113 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -27.4001  Val_loss: 1959.4229 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -37.2924  Val_loss: 2381.4512 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -42.4959  Val_loss: 2872.2981 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -50.9765  Val_loss: 3366.6716 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -58.8424  Val_loss: 3779.5398 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -68.0710  Val_loss: 4113.4448 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -77.8337  Val_loss: 4442.3389 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -85.3454  Val_loss: 4704.5786 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -94.0660  Val_loss: 4821.7598 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -104.1627  Val_loss: 4875.0103 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -111.2550  Val_loss: 4781.5103 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -121.5605  Val_loss: 4685.7368 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -132.3315  Val_loss: 4466.3618 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -144.9924  Val_loss: 3973.7722 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 5.6496  Val_loss: 2030.9956 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 3.9788  Val_loss: 2111.6133 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 3.5743  Val_loss: 2206.5642 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 3.5035  Val_loss: 2309.1802 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 2.2412  Val_loss: 2422.3086 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 2.6680  Val_loss: 2527.6899 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 1.4113  Val_loss: 2637.2126 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 1.0724  Val_loss: 2754.6262 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -0.0116  Val_loss: 2884.8682 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -0.0502  Val_loss: 3021.1733 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -0.9710  Val_loss: 3159.6951 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -1.4735  Val_loss: 3297.3430 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.4804  Val_loss: 3422.6194 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -2.4809  Val_loss: 3541.9597 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -3.0436  Val_loss: 3674.6445 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -3.3318  Val_loss: 3802.3779 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -4.1726  Val_loss: 3894.2900 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -5.0529  Val_loss: 3991.3860 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -5.7735  Val_loss: 4106.5791 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -5.9381  Val_loss: 4203.2119 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -6.7922  Val_loss: 4295.4644 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -7.3024  Val_loss: 4389.2407 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -8.2867  Val_loss: 4515.9199 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -8.7442  Val_loss: 4658.1924 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -9.1910  Val_loss: 4779.0923 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -10.0407  Val_loss: 4894.5566 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -11.6423  Val_loss: 5017.4824 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -11.5130  Val_loss: 5105.5049 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -12.5741  Val_loss: 5192.7993 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -13.5658  Val_loss: 5319.1572 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -14.1256  Val_loss: 5454.6201 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -14.9634  Val_loss: 5567.2417 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -14.9240  Val_loss: 5641.1890 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -15.4824  Val_loss: 5706.9072 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -16.7393  Val_loss: 5744.3120 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -17.5091  Val_loss: 5765.7676 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -18.3035  Val_loss: 5759.1016 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -18.9030  Val_loss: 5742.9194 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -20.5565  Val_loss: 5740.7095 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -20.6361  Val_loss: 5745.6011 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -21.7348  Val_loss: 5776.3799 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -23.5212  Val_loss: 5860.9185 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -24.0047  Val_loss: 5931.2539 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -25.4491  Val_loss: 5996.7485 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -26.6864  Val_loss: 5965.8960 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -27.0928  Val_loss: 5927.6611 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -28.6122  Val_loss: 5972.9878 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -29.6782  Val_loss: 6056.1479 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -30.1792  Val_loss: 5975.3584 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -32.2251  Val_loss: 5735.3105 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -33.7973  Val_loss: 5656.6030 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -35.0861  Val_loss: 5987.7988 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -36.3792  Val_loss: 6175.5371 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -37.6799  Val_loss: 6179.9531 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -39.4474  Val_loss: 5817.9736 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -40.7527  Val_loss: 5657.9268 \n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -42.3998  Val_loss: 5616.9390 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -44.6298  Val_loss: 5271.1465 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -45.9214  Val_loss: 4490.7480 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -48.0960  Val_loss: 3660.0032 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -49.9863  Val_loss: 3317.1843 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -52.4369  Val_loss: 3364.8838 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -54.0773  Val_loss: 1678.2316 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -57.0500WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -57.0500  Val_loss: 279.1273 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -59.5894WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.5894  Val_loss: -935.8441 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -62.3168WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.3168  Val_loss: -3202.6907 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -65.0206WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -65.0206  Val_loss: -4704.4434 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -67.9552WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -67.9552  Val_loss: -6838.9263 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -72.8326WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -72.8326  Val_loss: -7181.3188 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -77.0354WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -77.0354  Val_loss: -8277.0469 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -81.4144WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -81.4144  Val_loss: -8592.1152 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -85.9120WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -85.9120  Val_loss: -8733.9941 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -91.0124WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.0124  Val_loss: -9194.7451 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -91.6433  Val_loss: -9107.4561 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -94.9684  Val_loss: -9180.6436 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -93.6505  Val_loss: -9085.8525 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -95.8067  Val_loss: -9126.7900 \n",
      "Epoch 77/200\n",
      "96/99 [============================>.] - Loss for batch: -94.6789WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.6789  Val_loss: -9254.1992 \n",
      "Epoch 78/200\n",
      "96/99 [============================>.] - Loss for batch: -95.7786WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.7786  Val_loss: -9299.7783 \n",
      "Epoch 79/200\n",
      "96/99 [============================>.] - Loss for batch: -96.1173WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.1173  Val_loss: -9398.6885 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.0496  Val_loss: -9108.4434 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.3340  Val_loss: -9301.2520 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.7050  Val_loss: -9326.0762 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -96.6680  Val_loss: -9352.8076 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.4674  Val_loss: -9248.5156 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -97.0000  Val_loss: -9055.6758 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -95.9279  Val_loss: -9252.5869 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.1958  Val_loss: -9369.9688 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.7563  Val_loss: -8930.5469 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -96.0491  Val_loss: -9287.0635 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -98.7714  Val_loss: -9385.4795 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -98.1304  Val_loss: -9120.1797 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -96.0027  Val_loss: -8818.9736 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.1291  Val_loss: -9132.8066 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.6734  Val_loss: -9118.1924 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.3286  Val_loss: -8911.0889 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.0039  Val_loss: -8974.2236 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -96.8826  Val_loss: -9204.3418 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.5374  Val_loss: -9259.2920 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.5872  Val_loss: -9225.8965 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.7446  Val_loss: -9038.7002 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.2789  Val_loss: -9193.7529 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.8503  Val_loss: -9201.5967 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.1459  Val_loss: -9107.8809 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.3292  Val_loss: -9097.2861 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -97.7183  Val_loss: -8925.2539 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -96.9473  Val_loss: -9094.1152 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.1945  Val_loss: -9155.5029 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.5390  Val_loss: -9226.7109 \n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -97.7972  Val_loss: -9094.1240 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -96.0527  Val_loss: -9302.1436 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.1539  Val_loss: -9252.0186 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -97.6512  Val_loss: -9074.7451 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.7855  Val_loss: -9094.2314 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -96.4918  Val_loss: -9027.1973 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.6434  Val_loss: -9208.1201 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -96.6398  Val_loss: -9272.9590 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -96.6332  Val_loss: -9069.5830 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -96.7535  Val_loss: -9052.9668 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -95.6815  Val_loss: -9074.0459 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -96.5378  Val_loss: -9024.9814 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -97.3388  Val_loss: -9134.2646 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -97.2260  Val_loss: -9030.9150 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -97.4231  Val_loss: -9096.1953 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -95.4875  Val_loss: -9186.0117 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -97.9336  Val_loss: -9123.9473 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -98.0013  Val_loss: -9019.8975 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.6150  Val_loss: -9019.7139 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.6247  Val_loss: -9116.6875 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.3769  Val_loss: -9393.5137 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.7065  Val_loss: -9396.3779 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -97.8156  Val_loss: -9047.6367 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -95.5523  Val_loss: -8581.5957 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.2549  Val_loss: -8945.3115 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -97.6579  Val_loss: -9364.4170 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.6391  Val_loss: -9244.1035 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -97.3605  Val_loss: -9025.5635 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -96.7194  Val_loss: -8990.8105 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.2843  Val_loss: -9061.9707 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -98.2963  Val_loss: -9082.3721 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -96.9727  Val_loss: -9144.4414 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.4335  Val_loss: -9170.5430 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.8418  Val_loss: -9129.7236 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -97.0500  Val_loss: -9149.7969 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -96.7561  Val_loss: -9078.0752 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.2605  Val_loss: -9199.0117 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.5863  Val_loss: -9257.7148 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -95.2093  Val_loss: -9124.5557 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.1477  Val_loss: -9056.9551 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.9507  Val_loss: -8938.6826 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -97.5407  Val_loss: -9062.3496 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -96.3514  Val_loss: -9109.7529 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -96.9751  Val_loss: -9148.2383 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -97.5232  Val_loss: -9328.2617 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -99.2712  Val_loss: -9352.3994 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -96.9060  Val_loss: -9179.2031 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.9513  Val_loss: -9048.0547 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -96.2574  Val_loss: -9134.2871 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.0062  Val_loss: -9078.7861 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -97.1033  Val_loss: -9047.0166 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -98.1025  Val_loss: -8978.6201 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.1259  Val_loss: -9123.6045 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -100.1930  Val_loss: -9241.2559 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.5023  Val_loss: -9095.5918 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.0011  Val_loss: -9234.1387 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -98.4787  Val_loss: -9115.9736 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -96.9485  Val_loss: -9265.5605 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.0970  Val_loss: -9126.3809 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -95.6456  Val_loss: -9033.9707 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -99.3774  Val_loss: -9258.4775 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -97.3459  Val_loss: -9209.8525 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.4133  Val_loss: -9168.1006 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -96.2976  Val_loss: -9036.1758 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.4950  Val_loss: -8918.0977 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.2782  Val_loss: -8883.2832 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -97.2531  Val_loss: -9018.9150 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.1110  Val_loss: -9213.3760 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -96.5703  Val_loss: -9221.2256 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.4498  Val_loss: -9110.3242 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.4068  Val_loss: -8975.0547 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.2963  Val_loss: -8935.9492 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.0989  Val_loss: -9146.2090 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -97.6151  Val_loss: -9191.2656 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -98.4477  Val_loss: -8976.4707 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -99.7987  Val_loss: -9006.8135 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -97.0963  Val_loss: -9052.6416 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.7240  Val_loss: -9005.8262 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.9097  Val_loss: -9297.1406 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -97.3050  Val_loss: -9257.7539 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -99.2358  Val_loss: -9137.9258 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -96.7774  Val_loss: -9251.4395 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.1214  Val_loss: -8949.5205 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -97.5745  Val_loss: -9010.0254 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -96.9414  Val_loss: -9096.6387 \n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.1867  Val_loss: -9055.5918 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -99.4112  Val_loss: -9292.3457 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.3099  Val_loss: -9286.2109 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.1776  Val_loss: -9176.2422 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.6282  Val_loss: -9140.2109 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -98.1072  Val_loss: -9049.1777 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "5\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 19.9991WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 19.9991  Val_loss: -1415.8368 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 10.3064WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.3064  Val_loss: -1907.8000 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 2.9064WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 2.9064  Val_loss: -2302.8257 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -8.0311WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -8.0311  Val_loss: -2628.3633 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -13.7392WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -13.7392  Val_loss: -2861.8499 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -23.0034WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -23.0034  Val_loss: -2969.6404 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -29.1316  Val_loss: -2961.7920 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -40.3039  Val_loss: -2832.6907 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -44.8474  Val_loss: -2540.9243 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -57.0597  Val_loss: -2101.7993 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -64.8562  Val_loss: -1566.4861 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -71.7331  Val_loss: -841.2020 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -80.9037  Val_loss: 3.7714 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -91.6309  Val_loss: 842.8779 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -98.7121  Val_loss: 1820.1803 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -108.4069  Val_loss: 2885.8555 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -120.7274  Val_loss: 4187.4614 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -127.9409  Val_loss: 5473.8960 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -135.9871  Val_loss: 6055.7803 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -147.4392  Val_loss: 6746.3672 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 7.5028  Val_loss: 1307.0892 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 6.5616  Val_loss: 1315.1190 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 6.0638  Val_loss: 1321.8798 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 5.3445  Val_loss: 1333.0640 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 5.2418  Val_loss: 1351.0571 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 5.1155  Val_loss: 1374.0137 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 3.1252  Val_loss: 1403.1755 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 3.4589  Val_loss: 1432.9285 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 1.5795  Val_loss: 1468.4600 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 1.4335  Val_loss: 1509.7184 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 1.9950  Val_loss: 1562.8073 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 0.6600  Val_loss: 1627.2767 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -0.1384  Val_loss: 1697.3324 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -0.7193  Val_loss: 1770.2238 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -1.3939  Val_loss: 1845.5410 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -1.5086  Val_loss: 1933.2289 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -3.4345  Val_loss: 2029.4973 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -3.1317  Val_loss: 2123.2363 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -4.3596  Val_loss: 2215.2268 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -4.1399  Val_loss: 2316.1672 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -4.9693  Val_loss: 2421.4763 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -6.8029  Val_loss: 2531.2751 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -6.7776  Val_loss: 2637.4448 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -7.2857  Val_loss: 2741.1831 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -8.0184  Val_loss: 2848.5430 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -8.6918  Val_loss: 2943.2693 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -9.0354  Val_loss: 3028.9753 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -10.1810  Val_loss: 3102.1965 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -11.3179  Val_loss: 3166.9717 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -11.3354  Val_loss: 3209.0461 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -11.6803  Val_loss: 3250.8962 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -13.6274  Val_loss: 3290.8774 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -13.6570  Val_loss: 3335.9573 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -14.4349  Val_loss: 3351.3975 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -15.2180  Val_loss: 3373.6636 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -16.3453  Val_loss: 3384.6211 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -16.4501  Val_loss: 3401.9160 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -17.8869  Val_loss: 3411.4421 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -19.0791  Val_loss: 3369.7869 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -19.7284  Val_loss: 3338.1616 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -19.9667  Val_loss: 3338.0039 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -21.0841  Val_loss: 3279.4336 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -21.7392  Val_loss: 3188.0190 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -22.9716  Val_loss: 3133.1462 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -24.3933  Val_loss: 3182.9985 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -26.2607  Val_loss: 3210.9485 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -26.3790  Val_loss: 3039.4702 \n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -28.5627  Val_loss: 2759.9360 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -28.4732  Val_loss: 2507.7693 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -30.3455  Val_loss: 2543.4270 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -31.4195  Val_loss: 2499.7834 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -33.2800  Val_loss: 2316.9104 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -34.4036  Val_loss: 2140.2881 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -36.1340  Val_loss: 2112.9448 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -37.0003  Val_loss: 1904.7554 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -38.0560  Val_loss: 1691.6952 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -40.3891  Val_loss: 1835.9924 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -41.3338  Val_loss: 1845.0769 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -42.7192  Val_loss: 1692.4806 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -45.2426  Val_loss: 1766.2596 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -46.5552  Val_loss: 1290.9816 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -49.7680  Val_loss: 1133.6024 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -50.9484  Val_loss: 782.4944 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -53.3329  Val_loss: 590.1703 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -55.5050  Val_loss: -245.0353 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -58.4619  Val_loss: -1461.4972 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -62.1524  Val_loss: -1548.6537 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -66.0316WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.0316  Val_loss: -3743.3962 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -68.8815WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -68.8815  Val_loss: -5261.5923 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -74.4730WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -74.4730  Val_loss: -6053.1406 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -79.9745WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.9745  Val_loss: -8203.7168 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -86.4338WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -86.4338  Val_loss: -8330.4697 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -88.9033WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.9033  Val_loss: -8582.8994 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -91.5405WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.5405  Val_loss: -9011.3096 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -93.3193WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.3193  Val_loss: -9143.6436 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -94.3085  Val_loss: -9091.1787 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -93.8920WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.8920  Val_loss: -9197.6230 \n",
      "Epoch 77/200\n",
      "96/99 [============================>.] - Loss for batch: -95.6271WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.6271  Val_loss: -9459.4482 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.3478  Val_loss: -8829.4648 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -95.6542  Val_loss: -8787.4648 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.7311  Val_loss: -9353.8604 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.2998  Val_loss: -9122.8574 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.4922  Val_loss: -9016.9297 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.9757  Val_loss: -8989.5059 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -97.2696  Val_loss: -9235.5059 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -95.8384  Val_loss: -9121.0664 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.7435  Val_loss: -9196.5908 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -99.3604  Val_loss: -9015.1055 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -96.8184  Val_loss: -9048.8350 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -96.0720  Val_loss: -9156.0137 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.5111  Val_loss: -9005.2188 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.2382  Val_loss: -8974.5117 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -96.9299  Val_loss: -9073.1387 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.9880  Val_loss: -8907.5557 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -96.3572  Val_loss: -9235.7793 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -96.7565  Val_loss: -9199.6543 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.7672  Val_loss: -9131.6611 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -98.0918  Val_loss: -9084.4902 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.1536  Val_loss: -9123.8965 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.7858  Val_loss: -9139.8457 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -96.7190  Val_loss: -9332.0059 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.5034  Val_loss: -9064.4150 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.5640  Val_loss: -8966.0889 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.9218  Val_loss: -9235.8486 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.9765  Val_loss: -9253.9580 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -97.5856  Val_loss: -8982.4023 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.6728  Val_loss: -8739.8809 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -96.1008  Val_loss: -9070.5625 \n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.8218  Val_loss: -8997.3643 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.2906  Val_loss: -9035.5635 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -96.5063  Val_loss: -9018.8350 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -95.7079  Val_loss: -8792.0635 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -97.6819  Val_loss: -8717.4678 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -96.8275  Val_loss: -8957.3486 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -97.9647  Val_loss: -9119.0195 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -98.9516  Val_loss: -9118.8936 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -97.8572  Val_loss: -9048.9404 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.3846  Val_loss: -9051.2070 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -95.6431  Val_loss: -8970.1787 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -98.7089  Val_loss: -9170.8613 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.6137  Val_loss: -9192.8213 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -97.5356  Val_loss: -8802.8721 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -97.4937  Val_loss: -8841.7676 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -99.5849  Val_loss: -8794.1963 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.2434  Val_loss: -8936.9189 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -96.2787  Val_loss: -9214.1289 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.3126  Val_loss: -8943.7246 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.6738  Val_loss: -8921.9688 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -97.4636  Val_loss: -8560.4209 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -98.4249  Val_loss: -8800.2666 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -99.4923  Val_loss: -9285.6709 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -95.9874  Val_loss: -9176.1973 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -97.8680  Val_loss: -9150.3730 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.0201  Val_loss: -8927.4023 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -97.3482  Val_loss: -8817.4873 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.8581  Val_loss: -8836.2588 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -98.0508  Val_loss: -8929.3398 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -98.5322  Val_loss: -9232.3770 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -96.4574  Val_loss: -9110.5498 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -98.5473  Val_loss: -8831.9766 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -96.1801  Val_loss: -8795.9697 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.9130  Val_loss: -8915.3008 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.1569  Val_loss: -8985.2422 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -98.6138  Val_loss: -9059.2227 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -97.0726  Val_loss: -9072.0293 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -99.5426  Val_loss: -9215.1543 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.9035  Val_loss: -9039.6650 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -100.3900  Val_loss: -9064.8545 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.3466  Val_loss: -9026.6094 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.6323  Val_loss: -9030.4287 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.8579  Val_loss: -8983.6094 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -99.0901  Val_loss: -8941.6523 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -95.8535  Val_loss: -9024.5049 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -98.3827  Val_loss: -9091.2822 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.2227  Val_loss: -8842.3447 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.7940  Val_loss: -8783.1982 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.1276  Val_loss: -8889.0449 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -96.7026  Val_loss: -8945.8174 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -97.9152  Val_loss: -8743.6621 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.2578  Val_loss: -9004.8076 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -98.4900  Val_loss: -9314.0889 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -97.8047  Val_loss: -9306.5205 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -97.7160  Val_loss: -8989.2451 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -98.4692  Val_loss: -8807.1729 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -97.9867  Val_loss: -9031.3594 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.2953  Val_loss: -9050.2705 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -97.9150  Val_loss: -8950.5957 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -96.6559  Val_loss: -8887.7900 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -95.3570  Val_loss: -8907.0088 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -99.8114  Val_loss: -9016.9199 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -97.3692  Val_loss: -9107.9473 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.5239  Val_loss: -9042.3115 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -96.7673  Val_loss: -8973.1162 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.4218  Val_loss: -8931.0059 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -96.1342  Val_loss: -8795.2852 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -97.8598  Val_loss: -8760.5049 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -97.8065  Val_loss: -8982.3213 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.4746  Val_loss: -8713.7793 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.0044  Val_loss: -8796.5400 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -95.9591  Val_loss: -9141.2764 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -97.2838  Val_loss: -9132.3008 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.6320  Val_loss: -8754.9170 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -97.9623  Val_loss: -8545.0625 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.7915  Val_loss: -8840.5703 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -96.8410  Val_loss: -8996.0908 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -97.1922  Val_loss: -9046.5107 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.2447  Val_loss: -9045.9941 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.4889  Val_loss: -9109.1602 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -96.8555  Val_loss: -8934.9727 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.8956  Val_loss: -8817.7920 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -97.1327  Val_loss: -8924.3848 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.7112  Val_loss: -8927.7656 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.6239  Val_loss: -8944.3076 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -96.6397  Val_loss: -8998.0029 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -98.0328  Val_loss: -8685.2119 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -96.9381  Val_loss: -8665.9844 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.5727  Val_loss: -9009.5312 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -96.3702  Val_loss: -9128.7939 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -96.5993  Val_loss: -8765.8291 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -96.6197  Val_loss: -8672.6416 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "6\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 23.3928WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 23.3928  Val_loss: 1122.4592 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 14.0135WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.0135  Val_loss: 616.9949 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 5.2789WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 5.2789  Val_loss: 112.6492 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -2.8073WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -2.8073  Val_loss: -407.6478 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -10.9339WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -10.9339  Val_loss: -926.8621 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -15.7037WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -15.7037  Val_loss: -1468.5339 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -22.4509WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -22.4509  Val_loss: -2065.5198 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -31.1807WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -31.1807  Val_loss: -2637.9958 \n",
      "Epoch 8/20\n",
      "96/99 [============================>.] - Loss for batch: -36.0642WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -36.0642  Val_loss: -3091.7949 \n",
      "Epoch 9/20\n",
      "96/99 [============================>.] - Loss for batch: -42.8571WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -42.8571  Val_loss: -3521.7048 \n",
      "Epoch 10/20\n",
      "96/99 [============================>.] - Loss for batch: -48.8338WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -48.8338  Val_loss: -3825.7109 \n",
      "Epoch 11/20\n",
      "96/99 [============================>.] - Loss for batch: -56.8298WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -56.8298  Val_loss: -3950.6948 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -69.1100  Val_loss: -3792.3081 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -72.4124  Val_loss: -3384.7578 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -83.3804  Val_loss: -2688.6211 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -90.9223  Val_loss: -1822.2705 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -96.3016  Val_loss: -856.2988 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -103.3546  Val_loss: -64.4482 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -113.6087  Val_loss: 418.9016 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -123.1753  Val_loss: 848.1423 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 9.7249  Val_loss: 1487.3318 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 8.9337  Val_loss: 1482.6422 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 8.2505  Val_loss: 1481.0270 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 8.1472  Val_loss: 1477.7822 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 7.8492  Val_loss: 1476.6235 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 7.1616  Val_loss: 1473.4108 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 6.1933  Val_loss: 1466.3347 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 5.5700  Val_loss: 1465.5336 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 4.8950  Val_loss: 1466.4169 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 4.3324  Val_loss: 1469.2999 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 4.4247  Val_loss: 1474.1394 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 3.4718  Val_loss: 1479.1854 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 3.0698  Val_loss: 1477.6202 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 2.3934  Val_loss: 1472.3783 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: 1.7586  Val_loss: 1459.5015 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: 1.1650  Val_loss: 1431.8250 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: 0.6165  Val_loss: 1402.5254 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -0.4145  Val_loss: 1376.6483 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -0.3695  Val_loss: 1337.2688 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -1.4151  Val_loss: 1295.0939 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -1.9369  Val_loss: 1254.8396 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -3.2723  Val_loss: 1228.8994 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -3.6711  Val_loss: 1200.6364 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -4.1392  Val_loss: 1179.5831 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -5.1461  Val_loss: 1166.6659 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -5.7903  Val_loss: 1169.1665 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -6.9952  Val_loss: 1164.3204 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -7.3526  Val_loss: 1132.0319 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -7.4248  Val_loss: 1061.5640 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -8.3146  Val_loss: 988.2321 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -8.3617  Val_loss: 931.3812 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -10.5598  Val_loss: 876.2018 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -10.9772  Val_loss: 818.4793 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -11.6698  Val_loss: 760.8694 \n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -11.9199  Val_loss: 684.2039 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -13.2667  Val_loss: 602.1724 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -14.0867  Val_loss: 522.8920 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -15.2056  Val_loss: 407.9709 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -16.5350  Val_loss: 362.6385 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -17.9143  Val_loss: 289.8580 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -18.1868  Val_loss: 175.3122 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -18.8723  Val_loss: 32.4297 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -20.6414  Val_loss: -88.4115 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -21.7627  Val_loss: -130.4927 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -21.9676  Val_loss: -216.3375 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -23.5449  Val_loss: -321.5902 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -25.3647  Val_loss: -406.6416 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -26.2845  Val_loss: -507.3013 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -26.9313  Val_loss: -648.2332 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -27.9328  Val_loss: -835.4833 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -29.7493  Val_loss: -897.3796 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -30.9177  Val_loss: -901.0160 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -32.7164  Val_loss: -968.3266 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -34.1959  Val_loss: -1001.0337 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -35.8653  Val_loss: -1114.4449 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -37.6518  Val_loss: -1412.9565 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -39.4038  Val_loss: -1319.4381 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -41.2653  Val_loss: -1438.9182 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -43.8247  Val_loss: -1523.2496 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -45.0774  Val_loss: -1830.8148 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -47.4785  Val_loss: -1367.9495 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -50.5404  Val_loss: -1581.8215 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -52.6359  Val_loss: -2430.3557 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -56.9487  Val_loss: -2198.3591 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -60.0988  Val_loss: -3483.8091 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -63.3462WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -63.3462  Val_loss: -4843.3872 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -68.6004WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -68.6004  Val_loss: -6145.4702 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -72.9881WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -72.9881  Val_loss: -6892.3423 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -76.7660WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -76.7660  Val_loss: -7881.6362 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -83.1512WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -83.1512  Val_loss: -8542.9619 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -87.1340WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.1340  Val_loss: -8830.2656 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -92.1809WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.1809  Val_loss: -9058.4531 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -93.3995WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.3995  Val_loss: -9274.5723 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -95.5671  Val_loss: -9263.5996 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -95.3203  Val_loss: -9261.9775 \n",
      "Epoch 75/200\n",
      "96/99 [============================>.] - Loss for batch: -96.4364WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.4364  Val_loss: -9342.6367 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -97.1638WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.1638  Val_loss: -9376.1455 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.2364  Val_loss: -9354.4365 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.9283  Val_loss: -9258.9590 \n",
      "Epoch 79/200\n",
      "96/99 [============================>.] - Loss for batch: -98.0698WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -98.0698  Val_loss: -9399.2891 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.7429  Val_loss: -9312.5020 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.6669  Val_loss: -9379.2734 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.8157  Val_loss: -9258.5293 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -95.5448  Val_loss: -9313.5000 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.7303  Val_loss: -9378.5029 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.3945  Val_loss: -9079.6943 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.8149  Val_loss: -9237.3682 \n",
      "Epoch 87/200\n",
      "96/99 [============================>.] - Loss for batch: -97.5882WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.5882  Val_loss: -9458.8350 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.7714  Val_loss: -9374.2002 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.4218  Val_loss: -9232.4209 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.8341  Val_loss: -9454.6338 \n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -97.4259  Val_loss: -9368.4951 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.8042  Val_loss: -9317.4521 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -96.2653  Val_loss: -9315.2549 \n",
      "Epoch 94/200\n",
      "96/99 [============================>.] - Loss for batch: -97.9705WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.9705  Val_loss: -9522.1357 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.6784  Val_loss: -9369.3096 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -96.0852  Val_loss: -9361.1172 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.9405  Val_loss: -9280.2764 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -95.0875  Val_loss: -9323.8135 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.9021  Val_loss: -9403.7969 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -96.2661  Val_loss: -9289.8242 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -96.4926  Val_loss: -9217.4463 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.2315  Val_loss: -9361.5986 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -94.4119  Val_loss: -9314.9355 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.4950  Val_loss: -9233.0938 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.1276  Val_loss: -9176.8193 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -95.4914  Val_loss: -9355.5703 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -96.6320  Val_loss: -9368.3350 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -97.2170  Val_loss: -9302.8438 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -96.9404  Val_loss: -9241.7598 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -97.9292  Val_loss: -9400.3564 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.4820  Val_loss: -9292.1670 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -96.9187  Val_loss: -9185.2041 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -97.9462  Val_loss: -9418.7100 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -95.6418  Val_loss: -9345.7393 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.2827  Val_loss: -9262.8936 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -97.1125  Val_loss: -9326.3350 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.5838  Val_loss: -9448.7363 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -96.2511  Val_loss: -9259.3398 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -97.3610  Val_loss: -9153.4971 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -98.7221  Val_loss: -9239.3281 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -97.3684  Val_loss: -9231.9287 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -96.7353  Val_loss: -9356.1406 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.1007  Val_loss: -9476.0986 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -98.2682  Val_loss: -9426.1602 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -97.9353  Val_loss: -9318.2207 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.3505  Val_loss: -9358.4580 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.4070  Val_loss: -9326.1260 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.6451  Val_loss: -9207.9746 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -96.3085  Val_loss: -9433.7598 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -96.0569  Val_loss: -9308.0029 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -97.2000  Val_loss: -9397.1523 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.4406  Val_loss: -9381.7891 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -96.7450  Val_loss: -9413.9082 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.4428  Val_loss: -9404.0820 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -99.9980  Val_loss: -9286.5449 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -96.8223  Val_loss: -9483.1240 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -96.6041  Val_loss: -9367.7598 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -98.2919  Val_loss: -9284.1758 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -96.9582  Val_loss: -9276.7578 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -98.4085  Val_loss: -9447.6260 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.0537  Val_loss: -9344.0439 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.1412  Val_loss: -9292.0176 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -96.5477  Val_loss: -9447.7881 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -96.7457  Val_loss: -9267.6396 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -97.9859  Val_loss: -9301.7432 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -96.2378  Val_loss: -9254.7275 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -97.4008  Val_loss: -9327.5527 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.9539  Val_loss: -9356.1768 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.4185  Val_loss: -9284.3486 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -95.1323  Val_loss: -9375.2100 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.1622  Val_loss: -9224.7383 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -97.0398  Val_loss: -9293.2227 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -97.9744  Val_loss: -9262.7861 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -97.4448  Val_loss: -9351.5215 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.6127  Val_loss: -9272.2441 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.6720  Val_loss: -9354.6367 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -97.2269  Val_loss: -9214.3984 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -97.4078  Val_loss: -9284.2695 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -97.3541  Val_loss: -9167.5938 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -98.5726  Val_loss: -9327.5664 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.1352  Val_loss: -9444.5986 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.6011  Val_loss: -9236.1777 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.6197  Val_loss: -9227.9492 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -96.8029  Val_loss: -9381.2607 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.3619  Val_loss: -9368.8105 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.4714  Val_loss: -9414.0264 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -96.0893  Val_loss: -9466.5352 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.0322  Val_loss: -9234.6006 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -95.1664  Val_loss: -9273.1904 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -95.3054  Val_loss: -9322.7549 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.6007  Val_loss: -9224.3809 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.0610  Val_loss: -9318.3564 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.5762  Val_loss: -9381.2988 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -98.1448  Val_loss: -9437.6797 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -96.5549  Val_loss: -9418.0615 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.6021  Val_loss: -9253.0469 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -97.1003  Val_loss: -9195.4395 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -97.2562  Val_loss: -9432.5518 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.1162  Val_loss: -9459.2725 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -96.4138  Val_loss: -9033.2256 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -97.2330  Val_loss: -9307.7891 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -98.6894  Val_loss: -9336.6885 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -98.5603  Val_loss: -9454.8672 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -96.8687  Val_loss: -9495.7461 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -99.4871  Val_loss: -9214.7861 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -96.9968  Val_loss: -9317.3398 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.1244  Val_loss: -9350.9111 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -97.7511  Val_loss: -9380.7939 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.1454  Val_loss: -9252.5225 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -97.2297  Val_loss: -9288.9766 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -96.9353  Val_loss: -9364.6377 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -97.4533  Val_loss: -9314.2617 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.6426  Val_loss: -9293.4912 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -96.9428  Val_loss: -9260.2754 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.1434  Val_loss: -9480.6533 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -96.3640  Val_loss: -9369.0117 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -99.9576  Val_loss: -9345.3350 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.5121  Val_loss: -9412.3047 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -97.7150  Val_loss: -9430.1816 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "7\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 30.7145WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 30.7145  Val_loss: -737.6293 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 27.1883WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 27.1883  Val_loss: -1249.7317 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 18.1617WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 18.1617  Val_loss: -1693.0469 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: 7.7022WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 7.7022  Val_loss: -2060.1528 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -2.6778WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -2.6778  Val_loss: -2328.3618 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -9.0234WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -9.0234  Val_loss: -2487.3262 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -16.1238WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -16.1238  Val_loss: -2564.8474 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -27.1429  Val_loss: -2562.7163 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -34.8812  Val_loss: -2489.3057 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -41.8169  Val_loss: -2342.4998 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -48.8548  Val_loss: -2183.1663 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -61.3113  Val_loss: -2100.5229 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -67.7486  Val_loss: -2004.9269 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -73.4502  Val_loss: -1941.5524 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -83.6973  Val_loss: -1748.2469 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -91.3188  Val_loss: -1511.5032 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -104.9211  Val_loss: -1130.7108 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -109.4835  Val_loss: -848.5697 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -123.4792  Val_loss: -444.1601 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -128.1862  Val_loss: -220.8157 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 7.6927  Val_loss: 1140.4006 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 8.5399  Val_loss: 1105.5503 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 6.4061  Val_loss: 1073.4745 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 6.0638  Val_loss: 1042.6060 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 6.1513  Val_loss: 1011.1178 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 5.2050  Val_loss: 977.4038 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 4.8894  Val_loss: 943.2438 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 4.2961  Val_loss: 905.0467 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 3.7824  Val_loss: 874.6229 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 3.2404  Val_loss: 848.0735 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 2.0746  Val_loss: 823.6132 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 1.9325  Val_loss: 798.8017 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 0.9627  Val_loss: 769.4465 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -0.1779  Val_loss: 739.7452 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: 0.0804  Val_loss: 710.3370 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -0.0665  Val_loss: 675.5490 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -1.5117  Val_loss: 648.7279 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -2.4167  Val_loss: 612.1955 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -2.5998  Val_loss: 576.9405 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -3.0155  Val_loss: 533.5629 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -3.2964  Val_loss: 492.6485 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -4.8405  Val_loss: 461.5736 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -5.2719  Val_loss: 419.5528 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -5.7003  Val_loss: 375.1488 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -6.2824  Val_loss: 336.7986 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -7.9313  Val_loss: 309.4587 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -7.9927  Val_loss: 285.7931 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -8.1854  Val_loss: 260.5273 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -9.9436  Val_loss: 246.3560 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -10.2770  Val_loss: 229.5689 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -11.7514  Val_loss: 184.2318 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -11.3224  Val_loss: 135.5677 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -12.1297  Val_loss: 80.0967 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -13.7654  Val_loss: 3.9754 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -14.5262  Val_loss: -69.8098 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -15.0822  Val_loss: -134.6498 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -16.8469  Val_loss: -200.9649 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -16.6766  Val_loss: -258.4670 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -17.6548  Val_loss: -314.0448 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -18.9772  Val_loss: -343.5142 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -18.3456  Val_loss: -409.9829 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -20.4947  Val_loss: -512.8859 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -21.6705  Val_loss: -648.5257 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -22.4892  Val_loss: -783.7507 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -23.9896  Val_loss: -915.4917 \n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -24.7682  Val_loss: -1025.8600 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -26.3574  Val_loss: -1182.4171 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -27.5814  Val_loss: -1382.0382 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -28.5595  Val_loss: -1543.5486 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -30.5029  Val_loss: -1713.9617 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -31.6088  Val_loss: -1902.1154 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -32.3119  Val_loss: -2121.9565 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -33.9338  Val_loss: -2253.6858 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -35.2432  Val_loss: -2335.9128 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -37.7393  Val_loss: -2505.0332 \n",
      "Epoch 55/200\n",
      "96/99 [============================>.] - Loss for batch: -39.1198WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -39.1198  Val_loss: -2683.6328 \n",
      "Epoch 56/200\n",
      "96/99 [============================>.] - Loss for batch: -40.2495WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -40.2495  Val_loss: -2869.8440 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -42.0940WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -42.0940  Val_loss: -3083.0212 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -45.0160WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -45.0160  Val_loss: -3552.1831 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -45.7035WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -45.7035  Val_loss: -3822.2197 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -48.3039WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -48.3039  Val_loss: -3979.7891 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -50.8779WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -50.8779  Val_loss: -4052.1758 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -53.2672WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -53.2672  Val_loss: -4527.3306 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -56.3671WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -56.3671  Val_loss: -5116.2329 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -59.0136WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.0136  Val_loss: -5845.7334 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -62.6090WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.6090  Val_loss: -6342.9438 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -66.9115WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.9115  Val_loss: -7137.4971 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -72.2812WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -72.2812  Val_loss: -8043.0391 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -77.4280WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -77.4280  Val_loss: -8312.1338 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -83.9026WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -83.9026  Val_loss: -9096.4688 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -90.3052WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -90.3052  Val_loss: -9292.9648 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -92.3635  Val_loss: -9121.9131 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -95.3261WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.3261  Val_loss: -9303.2969 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -92.9508  Val_loss: -9268.0918 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -94.7448  Val_loss: -8922.6279 \n",
      "Epoch 75/200\n",
      "96/99 [============================>.] - Loss for batch: -94.6598WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.6598  Val_loss: -9325.7432 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -95.0794WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.0794  Val_loss: -9379.3594 \n",
      "Epoch 77/200\n",
      "96/99 [============================>.] - Loss for batch: -97.0976WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.0976  Val_loss: -9426.0908 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -95.9498  Val_loss: -9365.0654 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.2554  Val_loss: -9346.4023 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.4958  Val_loss: -9329.0420 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.5035  Val_loss: -9242.3086 \n",
      "Epoch 82/200\n",
      "96/99 [============================>.] - Loss for batch: -97.1283WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.1283  Val_loss: -9453.1436 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.2455  Val_loss: -9288.9053 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.3923  Val_loss: -8735.8193 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.4313  Val_loss: -8803.0693 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.2291  Val_loss: -9082.3555 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.7315  Val_loss: -9033.2549 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.5683  Val_loss: -8982.4375 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -96.7623  Val_loss: -9124.4326 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.7937  Val_loss: -9156.4189 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -94.8800  Val_loss: -8894.9639 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.9071  Val_loss: -9272.0947 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.2885  Val_loss: -8967.0811 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.1091  Val_loss: -8460.3037 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.9667  Val_loss: -8797.4707 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -95.8602  Val_loss: -8801.0918 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.9844  Val_loss: -8977.7246 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -97.0229  Val_loss: -9096.6533 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.1537  Val_loss: -8949.0566 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.8262  Val_loss: -9290.7031 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -98.7905  Val_loss: -9407.8799 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.1322  Val_loss: -9115.6104 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.3697  Val_loss: -9165.1855 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.5654  Val_loss: -9051.9219 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -96.0176  Val_loss: -8581.4775 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.0618  Val_loss: -8697.5420 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.4376  Val_loss: -9129.2490 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -97.1428  Val_loss: -9058.5342 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.4264  Val_loss: -8910.4619 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.1326  Val_loss: -9148.0742 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -97.9709  Val_loss: -9337.7881 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -96.6403  Val_loss: -8833.0898 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -97.7670  Val_loss: -8213.2637 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -97.1643  Val_loss: -8803.5225 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.7502  Val_loss: -9077.9531 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.3892  Val_loss: -9176.3545 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -98.7271  Val_loss: -9067.0000 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -97.6133  Val_loss: -8718.2168 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -96.2203  Val_loss: -8725.2451 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.3884  Val_loss: -9016.1396 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.1743  Val_loss: -9081.9346 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -97.1328  Val_loss: -9061.7363 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.9531  Val_loss: -9083.8672 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.9887  Val_loss: -9054.1670 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.7434  Val_loss: -9096.9248 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -98.4056  Val_loss: -9109.4092 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.3869  Val_loss: -8992.9141 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -96.9955  Val_loss: -8934.6514 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -96.2519  Val_loss: -8780.6738 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -97.2958  Val_loss: -8804.0459 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.2025  Val_loss: -9125.3535 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -98.1614  Val_loss: -9100.9688 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.6923  Val_loss: -8834.2539 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -96.6195  Val_loss: -8761.5791 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.4129  Val_loss: -8635.4043 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -96.4474  Val_loss: -8706.5312 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.6518  Val_loss: -8958.7246 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.3643  Val_loss: -9063.8018 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -95.8532  Val_loss: -8991.8467 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.2186  Val_loss: -8973.3643 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.0182  Val_loss: -8715.6113 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.1453  Val_loss: -8795.6455 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -98.4067  Val_loss: -8968.7324 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -99.5570  Val_loss: -8856.0605 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -97.5854  Val_loss: -8562.1436 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -97.5397  Val_loss: -8624.7168 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -96.5805  Val_loss: -8824.7383 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -96.8335  Val_loss: -8812.2402 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.5678  Val_loss: -8643.4688 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.0129  Val_loss: -8608.6670 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.4923  Val_loss: -8911.3984 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -98.4454  Val_loss: -8926.7100 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -98.1569  Val_loss: -8917.8311 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.1815  Val_loss: -9125.9238 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -98.5134  Val_loss: -9004.9941 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -98.7437  Val_loss: -8943.5938 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -96.5859  Val_loss: -8933.6338 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.2389  Val_loss: -9024.4668 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.1383  Val_loss: -8930.0410 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.7074  Val_loss: -8759.4951 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -97.5993  Val_loss: -8909.8418 \n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.1118  Val_loss: -8611.2539 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -96.5940  Val_loss: -8678.9580 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.7644  Val_loss: -8996.0029 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -99.4134  Val_loss: -9372.5078 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.0096  Val_loss: -9336.7207 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -97.0548  Val_loss: -9016.7246 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -97.2250  Val_loss: -8706.5859 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -96.4127  Val_loss: -8785.6777 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -98.9972  Val_loss: -9011.3203 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -96.8576  Val_loss: -8857.1621 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.2346  Val_loss: -8724.2012 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -95.4438  Val_loss: -8641.2119 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -96.1659  Val_loss: -8523.7422 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -97.0236  Val_loss: -8734.6279 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -97.4861  Val_loss: -9041.5400 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -97.6576  Val_loss: -9100.8760 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -96.5597  Val_loss: -8954.5000 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.5550  Val_loss: -8964.8809 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -96.8977  Val_loss: -8879.0859 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -97.5413  Val_loss: -8709.7256 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -98.8787  Val_loss: -8851.0049 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -98.2384  Val_loss: -9001.6846 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -97.5001  Val_loss: -8949.5078 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -97.3224  Val_loss: -8454.5742 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.3386  Val_loss: -8760.4619 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.3448  Val_loss: -8877.5557 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.3293  Val_loss: -9017.9932 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -98.1893  Val_loss: -9065.1631 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -97.8556  Val_loss: -8797.1025 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.0025  Val_loss: -8878.7217 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -97.0684  Val_loss: -8638.2793 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -97.6743  Val_loss: -8709.6865 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.5561  Val_loss: -9055.1689 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -97.6552  Val_loss: -8955.7383 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -97.0159  Val_loss: -8320.6250 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.5654  Val_loss: -7986.7690 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -97.8444  Val_loss: -8862.9189 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -98.5972  Val_loss: -9235.5049 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyyElEQVR4nO3dd3hc5Zn38e89o967LKtYsuTejdzpEGwIYEI1kFBSTN2QTbIsZUM2m/AmZCEECLCB0EMAhx4SmjFgbFyQe5dkSbZ6712a5/1jRrJkSy4aSSPN3J/r0sXomTmjew7j+c1TzjlijEEppZTqYnF1AUoppUYWDQallFK9aDAopZTqRYNBKaVULxoMSimlevFydQHOioqKMsnJya4uQymlRpUtW7ZUGGOi+7pv1AdDcnIyGRkZri5DKaVGFRE51N99OpSklFKqFw0GpZRSvWgwKKWU6kWDQSmlVC8aDEoppXrRYFBKKdWLBoNSSqleNBiGyYGSet7dVkhLe6erS1FKqeMa9Qe4jRaPfZbJv3aVEPmBD99dOI7vLRpHVJCvq8tSSqljaI9hmNQ2t5MUEcDsxDAe+yyLxb9dw89W7WB3Ya2rS1NKqV60xzBMGlo6SIkK5Lmb5pFd1sDLG/J4c0sBb20tYF5yODcvSWHptDFYLeLqUpVSHk57DMOkvrWDID97DqfFBPE/y6ez8b7z+MXFUymta+X2V7dy7iNf8MrGQzoPoZRyKQ2GYdLQ0kGwb+8OWoifNz84PYXPf342//fduYQF+PCLd3ez5Hdr+MOnmeRXNbmoWqWUJ9OhpGHS0NpBkG/fu9tqEZZNj2PptDFszq3i/748yOOfZfH4Z1nMT4ngirnxXDgjjhA/72GuWinliTQYhkGnzdDU1tk9lNQfEWHB+EgWjI+koLqJ97YX8daWAv7zrV088N4eLpg2hsvnxnNGWhReVu3sKaWGhgbDMGho7QDot8fQl4TwAO44J43bz05lR0Etb28t4P0dRfxjRxFRQb5cNnssNyxKJikyYKjKVkp5KA2GYdAVDMEn6DH0RUSYnRjG7MQw/uvbU/n8QBlvby3gpQ15PL8+l/OnxHLlaQmcPyUWi65oUkoNAg2GYdDQ0tVjcG6OwMfLwtJpY1g6bQwltS28sD6Xt7YW8sneUiaPCeZnF0zi/CkxiGhAKKUGTgeqh0FDazvACecYTsWYUD/uvWgKG+89l8dWzKa1w8aPXs7gsifXszazHGPMoP0tpZRn0WAYBvUtpz7HcLK8rBaWz47n038/k99fMZOKhjZueH4z1/9lE9/kVWlAKKVOmQbDMHBmjuFkeVktXD0vkTU/P4tfXjKVfcV1XPV/G7jkT+v4Kqt8yP6uUsr9aDAMg4Yh7DEczdfLys1LUlj3n+fy/74zg5qmdr733GZufmEzWaX1Q/73lVKjnwbDMOherjqEPYajBfp6cd2CJFb/9Czuu2gyGYeqWfrHtdz79i52F9bqEJNSql+6KmkYdM0xBPoM/+7287ay8sxUrjwtkcc/y+LVTYd4bfNhkiMDuGTWWC6eOZaJsUG6kkkp1U2DYRg0tHYQ6GN16ZlTIwJ9+O9Lp3HXeRP4eE8J/9hZxJOfZ/PEmmzCA7yZmRDGvORwblicrKfeUMrDaTAMg4aWjmEdRjqe8EAfVsxPYsX8JMrrW/lsXynbDtewo6CGRz7N5JWNh/jVpdNZNn2Mq0tVSrnIiJtjEJFlInJARLJF5B5X1zMYjncCPVeKDvZlxfwkHrpyJh/95EzevX0JEYG+3PrXLdzySgbVjW2uLlEp5QIjKhhExAo8CVwITAWuFZGprq3KefZrMYz84ZlZiWG8f+cS7rlwMmv2l3HR41+xv6TO1WUppYbZiAoGYD6QbYzJMca0Aa8Dy11ck9MaWtqPuRbDSOVttXDrWam8ddtijIHrnt3EgRJd5qqUJxlpwRAP5Pf4vcDRNqqN1KGk45mZEMZrKxfibRWue3ajhoNSHmSkBUNfy3aOWXAvIitFJENEMsrLR/5RvSNp8vlUpEQF8tqPFmK12MNh2+FqV5eklBoGIy0YCoDEHr8nAEVHP8gY84wxJt0Ykx4dHT1sxQ1U/SjsMXQZHx3E6ysXEuBr5ZpnNvKPHcf871BKuZmRFgzfABNEJEVEfIAVwPsurskpxhgaWjuG9DxJQ218dBDv3r6EWQmh/Ntr23hsdZYeOa2UGxtRwWCM6QDuBD4G9gGrjDF7XFuVc6oa2zBmaE+gNxwig3z56w8XcPmceB5dnclP3thOS3unq8tSSg2BEfdpZYz5F/AvV9cxWD7bXwbAwvGRLq7Eeb5eVh65ehapMUH878cHOFBSz/9eOYsZCaGuLk0pNYhGVI/BHf1zZzEJ4f7MiHePD08R4Y5z0njx5nmU1bdyyZ/WceXTX1Nc2+zq0pRSg0SDYQjVNLWxPruCb8+Ic7uT1J09KYbPf3Y2v7xkKvtL6rn8qa/JKW9wdVlKqUGgwTCEVu8ro8NmuGhGnKtLGRKhAd7cvCSFN25ZSGuHjdtf3arzDkq5AQ2GIbQ9v5pgXy+3GUbqz7SxoTx81Uz2l9Tz0Ef7XV2OUspJGgxDaF9xPZPjgrG48HTbw+XcybF8d2ESL32dR6ZeKU6pUU2DYYjYbIb9xXVMiQtxdSnD5mffmkSgrxe//dc+V5eilHKCBsMQya9uorGt06OCITzQh387N43PD5SzLqvC1eUopQbIY4Nhe34NT3w2dEfw7iu2n656qgcFA8ANi5JJCPfnwX/to9OmR0crNRp5bDBsOVTNI59mUt3UPiTPv7e4HovApDHBQ/L8I5Wft5W7l01mX3Ed72wrdHU5SqkB8NhgSIkKACC3YmjW3u8rriMlKhA/b+uQPP9IdsnMOGYlhvHwxwdobtPlq0qNNh4bDMmRgQDkVjQN+nMbY9hZUMO0se69TLU/IsL9F02hpK6F59bluLocpdQp8thgSIwIwGoR8ioaB/25D5Y3UFrXyuLU0X9+pIGanxLB0mmxPPXFQfKrBj98lVJDx2ODwdtqITHcn9whCIauFTlL0qIG/blHk19cPBWLCHe/uRObTkQrNWp4bDAAJEcFDkkwrD9YSVJEAIkRAYP+3KNJQngA//XtKWzIqeStrQWuLkcpdZI8OxgiA8mrbBzUJasdnTY2HqxkSZrnDiP1dM28RKaNDeHpLw7q8lWlRgmPDoaUqECa2jopq28dtOfcU1RHfWsHi1M9exipi4hw+9lp5FQ08tHuEleXo5Q6CR4fDMCgDiftLKwFYE5S2KA952i3bPoYxkcF8sxXukJJqdFAg4HBDYY9hbWEBXgTH+Y/aM852lktwnULktiRX0N2mZ5gT6mRzqODYWyYP75eFrLLBu8gt91FtUwfG+p2F+Zx1vLZ8Vgtwptb9GhopUY6jw4Gq0VIiwkatNNEt3XYOFBSz7R4zzo/0smIDvbl7InRvLOtQCehlRrhPDoYACbGBpNVOjg9hszSeto7jdtfmGegrkpPoLSuldX7Sl1dilLqODw+GCbEBlFS10Jts/Mn09tTZJ94nu6hp8I4kfOnxJIQ7s9fdBJaqRHN44NhUqz97KeDMSm6Pb+WYF8vkjz8wLb+eFktfH9JCt/kVbM9v8bV5Sil+uHxwTDREQyZTg4n2WyGz/eXsSg10iMu5TlQV89LJNjPi2e116DUiOXxwRAf5o+/t9XpCehdhbWU1LWwdNqYQarMPQX5enHd/CQ+3FWsJ9dTaoTy+GCwWIQJsUFOT0B/srcEq0U4b0rMIFXmvm5akoxFhBfW57m6FKVUHzw+GMA+z7CvuM6pcyZ9vKeUBSkRhAX4DGJl7iku1J+LZ8axKiOfxtYOV5ejlDqKBgMwMyGUysY2impbBrT97sJasssauHBG3CBX5r6+t2gcDa0dfLCzyNWlKKWOosEAzEgIA2BXQc2Atl+VkY+Pl4VLZ44dvKLc3NykcCbEBPHa5nxXl6KUOopTwSAi/ysi+0Vkp4i8IyJhPe67V0SyReSAiCzt0X6aiOxy3Pe4OM4dISK+IvKGo32TiCQ7U9upmDwmGC+LsLOg9pS3bWnv5N1thVw4fQyhAd5DUJ17EhGunZ/E9vwa9hXXubocpVQPzvYYPgWmG2NmApnAvQAiMhVYAUwDlgFPiYjVsc3TwEpgguNnmaP9B0C1MSYNeBR4yMnaTpqft5VJY4LZVXhqwWCM4dHVmdS1dHBNeuIQVee+vjMnHi+L8N52HU5SaiRxKhiMMZ8YY7pmDzcCCY7by4HXjTGtxphcIBuYLyJxQIgxZoOxz/S+DFzWY5uXHLffBM6TYTwT3cyEUHYW1J70BLQxhnve2sWfv8zh6vQEFnnw9Z0HKjzQhyVpUXyws2hQL5aklHLOYM4xfB/40HE7Hug5eFzgaIt33D66vdc2jrCpBfr8tBWRlSKSISIZ5eXlg1L8jPgwapvbOXySa+tf+jqPNzLyuf3sVB66YqaeTXWALp4ZR0F1MzsGMIynlBoaJwwGEVktIrv7+Fne4zH3Ax3Aq11NfTyVOU778bY5ttGYZ4wx6caY9Ojo6BO9hJOSnhwOwIaDlSd87LqsCn7zz32cPyWGn18wSUPBCRdMG4O3VfjHDh1OUmqkOGEwGGPON8ZM7+PnPQARuRG4GLjeHBkPKAB6DronAEWO9oQ+2nttIyJeQChQNfCXdmomxAQxJsSPtVnH74HsLarjllcySI0O4pGrZ+vpL5wU6u/NBdPG8Nrmw5TVD2y5sFJqcDm7KmkZ8J/ApcaYnmMw7wMrHCuNUrBPMm82xhQD9SKy0DF/cAPwXo9tbnTcvhJYY4Zx4FlEOGNCFOuyKujotPX5GGMMD7y3mwBfL176/nxC/XUV0mD4jwsm0d5p45GPM11dilIK5+cY/gQEA5+KyHYR+T8AY8weYBWwF/gIuMMY0+nY5jbgL9gnpA9yZF7iOSBSRLKBnwL3OFnbKTtzYjR1LR39jndvzKki41A1d56TxphQv2Guzn0lRwVy46JkVm3J56PdJa4uRymP5+XMxo6lpf3d9yDwYB/tGcD0PtpbgKucqcdZp6dFIQJfHCjjtHHhx9z/xJosooN9uWaeLk0dbD+9YCJbDlfz49e38frKhcxNOnb/K6WGhx753EN4oA+np0Xx+jf5tLR39rpvy6Eqvj5YycozxuPnbe3nGdRABfh48fyN8wgP8OYPn+iQklKupMFwlFvPSqW8vpV3tvW+aP0Ta7IJD/Dm+oVJLqrM/YUH+nDDomTWZVeQNUjX4VZKnToNhqMsTo1kZkIoT32R3X25z6+zK/jiQDk/PGM8AT5Ojb6pE7h2fhI+XhZe2pDn6lKU8lgaDEcREe69cAoltS3c9MJmnluXyw9fzmB8dCA3LBrn6vLcXkSgD8tnjeXtrYWDch1updSp02Dow6LUSJ64di67C2v59Qd7SQj35/UfLSTYT5enDocbFyfT1NbJ3zP0zKtKuYKOi/Rj2fQxZNz/LZraO4gO8sXLqhk6XKbHhzIvOZyXNxzi5iUpWPUgQqWGlX7aHUdogDdxof4aCi5w0+IUDlc18WVmmatLUcrj6CeeGpEumBZLVJAvf9t02NWlKOVxNBjUiORttXB1egJr9pdRXNvs6nKU8igaDGrEunZ+EjYDb3yjk9BKDScNBjViJUYEsCQtkne2FeqFfJQaRhoMakRbPiueQ5VNeiEfpYaRBoMa0ZZOH4OP1cL7el1opYaNBoMa0UL9vTlncjT/2FmEzabDSUoNBw0GNeKdOzmG8vpW8qtP7nrcSinnaDCoES8tJhiAg+UNLq5EKc+gwaBGvLToIACyyzQYlBoOGgxqxAsN8CYqyFeDQalhosGgRoW0mEAOlje6ugylPIIGgxoVUqODyC5r0APdlBoGGgxqVEiLCaK2uZ2KhjZXl6KU29NgUKNCqmMCWlcmKTX0NBjUqJAWYw+GrNJ6F1eilPvTYFCjQlyoH2NC/NiYU+XqUpRyexoMalQQEc6YEMW67Ao69dQYSg0pDQY1apw5MZra5nZ2FNS4uhSl3JoGgxo1Tk+LQgS+yqxwdSlKuTUNBjVqhAf6MDM+lDX7S11dilJubVCCQUR+LiJGRKJ6tN0rItkickBElvZoP01Edjnue1xExNHuKyJvONo3iUjyYNSm3Mvy2fHsKKhlyyGdhFZqqDgdDCKSCHwLONyjbSqwApgGLAOeEhGr4+6ngZXABMfPMkf7D4BqY0wa8CjwkLO1KfezYn4i4QHePPX5QVeXopTbGowew6PA3UDPpSLLgdeNMa3GmFwgG5gvInFAiDFmg7Gf2+Bl4LIe27zkuP0mcF5Xb0KpLgE+Xty0OIXP9pexeq8OKSk1FJwKBhG5FCg0xuw46q54IL/H7wWOtnjH7aPbe21jjOkAaoHIfv7uShHJEJGM8vJyZ16CGoW+f3oyM+JDue3VLazN1P//Sg22EwaDiKwWkd19/CwH7gce6GuzPtrMcdqPt82xjcY8Y4xJN8akR0dHn+glKDcT7OfNX3+4gKggX/668ZCry1HK7Xid6AHGmPP7aheRGUAKsMMx4pMAbBWR+dh7Aok9Hp4AFDnaE/pop8c2BSLiBYQCOsOo+hTq783MhFA9FbdSQ2DAQ0nGmF3GmBhjTLIxJhn7B/tcY0wJ8D6wwrHSKAX7JPNmY0wxUC8iCx3zBzcA7zme8n3gRsftK4E1Rs+xrI4jNTqIQ5WNtHfaXF2KUm7lhD2GgTDG7BGRVcBeoAO4wxjT6bj7NuBFwB/40PED8BzwiohkY+8prBiK2pT7SI0Oor3TcLiqqfvsq0op5w1aMDh6DT1/fxB4sI/HZQDT+2hvAa4arHqU+0t1nHH1YFmDBoNSg0iPfFaj1vjoQACdZ1BqkGkwqFErxM+bmGBfvXiPUoNMg0GNaqnRQRoMSg0yDQY1qqXGBJJd1oAuYFNq8GgwqFEtOTKQ+pYOapraXV2KUm5Dg0GNaokRAQAUVDe7uBKl3IcGgxrVEsL9AcivbnJxJUq5Dw0GNaolhHf1GDQYlBosGgxqVAv19ybEz0uHkpQaRBoMatRLCA8gv0p7DEoNFg0GNeolRvhrj0GpQaTBoEa9hPAACqqb9VgGpQaJBoMa9RLD/Wlu76Sysc3VpSjlFjQY1Kh3ZGWSDicpNRg0GNSo13WQm05AKzU4NBjUqBcX5gdASW2LiytRyj1oMKhRL9jXiwAfK6V1GgxKDQYNBjXqiQixIX6U1re6uhSl3IIGg3ILMcG+lOpQklKDQoNBuQV7j0GDQanBoMGg3EJsiC+ldS16kJtSg0CDQbmF2BA/Wtpt1LV0uLoUpUY9DQblFmJD7EtWy3RlklJO02BQbqErGEo0GJRymgaDcguxIb4AlNbpklWlnKXBoNxCTLC9x6AHuSnlPA0G5Rb8fayE+HnpHINSg0CDQbmN2BA/HUpSahA4HQwi8m8ickBE9ojI73u03ysi2Y77lvZoP01Edjnue1xExNHuKyJvONo3iUiys7UpzzIm1I9i7TEo5TSngkFEzgGWAzONMdOAhx3tU4EVwDRgGfCUiFgdmz0NrAQmOH6WOdp/AFQbY9KAR4GHnKlNeZ6kiADyKhr1IDelnORsj+E24HfGmFYAY0yZo3058LoxptUYkwtkA/NFJA4IMcZsMPZ/vS8Dl/XY5iXH7TeB87p6E0qdjJSoQGqb26luand1KUqNas4Gw0TgDMfQz5ciMs/RHg/k93hcgaMt3nH76PZe2xhjOoBaILKvPyoiK0UkQ0QyysvLnXwJyl2kRgcBkFvR4OJKlBrdvE70ABFZDYzp4677HduHAwuBecAqERkP9PVN3xynnRPc17vRmGeAZwDS09N13EAB9h4DwMHyRk4bF+HiapQavU4YDMaY8/u7T0RuA952DAttFhEbEIW9J5DY46EJQJGjPaGPdnpsUyAiXkAoUHXyL0V5uoRwf7wsQm5Fo6tLUWpUc3Yo6V3gXAARmQj4ABXA+8AKx0qjFOyTzJuNMcVAvYgsdMwf3AC853iu94EbHbevBNYYnUVUp8DLaiEpMoCcch1KUsoZJ+wxnMDzwPMishtoA250fJjvEZFVwF6gA7jDGNPp2OY24EXAH/jQ8QPwHPCKiGRj7ymscLI25YHGRwVpj0EpJzkVDMaYNuC7/dz3IPBgH+0ZwPQ+2luAq5ypR6nx0YGszSqn02awWnRRm1IDoUc+K7eSEhVIW4eNoppmV5ei1KilwaDcSnyYPwDFev1npQZMg0G5lehg++m3y+v1nElKDZQGg3IrXcFQ0aDBoNRAaTAotxIe4IPVItpjUMoJGgzKrVgtQmSgjwaDUk7QYFBuJzrYl3IdSlJqwDQYlNuJDvbVHoNSTtBgUG4nOkiDQSlnaDAotxMd7EtFQys2m55qS6mB0GBQbic62JcOm6GmWS/Yo9RAaDAot6MHuSnlHA0G5XaigzQYlHKGBoNyO909hgY9X5JSA6HBoNyODiUp5RwNBuV2gny98PO2UFanwaDUQGgwKLcjIkQG+lLV2ObqUpQalTQYlFuKCPShUoNBqQHRYFBuKTLIR3sMSg2QBoNySxGBGgxKDZQGg3JLkYE+VDbq5LNSA6HBoNxSRKAvLe02mto6XF2KUqOOBoNyS5GBPgBUNuhwklKnSoNBuaUIRzDoPINSp06DQbmliCANBqUGSoNBuaXuoSQNBqVOmQaDcktHhpJ0ZZJSp0qDQbmlIF8vfKwW7TEoNQAaDMotiYj9IDddlaTUKXMqGERktohsFJHtIpIhIvN73HeviGSLyAERWdqj/TQR2eW473EREUe7r4i84WjfJCLJztSmlB79rNTAONtj+D3wK2PMbOABx++IyFRgBTANWAY8JSJWxzZPAyuBCY6fZY72HwDVxpg04FHgISdrUx4uMkhPpKfcS21zOy3tnUP+d5wNBgOEOG6HAkWO28uB140xrcaYXCAbmC8icUCIMWaDMcYALwOX9djmJcftN4HzunoTSg2EnhZDuZsrnv6ahz7aP+R/x8vJ7X8CfCwiD2MPmcWO9nhgY4/HFTja2h23j27v2iYfwBjTISK1QCRQcfQfFZGV2HsdJCUlOfkSlLuKCvKlvL6Vjk4bXladTlOjW0ltC9llDSSE+w/53zrhvxYRWS0iu/v4WQ7cBvy7MSYR+Hfgua7N+ngqc5z2421zbKMxzxhj0o0x6dHR0Sd6CcpDzUkKp6Xdxvb8GleXopTTth6uBobnoM0T9hiMMef3d5+IvAzc5fj178BfHLcLgMQeD03APsxU4Lh9dHvPbQpExAv70FTViV+CUn07PS0Ki8DazHLSkyNcXY5STtlyyB4Mw3H+L2f710XAWY7b5wJZjtvvAyscK41SsE8ybzbGFAP1IrLQMX9wA/Bej21udNy+EljjmIdQakBCA7yZlRjG2qxjRiM9wvPrcrntr1tcXYYaJF09hoqGVob6o9HZOYYfAY85vuG34Bj3N8bsEZFVwF6gA7jDGNM1lX4b8CLgD3zo+AH7MNQrIpKNvaewwsnalOLMCdE8sSaLmqY2wgJ8XF3OsFqbVc767ApsNoPFous4RrPWjk72FNbh522hpd1GY1snQb7Ofnz3z6kegzFmnTHmNGPMLGPMAmPMlh73PWiMSTXGTDLGfNijPcMYM91x351dvQJjTIsx5ipjTJoxZr4xJseZ2pQCOHNiFDYDm3I9b1SysLqZ9k5DWb2uzBrt9hbV0dZp4/Q0+5zqUB+4qUs1lFtLiQoCoKim2cWVDC9jTPdrLqhucnE1ylmHKu3/DxeOt8+VVQzxMmwNBuXWwvy98bYK5SPoW/POghoaW4f2ynK1ze00ttlHb/M1GEaEoppm1g1wvqvQEfLT40OBoZ+A1mBQbs1ike7jGUaChtYOrnj6a/785cEh/TsF1Ud6SAVVntVbGkr1LQM/8vipL7K56YXNA/pSUFTTTHiAN4kRAQBUNmiPQSmnRAf7jphx9ryKRto7Dd/kVQ9oe5vN0N5pO+HjCnsMnfUMiZHMGMPHe0pG7PmtGlo7WPbHr/j533cMaPvssgY6bKZ7ddGpKKppZmyY/7BdZ0SDQbm96BHUY8itaARgR0ENnbZTX3J41xvbuebPG+g4QTgUOsIgOTLAJUNJJxNeR9uWX8Mtr2zhsifXk11W3+u+fcV1PPppJnUt7QOuqbCmmVUZ+dgGsN8BHv74AIU1zXyyp5TaplOvo+v//eYTLIToaylqUU0LY8P88fO2Euhj1aEkpZwVE+JL+RB3vU9W14dDU1snB0rqT/DoY209VM3WwzU8vz73uI8rqmnGz9vCjISwYe8xFNU0M//B1dz95o5TCr8NBysBaGzt4Mevbe9u/8tXOVz42Fc89lkW720rHHBdj63O5O43d3LXG9tp6zi14FqbWc5LG/JYOD6Ctk4bH+0pPqXtG1o7KK2zvwdPtELuBy9lcOPzm2noMeRUVNNMfJj9VBiRQb5Dfg4wDQbl9qKDfKlsaB3QN/TjKatrOeXx5tyKRvy87f/stuWf2pBCY2sHhTXN+HhZ+MOnmccdZy50fJAkhvtTVNN8zGvferiaP3xygFXf5A/6fnnwX/uoa+lgVUYB97+zq8/HbMqp5F+7en+4bsypZFJsMHedP4G9xXXsKaqlua2TP32ezelpUcSG+LLRiWXHG3OqiA725R87inh7a8Ex9ze2dnD3mzvYVVDbq313YS23/nULk2KDefaGdFKiAnlve9Ex23dpae/k/nd2kV3W0N2W5/hCkBjhz/b8mn7fN8W1zazZX8aXmeXc9PxmOm2GupZ26ls7GBvmBzjOGqw9BqWcEx3si80w6N+ylj+5nsueXE9pXctJb5Nb0cjcpHCignzYkld9SsMaXb2N6+Yn0dJuY1dhbb+PLXSMSSeEB9BhM5QcVeNDH+7n8TXZ3P3WTtZmlZ90DWD/4OtvLuCzfaX8c2cxPz53AtcvSOLNLQV9Dv/c/+5ubn91K3/bdBiAtg4bGXnVLEqN5JKZY/G2Cm9tKeTtbQXUNLXz4/MmsHB8JJtyqk7pqN/8qiZueSWDXQW1HK5q4tazUokK8u3zW/tXWeWsyijghuc3kVVq78112gw/W7WDUH9vXvr+fIL9vLlk1lg25FT2Oxfy/vYiXt10mF9/sLe77WC5PSRWzEuircPWfXqLLsYYjDGs3lsKwPcWjiPjUDUHSuq7lx2P7eoxBPpSoZPPSjknOtj+TausbvD+MdU2t1Nc28L+knqufXbjSX3AG2PIKW8gJSqQOUnhvL2tkCkPfMTu43zA99T1DfTbM+MAjjsUVVjdTEK4P4kR9g+TQ5WN3fd12gy7Cmu5Oj0BH6ulewjnZD32WRa3vLKF9N982utb/xcHyrjt1a1MjQvhlrPGs3x2PB02c8wSzfyqJrLLGogI9OH+d3exp6iWHQU1NLd3snB8JOGBPpw3OZa/b8nn0U+zmB4fwrzkcBakRFLR0EpORePRJfXr6S8P8vGeUu58bStgPw5gfko43+QdGwybc6vx9bJgtVi4z9HTWZWRz4HSeh64eCqxIfb30ZkTojCGPp/DGMPz63PxsghfZpaz5ZD9MbkVjYjAinmJRAX58NBH+3v11P64OotzHv6Cv28pYHxUID84PQWA7fk1fQTD0F+ASoNBub3oYF+AQZ1nyK+yT+ieOzmGnPJG9pXU9fvYvIpGjDFUN7VT19JBSlQg9180hfsumoy31cJz644/X9DlYHkDVoswKyGM2BBfDpT2HQxNbR1UNrYRH+bP9LGhiMA3uUe+oWaV1dPU1smi1EjmJIXx9cGTX1tf09TGy1/ncdbEaOJC/Xl7q33M3xjDfW/vYnxUIH/70QL8vK3MTQoj1N+bz/aV9XqOLzLtPZTnb5qHv7eVF9bn8cmeEkSOHMB185Jkgny9SIkK4FeXTkdEWOC4b1POyQ0nVTe28fbWAnysFg5VNhHq782UMSGkj4ugoLqZ4trecy/f5FUxOzGMGxeN45u8avIqGnnkk0zmJYezbPqY7sfNSAjF18vS5yTyV1kV7C+p5xcXTyUqyIc/fJoJQE55I/Fh/kQG+fLAJdPYWVDLi1/ndW/3zrZC8iqb2FlQy7emxjIuMoCIQB+251dTWGPv7R2ZY7BfgGqgk+gnQ4NBub2YrmDoZ2XSi+tz+WBn/2PGfek6EvV7C8cBsD677w/XXQW1nP3wF3x+oKx7KCglKpDkqEBWnpnKlacl8M+dxd215Vc19bviKLusgXERAfh4WZgYG0ymIxgOVzZxzsNfsMNxevEjfyeI8EAfZsSH8lWP4aLth+2Pm5UQxuLUKPYU1Z30Kptnv8qhsa2Tey6czOLUSLYcsg/tZJU1UFTbwk2Lk7vPSeVltXDWxGi+OFDW60Psi/1ljIsMYFZCKFfMTeD97UW8sD6P78yO7952wfhINtx7Hn+/dTGnjQsHYHxUINHBvvzh00y+/+I3XPbk+l6va09RLS+sz2XVN/kYY3h10yFa2m08fu1sLALzkiOwWIR5jjPtZvRYMtzQ2sGeolrmJUdw4Qx7j+zWv26hoqGVu5dNpuc1w3y9rMxJCusVDOX1reRXNfEfb+4gPsyfa+YlcutZqazPrmRjTiW5FY2Mj7YfhX/JzDjOmhjNY6szqW1qJ6+ikcNVTXxnTjxT4kK48rQERIRZCaHdPQZvqxAdZH8fJ0cG0mkz5FaefM/pVGkwKLcXfZxgsNkMj3yaybNfndy39i6HHT2G9ORwJsQE8ZVjuGR3YS1/XJ1Ja4d9cvHTvSWA/UMoxzHOnBwV2P083104jrZOG3/bdJjM0nrOfvgLXtt8uM+/mV3W0P3hMik2mKzSBjpthsc+yyK3opE3t9gnVHsGEMAZE6LYll9DvWOsf0dBDaH+3qREBbIoNRJjYGPu8YeTbDbDbz7Yy5OfH+SSWWOZEhdCenI41U3tHCxvZK2jF3DmxN7XRzlvSgyVjW18tr+MktoWfv/RftZlV3DOpBhEhBsX219/WIAPD1wy9bg1iAi/Xj6dOUlhFNe2cLC8gWfW2k+p9vKGPC7903p+9Y+93P3WTu5+cyePr8nm/CkxLJsex1PXz+XuZZMAmBIXTICPlYweQ0HbDldjMzAvJYK0mCAmxQazv6SeBSkR3UHS0/yUSPYU1VLf0s7qvaXMe3A1Z/z+c5paO3nupnT8vK18d+E4YkN8+dmqHewtrmPKmODu13HPhZOpb+3g6S8Pds/x3HXeBD686wwmxNofNzsxnKyyBtZlVTA2zL/7RIhdRz+f7BDkQGgwKLfn520l2M+rz2DIqWikvqWDAyV1p7Q653BVIxGBPgT7ebMkLYrNuVU8/PEBlj+5nj+uzuqeVO0aNtldVMe2/BqCfb1IjjwSDGkxQXxraix/XnuQX763h06b6XPlTUenjbzKRtJiHMEwJpjWDhtrM8t5Z1sBXhbh072l2GymewVMcpT9KNnT06LptJnuuYRth2uYlRiGiDA7MQx/byt/3XiIlvZOKhtasdkMzW2d7Cmq7Z7ofXXzYf6yLpcbFo3jkatmAXRf42LLoSq+zCxnQkxQ9zh4l6XTxjAxNoh7397FFU9/zTNrc5geH8pNi5Mdrz+Y310+g7/cmH5SZ79dNn0Mz96Qzod3ncHNi5NZn13Bc+tyeeC9PZw9MZpN953Hd+bE8/ctBUQF+vDQFTMd28Ux0fGB62W1MCcpjC09DjT7Jq8ai8DcpDAALnL0Gu48N63POhakRGAz9iW2D39ygHGRAfzk/An87UcLmTzGfrVjP28r/3buBAprmrloRhx39HiuKXEhLJ81lhfW5/Li13kkRQT0+sIAMCcpDGNgV2Ett5+d2t0+ITYIXy/LMaunBtPQnbdVqREkOrjvg9y2OT4cWtpt5FYc+eA9kcNVTSRFdH3wRvHi13n86fNsLp8TT351E09+ns35U2LZWVCLl0XYXVhLYXUT6cnhWI86BfYDF0/lgkfXsiGnEm+rdA/12OvqxMdq4ZO9pbR3GqbE2T/cJjm+ff501XZ8vCz8+/kT+e2H+9lZWEtORSNjQvwI8LH/8547LowAHysf7yllSlwImaX1XDDNPmbu42Xhvosm88D7e5j3m9XUt3YQFeRDW4eNupYO5iSFceVpCTz04X5OT4viV5dO6x5WGR8VSESgD5/uLWNTblX3sFpPft5WHlsxh+V/Wk+gr5V371jS/Y23y4r5A7s87/I58Ty+Jptff7CXmQmhPHNDOlaL8NvLZxAT4stls+OJdAy/HG1GfBjPrcuhrcOGj5eFb3KrmBIXQrCfNwA/PCOFaWNDOD0tqs/t7SvLfLnzb9to67Tx2IrZLJ8df8zjrl+QxBkTohgXGXjMffddNIXCmma+yavuc9/NSgzDx8vCt2fEcXX6keueeVstTIkLOe6qNGdpMCiPkBwZyPb8GprbOvn2E19x0+JkbliU3Ouyn/uK604pGOYk2se+T58QxTXpiZw/NZZvTY1l6+FqLn/qa1Y8Y7/sedc32KrGNq5KTzzmuRIjAvivi6fwwvo8Lpw+hifWZFNW10J0sC8XP7EOqwiVja1MGxvS/U12QkwwItDY2smfrpvD/JQIfv/xAT7eU0JuRWP3MBLYx8SvTk/kxa/z2Hq4mgAfL66Zd6SO7y1KJibEj3/uLGZyXDAHSuqxijB1bAh/XpvD/e/sxs/bwoPfmd5rrF1EmJsUzup9pVjkyLfso02JC+HN2xYRHuDTfa6fwZAaHcTMhFB2F9by4GUzugPXz9vKvRdOOe620+NDaO80ZJbWM2lMMNvyq1kx70hABfp6cf7U2H639/ex8s7ti7n9Vftqp4tnju3zcSLSZygAxIT48cbKRXyZWc7sxLBj7g/19+azn55FXKhfr/0OMCM+lHe2FQ7ZtTY0GJRHWD57LHe9vp173t5JTnkjf/4yh+sXjGN7fg3zkyPYeriafcV1XDKr73/gPbV32iiqaeGy2fYPOT9vKw9dObP7/rlJ4fzP8mk89flBkiICWDE/kb87xv/np/R9idHrF4zjuvlJbD1cwxNrstmWX0NaTBDZZQ14WwVj4OXvL8Dbah/99fex8tDlM0mJDuweA1+cGsn724toaO3oXtLa5Z4LJ5NxqIrdhXX8/oqZ3StcuiydNoal08ZwtJuXpHC4qgmrCEmRx36o/+yCiSwcH8F5U2J7hdHRZiaE9XufM/5n+XTyq5qYkRB64gf3MMPRa9lVWEt7p42WdlufcwnHkxgRwPt3LqHTZo7pBZ4si0U4Z3LMcf9GX2bEh/LKxkPkVR6Z1B5MGgzKIyydNoZgPy/e215EgI+VwppmPtxdzP6Sem49azx1Le3sLe5/yWlNUxu//mAfK88cj5+3hU6bOe633xsWJXPd/CQ6bAZjwCL2b+4z4vv/ABMRpo0NwdsqbDtc033iv3duX4K/j5XUoz4Arp7Xu/dxVXoiP35tG2Af5unJz9vK8zfOY0NOJZeeRPh1sVrkuB/4U+JCmBIXctLPN9hmJ4b1+W37RJIiAgj282JXYS0NLfZTT8xLDj/l5xERvKzDf3W8riDcVVirwaDUQPl5W7lk1lj+tukwv7h4Ko9+msmPX9uGzcDi1CiKalr6Xc/f0t7JLa9sYVNuFTZjuGSW/dt40gmGRbysFrys9tvTxoYSGeTT/Y3/eHVOHRvKhoMVJIQHEBfqx7SxIccMJfRl6bRYwgK8qWlq7zXB3SUmxK/PcXBPJCJMHxvKnsJayutbGRcZQIzjALbRYEJMEJfNHktM8NDUrMGgPMZtZ6Xi52Xl8rnxCPD+jiJuXpLCkrQoskrreWdbIb98bzf/eeFkOm2G59flsSGngm2Ha2jtsDEpNpiP95RQ2dhGqL83M09h+OIvN6afMBS6fGf2WP77H3vZXVTH8lljTyoUwN4juXxOAs+vzyUluv9v+cpuRkIoL6zP5UBpfb9zBCOVl9XCH1fMGbrnH7JnVmqESYwI6F4rv2J+Uq/VMNcuSOJQVRMvrM/ji8xyvK0WDpY3MH1sKN9dOI7zJsdgsQgrntnI2sxy7jwnrXvVz8mIPYVvo99blMw72wrZUVDLotTIk3+BwI/PS2NyXPAxQ0nqWAvHR/DM2hwWp0Zx13kTXF3OiCKnckKqkSg9Pd1kZGS4ugzlJjbmVPIfb+6gvqWDp66fy+LUI8sVbTbD4t+toaqxjXX3nDNk3XiAzNJ6fvPPffzxmtlEBJ54fb8amNqmdkIDvF1dhkuIyBZjTHqf92kwKNVba0cnbR227jXtPX20u4S65vZjJn6VGm2OFww6lKTUUXy9rPh2zRofpefJ1JRyV3pKDKWUUr1oMCillOpFg0EppVQvGgxKKaV60WBQSinViwaDUkqpXjQYlFJK9aLBoJRSqpdRf+SziJQDhwa4eRTQ9yk1PZvul2PpPumb7pdjjZZ9Ms4YE93XHaM+GJwhIhn9HRLuyXS/HEv3Sd90vxzLHfaJDiUppZTqRYNBKaVUL54eDM+4uoARSvfLsXSf9E33y7FG/T7x6DkGpZRSx/L0HoNSSqmjaDAopZTqxWODQUSWicgBEckWkXtcXY+riEieiOwSke0ikuFoixCRT0Uky/HfcFfXOdRE5HkRKROR3T3a+t0PInKv471zQESWuqbqodXPPvlvESl0vF+2i8hFPe7zhH2SKCKfi8g+EdkjInc52t3qveKRwSAiVuBJ4EJgKnCtiEx1bVUudY4xZnaPtdf3AJ8ZYyYAnzl+d3cvAsuOautzPzjeKyuAaY5tnnK8p9zNixy7TwAedbxfZhtj/gUetU86gJ8ZY6YAC4E7HK/drd4rHhkMwHwg2xiTY4xpA14Hlru4ppFkOfCS4/ZLwGWuK2V4GGPWAlVHNfe3H5YDrxtjWo0xuUA29veUW+lnn/THU/ZJsTFmq+N2PbAPiMfN3iueGgzxQH6P3wscbZ7IAJ+IyBYRWeloizXGFIP9HwIQ47LqXKu//eDp7587RWSnY6ipa8jE4/aJiCQDc4BNuNl7xVODQfpo89R1u0uMMXOxD6vdISJnurqgUcCT3z9PA6nAbKAYeMTR7lH7RESCgLeAnxhj6o730D7aRvx+8dRgKAASe/yeABS5qBaXMsYUOf5bBryDvZtbKiJxAI7/lrmuQpfqbz947PvHGFNqjOk0xtiAZzkyLOIx+0REvLGHwqvGmLcdzW71XvHUYPgGmCAiKSLig31y6H0X1zTsRCRQRIK7bgMXALux74sbHQ+7EXjPNRW6XH/74X1ghYj4ikgKMAHY7IL6hl3Xh5/Dd7C/X8BD9omICPAcsM8Y84ced7nVe8XL1QW4gjGmQ0TuBD4GrMDzxpg9Li7LFWKBd+zvdbyAvxljPhKRb4BVIvID4DBwlQtrHBYi8hpwNhAlIgXAL4Hf0cd+MMbsEZFVwF7sq1TuMMZ0uqTwIdTPPjlbRGZjHw7JA24Bz9knwBLge8AuEdnuaLsPN3uv6CkxlFJK9eKpQ0lKKaX6ocGglFKqFw0GpZRSvWgwKKWU6kWDQSmlVC8aDEoppXrRYFBKKdXL/wed9FUELh+hOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "8\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 20.3436WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 20.3436  Val_loss: 1086.3347 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 13.0488WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 13.0488  Val_loss: 774.7271 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 3.1350WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 3.1350  Val_loss: 526.5760 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -2.4741WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -2.4741  Val_loss: 276.5332 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -13.8562WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -13.8562  Val_loss: 88.9351 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -19.4661WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.4661  Val_loss: -49.4892 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -29.6006WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -29.6006  Val_loss: -51.5916 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -33.7839  Val_loss: -6.7556 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -42.6080  Val_loss: 127.5158 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -51.8849  Val_loss: 435.7026 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -58.6315  Val_loss: 818.7844 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -67.1820  Val_loss: 1285.6925 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -76.4149  Val_loss: 1917.6561 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -83.3836  Val_loss: 2481.0640 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -94.0091  Val_loss: 3059.7188 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -103.0658  Val_loss: 3555.2939 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -109.1216  Val_loss: 4255.3018 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -121.5388  Val_loss: 4995.1655 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -128.5730  Val_loss: 5772.3970 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -139.6177  Val_loss: 6430.7480 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 2.0087  Val_loss: 1008.3174 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 1.4786  Val_loss: 1024.2906 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 1.8206  Val_loss: 1044.2733 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 1.1226  Val_loss: 1071.3660 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: -0.3070  Val_loss: 1094.2640 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: -0.1583  Val_loss: 1115.0688 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -0.7442  Val_loss: 1119.9186 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -2.4752  Val_loss: 1125.0543 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -2.0663  Val_loss: 1129.0750 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -2.0461  Val_loss: 1124.4977 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -3.6162  Val_loss: 1117.9525 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -3.4569  Val_loss: 1106.2849 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -4.2548  Val_loss: 1091.4585 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -4.7881  Val_loss: 1065.2063 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -5.9502  Val_loss: 1038.8434 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -6.8599  Val_loss: 1014.1022 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -7.4841  Val_loss: 990.7770 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -8.6679  Val_loss: 955.0006 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -8.4839  Val_loss: 910.5989 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -9.5507  Val_loss: 862.5823 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -8.9886  Val_loss: 808.5638 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -10.3008  Val_loss: 754.4776 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -11.0929  Val_loss: 702.2266 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -11.0267  Val_loss: 647.3569 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -12.6502  Val_loss: 578.2165 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -12.0868  Val_loss: 505.3894 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -14.2379  Val_loss: 446.3145 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -14.6607  Val_loss: 427.0678 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -15.3778  Val_loss: 388.1792 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -15.2632  Val_loss: 328.5221 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -16.4919  Val_loss: 239.3514 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -17.9337  Val_loss: 135.0099 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -18.2344  Val_loss: 38.7435 \n",
      "Epoch 33/200\n",
      "96/99 [============================>.] - Loss for batch: -19.0458WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.0458  Val_loss: -74.7327 \n",
      "Epoch 34/200\n",
      "96/99 [============================>.] - Loss for batch: -20.5380WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -20.5380  Val_loss: -170.5439 \n",
      "Epoch 35/200\n",
      "96/99 [============================>.] - Loss for batch: -19.8693WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -19.8693  Val_loss: -214.6756 \n",
      "Epoch 36/200\n",
      "96/99 [============================>.] - Loss for batch: -21.8611WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -21.8611  Val_loss: -278.1958 \n",
      "Epoch 37/200\n",
      "96/99 [============================>.] - Loss for batch: -21.2886WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -21.2886  Val_loss: -364.0472 \n",
      "Epoch 38/200\n",
      "96/99 [============================>.] - Loss for batch: -23.4563WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -23.4563  Val_loss: -464.9560 \n",
      "Epoch 39/200\n",
      "96/99 [============================>.] - Loss for batch: -23.2830WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -23.2830  Val_loss: -578.8865 \n",
      "Epoch 40/200\n",
      "96/99 [============================>.] - Loss for batch: -25.4990WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -25.4990  Val_loss: -701.9547 \n",
      "Epoch 41/200\n",
      "96/99 [============================>.] - Loss for batch: -26.2661WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -26.2661  Val_loss: -823.0620 \n",
      "Epoch 42/200\n",
      "96/99 [============================>.] - Loss for batch: -27.1277WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -27.1277  Val_loss: -884.8367 \n",
      "Epoch 43/200\n",
      "96/99 [============================>.] - Loss for batch: -27.6190WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -27.6190  Val_loss: -950.8759 \n",
      "Epoch 44/200\n",
      "96/99 [============================>.] - Loss for batch: -29.5346WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -29.5346  Val_loss: -1058.5920 \n",
      "Epoch 45/200\n",
      "96/99 [============================>.] - Loss for batch: -30.4748WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -30.4748  Val_loss: -1244.5509 \n",
      "Epoch 46/200\n",
      "96/99 [============================>.] - Loss for batch: -31.6929WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -31.6929  Val_loss: -1441.6151 \n",
      "Epoch 47/200\n",
      "96/99 [============================>.] - Loss for batch: -32.5674WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -32.5674  Val_loss: -1633.7020 \n",
      "Epoch 48/200\n",
      "96/99 [============================>.] - Loss for batch: -33.3177WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -33.3177  Val_loss: -1869.5626 \n",
      "Epoch 49/200\n",
      "96/99 [============================>.] - Loss for batch: -35.1880WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -35.1880  Val_loss: -2127.6938 \n",
      "Epoch 50/200\n",
      "96/99 [============================>.] - Loss for batch: -36.9757WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -36.9757  Val_loss: -2283.2051 \n",
      "Epoch 51/200\n",
      "96/99 [============================>.] - Loss for batch: -37.5911WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -37.5911  Val_loss: -2346.6523 \n",
      "Epoch 52/200\n",
      "96/99 [============================>.] - Loss for batch: -38.8212WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -38.8212  Val_loss: -2500.1953 \n",
      "Epoch 53/200\n",
      "96/99 [============================>.] - Loss for batch: -40.6563WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -40.6563  Val_loss: -2728.7502 \n",
      "Epoch 54/200\n",
      "96/99 [============================>.] - Loss for batch: -42.3436WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -42.3436  Val_loss: -3069.3542 \n",
      "Epoch 55/200\n",
      "96/99 [============================>.] - Loss for batch: -43.4392WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -43.4392  Val_loss: -3435.0798 \n",
      "Epoch 56/200\n",
      "96/99 [============================>.] - Loss for batch: -45.9021WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -45.9021  Val_loss: -3769.6465 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -47.9167WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -47.9167  Val_loss: -3776.5732 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -48.8442WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -48.8442  Val_loss: -4030.8374 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -52.7215WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -52.7215  Val_loss: -4441.7544 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -53.0071WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -53.0071  Val_loss: -4760.9341 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -56.6038WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -56.6038  Val_loss: -5364.3726 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -58.2703WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -58.2703  Val_loss: -5849.1509 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -61.4121WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -61.4121  Val_loss: -5991.4619 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -64.5294WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -64.5294  Val_loss: -6990.4824 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -67.9901WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -67.9901  Val_loss: -7366.4175 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -70.9530WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -70.9530  Val_loss: -7985.4785 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -74.6792WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -74.6792  Val_loss: -8184.3672 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -78.8641WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -78.8641  Val_loss: -8837.0371 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -81.9515WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -81.9515  Val_loss: -9051.4404 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -85.7223WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -85.7223  Val_loss: -9193.5166 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -91.3189  Val_loss: -9113.2109 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -92.5331WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.5331  Val_loss: -9225.0361 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -94.9792WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.9792  Val_loss: -9296.0977 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -96.4434WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.4434  Val_loss: -9349.4502 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.5461  Val_loss: -9218.1084 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -96.0494  Val_loss: -9003.0205 \n",
      "Epoch 77/200\n",
      "96/99 [============================>.] - Loss for batch: -97.4091WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -97.4091  Val_loss: -9365.9531 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -95.5885  Val_loss: -9215.0166 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.3224  Val_loss: -9091.4590 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.8771  Val_loss: -9337.3184 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.7190  Val_loss: -9197.1650 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.3474  Val_loss: -9031.1309 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.1439  Val_loss: -9166.9854 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -98.4378  Val_loss: -9304.0762 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.5979  Val_loss: -9222.9189 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -97.8548  Val_loss: -9111.3506 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.7122  Val_loss: -9275.3457 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.2865  Val_loss: -9061.1826 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.3028  Val_loss: -8880.1992 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.1505  Val_loss: -8874.6191 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.8166  Val_loss: -9038.3604 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -99.4359  Val_loss: -9195.0127 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -97.0778  Val_loss: -8943.6201 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.4968  Val_loss: -9023.0049 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.4810  Val_loss: -9009.4580 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.2131  Val_loss: -8990.7520 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.8028  Val_loss: -8968.7705 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -97.7171  Val_loss: -9009.4453 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.4178  Val_loss: -8910.1680 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.6979  Val_loss: -9045.0400 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.9724  Val_loss: -9092.3018 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.3506  Val_loss: -9097.8672 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.9146  Val_loss: -9017.6436 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -99.2428  Val_loss: -8784.1133 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -99.9820  Val_loss: -9110.4307 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -97.6843  Val_loss: -9119.3105 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -96.9763  Val_loss: -8841.3203 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -99.9891  Val_loss: -9178.0645 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.1899  Val_loss: -9053.7549 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.3396  Val_loss: -8803.3770 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.5960  Val_loss: -9039.4033 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -99.3562  Val_loss: -9268.4736 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.6689  Val_loss: -9255.4580 \n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -96.2492  Val_loss: -9006.5088 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.8649  Val_loss: -8609.9531 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.1319  Val_loss: -8749.1953 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -98.8163  Val_loss: -8899.3975 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -97.4783  Val_loss: -9110.3691 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -96.5449  Val_loss: -8940.2148 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -98.7718  Val_loss: -8986.7695 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.5119  Val_loss: -9005.5605 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.9245  Val_loss: -8999.5586 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.3631  Val_loss: -9003.3262 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -96.4601  Val_loss: -8774.3398 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -97.1884  Val_loss: -8764.5205 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.9850  Val_loss: -8822.4756 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.0336  Val_loss: -9002.0596 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.7242  Val_loss: -9148.7344 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -99.2544  Val_loss: -8998.4980 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.8105  Val_loss: -8700.6260 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -99.1058  Val_loss: -8951.3262 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -96.9366  Val_loss: -9039.6572 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -99.2660  Val_loss: -9070.4570 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.9976  Val_loss: -9030.9102 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -100.6057  Val_loss: -9061.0654 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -98.1830  Val_loss: -8870.3838 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -98.3393  Val_loss: -8766.5527 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -98.5201  Val_loss: -8853.3809 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.4282  Val_loss: -9042.1172 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -99.0003  Val_loss: -9072.2334 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -99.0869  Val_loss: -8952.7793 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.9168  Val_loss: -8860.9980 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -99.5346  Val_loss: -9015.5898 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -97.4212  Val_loss: -8958.2598 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.6729  Val_loss: -8829.9326 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -97.4149  Val_loss: -8753.3682 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.5290  Val_loss: -8746.6279 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.1251  Val_loss: -8823.8877 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.3179  Val_loss: -8809.5361 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.4687  Val_loss: -8962.1836 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -98.4679  Val_loss: -9212.0986 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -97.3229  Val_loss: -9183.7568 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -98.1706  Val_loss: -8960.4834 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -99.3388  Val_loss: -8809.3682 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.9566  Val_loss: -8865.0195 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -98.3049  Val_loss: -8858.5264 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -99.4041  Val_loss: -8815.7939 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.0519  Val_loss: -8984.7197 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.0557  Val_loss: -9143.9854 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.7688  Val_loss: -9073.2207 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.1291  Val_loss: -8899.2861 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.1297  Val_loss: -9023.0264 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -99.6295  Val_loss: -9058.7334 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.8026  Val_loss: -8956.7783 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -98.3056  Val_loss: -8892.1914 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -99.0323  Val_loss: -8854.3223 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -99.5394  Val_loss: -8907.6328 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.5435  Val_loss: -8943.3760 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -96.9876  Val_loss: -8825.8223 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -98.2770  Val_loss: -8885.8770 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -99.0644  Val_loss: -9099.7637 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -97.7712  Val_loss: -8967.1846 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -97.0729  Val_loss: -8705.3350 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -98.5567  Val_loss: -8586.6826 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -100.0443  Val_loss: -9039.8271 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.9018  Val_loss: -9026.0547 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -99.6749  Val_loss: -9019.2041 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -97.9533  Val_loss: -8992.7617 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -98.0527  Val_loss: -8791.2598 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.4506  Val_loss: -8922.8545 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.1463  Val_loss: -8977.5371 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -99.4708  Val_loss: -9046.2861 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.9512  Val_loss: -8891.0117 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -98.2627  Val_loss: -8915.0303 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -99.0313  Val_loss: -9097.0742 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.1951  Val_loss: -8949.5762 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -99.7123  Val_loss: -8843.5742 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.8751  Val_loss: -8878.4658 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.3038  Val_loss: -8847.6650 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.3258  Val_loss: -8907.7920 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.6553  Val_loss: -8878.1328 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.5425  Val_loss: -8921.0615 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.5146  Val_loss: -8763.1816 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -98.4824  Val_loss: -8825.5039 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.9136  Val_loss: -9037.7695 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.6902  Val_loss: -9045.2900 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -99.3798  Val_loss: -9010.3613 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -97.6613  Val_loss: -8806.8047 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -99.0661  Val_loss: -8692.0391 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw60lEQVR4nO3deXxU1f3/8dcnmSxkBZJAQsISZBNQQRDcN6ygXyvayrdoW6hLsZQutv211e4b369+bevSulYpoLaUWhXcRRAUZTEssocEwhKSkIQlG9nn8/tjLnECkxAgk8lMPs/HI4/cnHvP5OQ6zptzz73niKpijDHGnEpYoBtgjDEmOFhgGGOMaRMLDGOMMW1igWGMMaZNLDCMMca0iSvQDfCX5ORkHTBgQKCbYYwxQWXdunWlqpria1/IBsaAAQPIysoKdDOMMSaoiMjelvbZJSljjDFtYoFhjDGmTSwwjDHGtIkFhjHGmDaxwDDGGNMmFhjGGGPaxALDGGNMm1hgBND2wnLW5h0OdDOMMaZNLDAC6H/e2s6vFm0JdDOMMaZNLDACaEdRBbUN7kA3wxhj2sTvgSEi3UXkZRHZISLbReQSEekpIktEJMf53sPr+AdEJFdEskVkolf5GBHZ7Ox7XETE3233p6PH6iipqKW+0QLDGBMcOqKH8RjwjqoOAy4AtgP3A0tVdTCw1PkZERkOTAVGAJOAJ0Uk3Hmdp4AZwGDna1IHtN1vdh6sBKCh0ZbINcYEB78GhogkAFcCzwOoap2qHgUmA/Ocw+YBtzjbk4EFqlqrqnlALjBORNKABFVdpZ5FyOd71QlK2QcrAGhwWw/DGBMc/N3DGAiUAH8XkQ0i8pyIxAK9VbUQwPneyzk+HdjvVT/fKUt3tk8sD1o5TmDU2RiGMSZI+DswXMCFwFOqOhqowrn81AJf4xLaSnnzyiIzRCRLRLJKSkrOpL0dZmdTD8MuSRljgoO/AyMfyFfVNc7PL+MJkIPOZSac78Vex/f1qp8BFDjlGT7Km1HVZ1V1rKqOTUnxuf5Hp5FjYxjGmCDj18BQ1SJgv4gMdYomANuAxcB0p2w6sMjZXgxMFZEoEcnEM7i91rlsVSEiFzt3R03zqhN0DlfVcaiqjtjIcOptDMMYEyQ6YsW97wIviUgksBu4E09QLRSRu4F9wBQAVd0qIgvxhEoDMEtVG53XmQnMBboBbztfQSmvtAqAwb3j2bj/KI1uJTwsqO8SNsZ0AX4PDFXdCIz1sWtCC8fPBmb7KM8CRrZr4wJkjxMYg3rFsXH/Ueob3YSHhZ+iljHGBJY96R0Aew9VESaQmRwLYA/vGWOCggVGAOQdOkZ6j27ERnp6FTbwbYwJBhYYAbCntIoBSbG4wj2n3wa+jTHBwAKjg6kqew55AiMi3DPQXW89DGNMELDA6GCHq+qoqGlgQHIsrjDP6W+wMQxjTBCwwOhgew4dAyAzOQaX9TCMMUHEAqODHb+ltn9SLJHOGIZNQGiMCQYWGB0sr7SK8DChb4+Yzwe9G6yHYYzp/CwwOtju0kr69Ywh0hX2+SUp62EYY4KABUYH21VcxUDngb2IpkFv62EYYzo/C4wO1OhW8g5VcU6vOICm22rtLiljTDCwwOhAB45UU9fgbuphHB/DqLPAMMYEAQuMDrSr1LMGxsk9DLskZYzp/CwwOtDuEs8ttU09jDC7rdYYEzwsMDrQrpJKusdE0DM2EoBIlz24Z4wJHhYYHWh3SSUDk2PxLBr4eQ/Dpjc3xgQDC4wOtKukinNS4pp+dtkYhjEmiPg9MEQkXEQ2iMgbzs89RWSJiOQ433t4HfuAiOSKSLaITPQqHyMim519j8vxf6IHkfKaekoqahnoFRgRNr25MSaIdEQP4/vAdq+f7weWqupgYKnzMyIyHJgKjAAmAU+KyPF1S58CZgCDna9JHdDudtU04J0S21R2PDCsh2GMCQZ+DQwRyQD+C3jOq3gyMM/Zngfc4lW+QFVrVTUPyAXGiUgakKCqq1RVgfledYLG7hLnllofl6RsDMMYEwz83cN4FPgJ4P2J2FtVCwGc772c8nRgv9dx+U5ZurN9YvlJRGSGiGSJSFZJSUm7/AHtZVdJJeFhQr+eMU1lEU2D3tbDMMZ0fn4LDBG5CShW1XVtreKjTFspP7lQ9VlVHauqY1NSUtr4azvG7pIq+juTDh7nsqlBjDFBxOXH174MuFlEbgSigQQReRE4KCJpqlroXG4qdo7PB/p61c8ACpzyDB/lQWVXSWWz8QsAV9jx2Wqth2GM6fz81sNQ1QdUNUNVB+AZzF6mql8DFgPTncOmA4uc7cXAVBGJEpFMPIPba53LVhUicrFzd9Q0rzpBodGt7Ck91mz8AkBEiAgX62EYY4KCP3sYLXkQWCgidwP7gCkAqrpVRBYC24AGYJaqNjp1ZgJzgW7A285X0Mg/coy6RvdJPQzwPLxng97GmGDQIYGhqsuB5c72IWBCC8fNBmb7KM8CRvqvhf61vbAcgMG940/a5woXG/Q2xgQFe9K7A6zfd5TI8DBG9Ek4aV9keJhNPmiMCQoWGB1g/d4jjExPIMoVftI+V7jYg3vGmKBggeFndQ1uNh0o48J+PXzud4WF2QJKxpigYIHhZ1sLyqhrcDOmv+/AiLAehjEmSFhg+Nn6fUcBuLDFwLAxDGNMcLDA8LMN+47QJzGa3gnRPve7wsPsLiljTFCwwPCzrQXlnJeR2OL+iHCx5zCMMUHBAsOPKmrqySutYmSflgPDFWZjGMaY4GCB4UfbCysAGJneWg/DnvQ2xgQHCww/2nKgDIAR6Sc/sHecZ9DbehjGmM7PAsOPthSUkRIfRa943wPecHxqEOthGGM6PwsMP9pWUM5IH9OBePNMPmg9DGNM52eB4Sc19Y3kFFe2On4BEOmy6c2NMcHBAsNPdhRV0OhWRrRyhxR4ehg2hmGMCQYWGH5yfMB7ZCsD3uAZw6hrsB6GMabzs8Dwk60F5SR2iyC9e7dWj4sIs6lBjDHBwa+BISJ9ReQDEdkuIltF5PtOeU8RWSIiOc73Hl51HhCRXBHJFpGJXuVjRGSzs+9xZ7nWTmtrQRkj0xM4VTNtenNjTLDwdw+jAfiRqp4LXAzMEpHhwP3AUlUdDCx1fsbZNxUYAUwCnhSR44tIPAXMwLPW92Bnf6dU3+hmR2FFq094H2cP7hljgoVfA0NVC1V1vbNdAWwH0oHJwDznsHnALc72ZGCBqtaqah6QC4wTkTQgQVVXqaoC873qdDo5Byupa3Qz4hR3SIEzvbkNehtjgkCHjWGIyABgNLAG6K2qheAJFaCXc1g6sN+rWr5Tlu5sn1h+4u+YISJZIpJVUlLS7n9DW20tcJ7wPsUzGHB8tlrrYRhjOr8OCQwRiQP+A9ynquWtHeqjTFspb16g+qyqjlXVsSkpKWfW2Hawo6iC6IgwBiTFnvLYiDChvlHxdJyMMabz8ntgiEgEnrB4SVVfcYoPOpeZcL4XO+X5QF+v6hlAgVOe4aO8U8ouqmBI73jCw049Lh8R7vlP0GiXpYwxnZy/75IS4Hlgu6r+2WvXYmC6sz0dWORVPlVEokQkE8/g9lrnslWFiFzsvOY0rzqdzo6iCob2jm/TsS4nMGwcwxjT2bn8/PqXAV8HNovIRqfsZ8CDwEIRuRvYB0wBUNWtIrIQ2IbnDqtZqtro1JsJzAW6AW87X53OocpaSitrGZratsCICPf0Quoa3URHhJ/iaGOMCRy/BoaqrsT3+APAhBbqzAZm+yjPAka2X+v8I7vIswbGsNRTD3iDZwElwJ7FMMZ0evakdzvb4QRGm3sYLueSlN0pZYzp5Cww2ll2UQVJsZGkxEe16fiIMM9/gnobwzDGdHIWGO1se1F5m3sX4JkaBKDeJiA0xnRy/h707lKO1TWwraCce68a2OY6n98l5TswVJWaejfH6ho4VtdIbYObKFcYcVEu4qJdTbflGmOMv1lgnKC4ooaH38lm6ri+jOnf87Tqbth3lAa3ctGAtteLPN7DaFTqG93kHKxk/b4jrN93hM35ZewurWrxGQ0RSImLIr1HNwYmxzEuswfjM5PonxRzykkPjTHmdFlgnCAuysWbmwtxhYeddmCszTtMmMCY/j1OfbDD5Yxh3DMvi4PlNU3PYyTHRXJBRneuG96bhOgIYiLD6RYRTlREGLX1biprGyirrqfgaDUFZdV8kF3Mf9Z7Zk/pnRDF+Mwkxg/syfjMJM5JibUAMcacNQuME8REurh+eG/e2lzIb28eQaSr7Zd81uYd5ty0BOKjI9pc59w+CYzu153kuCgmj+rD0NR4RvftQd+e3U7rQ15VyS2uZHXeYdbsPsSq3YdY/JnnYfiMHt346vj+fOWivvSMjWzzaxpjjDcLDB8mj07ntY0FLM8u5voRqW2qU9fgZsP+I0y9qN9p/a707t149duXnUkzmxERBveOZ3DveL5+cX9UlbzSKtbkHWbRxgM89M4OHnl/J18anc7Mq8+hfxvmuTLGGG8WGD5cMSiZpNhIXt1woM2BsSn/KDX1bsZlnt5lLH8REQamxDEwJY7bx/Vj58EK5q/aw8KsfBZm7efmC/ow65pBDG7jFCbGGGO32PjgCg/j1tHpLNl2kIKj1W2qszy7hPAw4bJzkv3cujMzpHc8f7jlPFb+5BruuWIg7207yPWPfsjMF9c1rT9ujDGtscBowfRLB+BWZd6qPW06ftmOYsb060FiTNvHLwKhV0I0P7vxXFb+9Fq+c80gVuaUctNfVvLjf39GaWVtoJtnjOnELDBa0LdnDDecl8Y/1uyjqrah1WOLymrYVljO1cMCtwbH6eoZG8mPrh/Kyvuv5d6rBvLqhgNc+8flvLB6r021bozxyQKjFfdcnklFTQP/ztrf6nErdnqW87hmaK9Wj+uMErtF8MAN5/LOfVcwok8iv3xtCzf/dSV/XZbDmt2HcFt4GGMcFhitGN2vB2P692DOx3ta/Vf321uKSO/ejWGnMSVIZzOoVzz/+OZ4Hr99NNV1jfzxvZ185dnVXPF/H/DPtftsckRjjAXGqdxzeSb7Dh/jva1FPveXVNTyUU4pN4/qE/QPx4kIN1/Qh2X/72o2/+Z6Hr99NL0Sonjglc3c8dwaG+MwpouzwDiF60ekMiAphj8t2Um9j39lv7GpgEa3cuvo9AC0zn/ioyO4+YI+vDLzUv445QI+23+UyX/9mN0llYFumjEmQIIqMERkkohki0iuiNzfEb8zPEz4xX8NJ7e4knmf7Gm2z+1W/rM+nxF9EhgSos8ziAi3jcng5W9dSk19I1OeXmW34RrTRQVNYIhIOPAEcAMwHLhdRIZ3xO+ecG4vrhmawiNLdpJbXNFU/ujSHLYcKGfaJf07ohkBdV5GIv/+1iVER4Qz9dnVrNp1KNBNMsZ0sKAJDGAckKuqu1W1DlgATO6IXywi/M+XzqNbZDjfnL+OF1fv5Xv/3MDjS3OYMiaD/x7btyOaEXADU+J4eeYlpCVGM/3va3m3hXEdY0xoCqbASAe872/Nd8qaiMgMEckSkaySkpJ2/eVpid148qtjKCqr4RevbWF5djH3XJ7JH24dGfSD3acjLbEbC++9hOFpCcx8cR0LT3HLsTEmdIhqcNxnLyJTgImqeo/z89eBcar6XV/Hjx07VrOystq9HcfqGqioaaB7TARRrvB2f/1gUVXbwLdeXMdHOaV88YI+fOPS/qc9HbwxpvMRkXWqOtbXvmDqYeQD3td+MoCCjm5ETKSL3gnRXTosAGKjXDw3fSwzrhzIiuxivvzUKr790jq79daYEBZMgfEpMFhEMkUkEpgKLA5wm7q0KFc4P7vxXNb87Dp++IUhLN1ezE2Pr2TDviOBbpoxxg+CJjBUtQH4DvAusB1YqKpbA9sqA9AtMpzvTRjMK9++lEhXGLf/bTXLdhwMdLOMMe0saAIDQFXfUtUhqnqOqs4OdHtMcyP6JPLKty9lSO94ZsxfZ6FhTIgJqsAwnV9yXBQv3TOe4X0SmPnielbvtuc1jAkVFhim3cVHRzD3znH07RnDPfOy2JR/NNBNMsa0AwsM4xc9YyN58e7xdI+JYPqcteQW2xxUxgQ7CwzjN6mJ0bx493jCw4Rpz6+xy1PGBDkLDONXA5JjmXfXOESEqc+uZuaL69h/+Figm2WMOQMWGMbvRvRJZOmPruKHXxjC8uwSJj36IWvzDge6WcaY02SBYTpEdITnWY0lP7yS1MRops9Za4PhxgQZCwzToTJ6xLBgxiXER7v45aKttma4MUHEAsN0uJT4KO6/YRif7T/KKxsOBLo5xpg2ssAwAXHLqHRG9e3OQ+/soLK2IdDNMca0gQWGCYiwMOHXXxxOSUUtf12WG+jmGGPawALDBMzofj348oUZzFmZx57SqkA3xxhzChYYJqB+OmkoEeHC7Le2B7opxphTsMAwAdUrIZpZ1w5iybaDfJTTvsvqGmPalwWGCbi7LsskvXs3/rxkJ8GyZLAxXZEFhgm46Ihw7r1qIBv2HWWNPQFuTKflt8AQkYdFZIeIbBKRV0Wku9e+B0QkV0SyRWSiV/kYEdns7HtcRMQpjxKRfznla0RkgL/abQJjypi+JMVG8uTyXYFuijGmBf7sYSwBRqrq+cBO4AEAERmOZz3uEcAk4EkRCXfqPAXMAAY7X5Oc8ruBI6o6CHgEeMiP7TYB0C0ynG9cOoAPd5aQc7Ai0M0xxvjgt8BQ1fecdbgBVgMZzvZkYIGq1qpqHpALjBORNCBBVVep50L2fOAWrzrznO2XgQnHex8mdNwxvh+RrjDmrdoT6KYYY3zoqDGMu4C3ne10YL/XvnynLN3ZPrG8WR0nhMqApBN/iYjMEJEsEckqKbE7boJNUlwUky/ow3/WHaDsWH2gm2OMOcFZBYaIvC8iW3x8TfY65udAA/DS8SIfL6WtlLdWp3mB6rOqOlZVx6akpJzeH2M6hTsvy6SmoZEH39kR6KYYY07gOpvKqnpda/tFZDpwEzBBP79fMh/o63VYBlDglGf4KPeuky8iLiARsNtpQtDwPgnMuHIgz6zYzbjMHtw6OuPUlYwxHcKfd0lNAn4K3Kyq3kusLQamOnc+ZeIZ3F6rqoVAhYhc7IxPTAMWedWZ7mzfBixTu2E/ZP3oC0MZ1bc7P/jXZ8yYn0VNfWOgm2SMwb9jGH8F4oElIrJRRJ4GUNWtwEJgG/AOMEtVj38izASewzMQvovPxz2eB5JEJBf4IXC/H9ttAizSFcaCGRfz44lDeW/bQR582y5PGdMZnNUlqdY4t8C2tG82MNtHeRYw0kd5DTClXRtoOrXoiHBmXTOIQ5V1zPk4j6uHpnD10F6BbpYxXZo96W06tZ/eMJTM5Fgefjfbpg0xJsAsMEynFuUK59tXn8PWgnI+yC4OdHOM6dIsMEynd8vodDJ6dOPJD2zaEGMCyQLDdHoR4WF8dXx/svYe4cDR6kA3x5guywLDBIVJI1MBeHdLUYBbYkzXZYFhgkJmcizDUuN5Z6sFhjGBYoFhgsbEEal8uucwJRW1gW6KMV2SBYYJGpNGpqIK728/GOimGNMlWWCYoDEsNZ5+PWN4x8YxjAkICwwTNESESSNT+WRXKeU1Nv25MR3NAsMElYkjUqlvVD7YYQ/xGdPRLDBMUBndtzu94qPsspQxAWCBYYJKWJgwcUQqy7NLqK6zac+N6UgWGCboTBqZSnV9Ix/m2DK8xnQkCwwTdMZl9qR7TIQ99W1MB7PAMEEnIjyM687tzRubCrnliY9Zt9dW6zWmI/g9METk/4mIikiyV9kDIpIrItkiMtGrfIyIbHb2Pe4s1YqznOu/nPI1IjLA3+02ndu9Vw7khvNS2XOoikeW5AS6OcZ0CX4NDBHpC3wB2OdVNhyYCowAJgFPiki4s/spYAaedb4HO/sB7gaOOKv4PQI85M92m85vcO94Hps6mm9eMZCVuaVkF1UEuknGhDx/9zAeAX4CeC+VNhlYoKq1qpqHZ/3ucSKSBiSo6ir1LK02H7jFq848Z/tlYMLx3ofp2u4Y148oVxhzP8kLdFOMCXl+CwwRuRk4oKqfnbArHdjv9XO+U5bubJ9Y3qyOqjYAZUCSj985Q0SyRCSrpMTuoOkKesRG8l/np/HW5iIa3baEqzH+dFaBISLvi8gWH1+TgZ8Dv/JVzUeZtlLeWp3mBarPqupYVR2bkpLS1j/DBLmrh/airLqezQfKAt0UY0Ka62wqq+p1vspF5DwgE/jMuXKUAawXkXF4eg59vQ7PAAqc8gwf5XjVyRcRF5AI2K0xBoDLzvF0Nj/aWcKovt0D2xhjQphfLkmp6mZV7aWqA1R1AJ4P/AtVtQhYDEx17nzKxDO4vVZVC4EKEbnYGZ+YBixyXnIxMN3Zvg1Y5oxzGENSXBQj+iTwUW5poJtiTEjr8OcwVHUrsBDYBrwDzFLV43M8zASewzMQvgt42yl/HkgSkVzgh8D9Hdpo0+ldMTiFDfuOUFXbEOimGBOyzuqSVFs5vQzvn2cDs30clwWM9FFeA0zxV/tM8LtySDJPr9jFip0l3HheWqCbY0xIsie9TUgYn5lEclwUizcWnPpgY8wZscAwISE8TLjp/DSWZRfb4krG+IkFhgkZX7ygD3UNbt7bamt+G+MPFhgmZFzYrzupCdGs2GkPbRrjDxYYJmSICCPTE9leWB7ophgTkiwwTEgZnhbP7pJKauptNT5j2psFhgkp56Yl4FbYedBmrzWmvVlgmJBybloCANsK7LKUMe3NAsOElH49Y4iNDLdxDGP8wALDhJSwMGFYWgLbC+2SlDHtzQLDhJxz0+LZXliO29bHMKZdWWCYkHN+RncqahvYXVoZ6KYYE1IsMEzIGdO/BwBZe44EuCXGhBYLDBNyBibH0iMmgnV7LTCMaU8WGCbkiAhj+vewwDCmnVlgmJA0pn9PdpdWcaiyNtBNMSZk+DUwROS7IpItIltF5P+8yh8QkVxn30Sv8jEistnZ97izVCvOcq7/csrXiMgAf7bbBL/j4xgf5diyrca0F78FhohcA0wGzlfVEcAfnfLhwFRgBDAJeFJEwp1qTwEz8KzzPdjZD3A3cERVBwGPAA/5q90mNIzu151hqfH85vWt7D98LNDNMSYk+LOHMRN4UFVrAVS12CmfDCxQ1VpVzcOzfvc4EUkDElR1laoqMB+4xavOPGf7ZWDC8d6HMb5EhIfx1NfG0Nio/Pb1bYFujjEhwZ+BMQS4wrmEtEJELnLK04H9XsflO2XpzvaJ5c3qqGoDUAYknfgLRWSGiGSJSFZJia2J0NVlJsdyzbBeNhGhMe3EdTaVReR9INXHrp87r90DuBi4CFgoIgMBXz0DbaWcU+z7vED1WeBZgLFjx9pjvoa0xGje2VKD262EhVmn1JizcVaBoarXtbRPRGYCrziXl9aKiBtIxtNz6Ot1aAZQ4JRn+CjHq06+iLiARODw2bTddA1pidHUNbo5fKyO5LioQDfHmKDmz0tSrwHXAojIECASKAUWA1OdO58y8Qxur1XVQqBCRC52xiemAYuc11oMTHe2bwOWOUFkTKtSE7sBUHi0JsAtMSb4nVUP4xTmAHNEZAtQB0x3PuS3ishCYBvQAMxS1ePLo80E5gLdgLedL4DngRdEJBdPz2KqH9ttQkif7tEAFJZVc15GYoBbY0xw81tgqGod8LUW9s0GZvsozwJG+iivAaa0dxtN6EtNPB4Y1sMw5mzZk94mpCXHRhERLhYYxrQDCwwT0sLChN4J0RSVVQe6KcYEPQsME/L6JHajwHoYxpw1CwwT8lIToymywDDmrFlgmJCX1t0TGLZkqzFnxwLDhLy0hM8f3jPGnDkLDBPyBqbEAbD5QFmAW2JMcLPAMCFvXGZPukWE88GO4lMfbIxpkQWGCXnREeFcNiiZpduLsRlljDlzFhimS5hwbi8OHK0mp7gy0E0xJmhZYJgu4ZqhvQBYZpeljDljFhimS0hNjGZAUgyb8o8GuinGBC0LDNNlDEtNYEehrb5nzJmywDBdxrC0ePIOVVFd13jqg40xJ7HAMF3GsNQEVLE1vo05QxYYpss4Ny0egB1F5QFuiTHByW+BISKjRGS1iGwUkSwRGee17wERyRWRbBGZ6FU+RkQ2O/sed5ZqxVnO9V9O+RoRGeCvdpvQ1bdHDDGR4Wy3cQxjzog/exj/B/xWVUcBv3J+RkSG41lidQQwCXhSRMKdOk8BM/Cs8z3Y2Q9wN3BEVQcBjwAP+bHdJkSFhQlDU+Oth2HMGfJnYCiQ4GwnAgXO9mRggarWqmoekAuME5E0IEFVVzlrf88HbvGqM8/ZfhmYcLz3YczpODctgS0HyimvqQ90U4wJOv4MjPuAh0VkP/BH4AGnPB3Y73VcvlOW7myfWN6sjqo2AGVA0om/UERmOJe/skpKStrvLzEh4/aL+lFZ28BTy3cFuinGBJ2zCgwReV9Etvj4mgzMBH6gqn2BHwDPH6/m46W0lfLW6jQvUH1WVceq6tiUlJTT/4NMyDsvI5EvjU7n+ZV5HDhqy7YaczrOKjBU9TpVHenjaxEwHXjFOfTfwPFB73ygr9fLZOC5XJXvbJ9Y3qyOiLjwXOI6fDZtN13Xd64dRF2D22avNeY0+fOSVAFwlbN9LZDjbC8Gpjp3PmXiGdxeq6qFQIWIXOyMT0wDFnnVme5s3wYsU5t21JyhzORYYiPDybHnMYw5LS4/vvY3gcecHkENnrufUNWtIrIQ2AY0ALNU9fijtzOBuUA34G3nCzyXs14QkVw8PYupfmy3CXEiwuDe8ew8aDPXGnM6/BYYqroSGNPCvtnAbB/lWcBIH+U1wJT2bqPpuob2juf97QcD3Qxjgoo96W26pCGp8RyqqqO0sjbQTQmomvpGmyqlHeQWV/DPtftCfoEuCwzTJQ3p7Vnnu6t/WD6zYjcTH/2QFTvb7zb0ugY3lbUN7fZ6nd3ukkq+8sxqHnhlM3sPHQt0c8gtrmRbgX8eTrXAMF3S0N6eeaVyQmAco67BTX2j+4zqLssuRhXuW7ChzbcZF5ZVs2TbQVbvPuTzX9S/WrSFSY9+SF1D623aUVROcXlNm9uaf+QYj76/k9+9vo21eZ3jJkm3W5nxwjpqnb91Td4hn8e1Z89j1a5DlFT47hnvKa3ijr+t5nsLNtDobv/ejgWG6ZJS4qNI7BZBdpD3MFSVb/x9LTPmZzWVFZfXsGHfkaafV+8+xFeeWUXFCU+3H66qY1P+UW4dnU59ozLrpfWn/JA/XFXH9Y98yDfnZzH12dXc9vQqiso+/9CvrG1g0cYC8o9U8+bmghZfZ9HGA9z0+Equf/RDPso5uXdTWduA2+sD781Nhdzw6Ec8tjSHF9fs5SvPrmLanLVMn7PWZy9xV0kl0+esZeGn+8krreLNTYXct2ADWw6Utfr3eTtSVUeBV4juLqnkz0t2Ulj2edmHOSXkFlfyh1tGkhQbyRofQfbcR7u55o/LyT9y6t5HVW0DH+WUcPRYHTuKytle2Lyn8M6WQm7/22qufvgD/rFmX7N9ZdX1fPW5NdQ3unnijgsJD2v/yTD8eZeUMZ2WiHBB3+4s215MzU2NREeEn7pSO5izMo/HluYQHiY8PnU0lw9OBjxjCVGuMFqa8eaT3FKq6xuZcG7vZuVr8w7zya5DiHiColdCND97dTMrc0tZ94svEBvl4s/v7WTtnsO8uHofM68+p6nuytxSVGHaJf25fnhvZr60ngff3sGvvjic8pp6olxhRLman5c5K/OorG3g73deROHRGn7/xjZ+8dpm/jZtLCLCW5sLqa5vJLFbBM+vzOOWUekn/U0rc0q5718buah/T8qq67lr7qe8c9+VnJPiuUz4/raDfH/BBq4Z1ou/3D6aFTtL+N6CDVyQkchjU0fTMzaSh97ZwSe7DlFcXsOsl9az+DuX0y0yvOlcznppPTsPVpx0qW1Tfhlvfu+KpmPX7T3CiuxivjdhMK5wz7+fc4sreOidbD7YUUyDW5k4ojeTRqby4Ns7OFheyzMrdvHEHRdy3fDezPtkD8lxUdx4Xhrvbi1ize7mgVFcXsOf3ttJdX0j98zL4sV7xpMcF0V9o5sHXtlMXYObG89LY9LIVI5U1TH972vZlN881C4e2JPiilqSYiPJLa5kRJ8EEqIj+NWiLVw+KJl+STEAPLV8FwVl1bwy81KGpsb7fB+dLQsM02V966qB3PG3NfxjzT7uujyz1WMPHK2msqah1f8RVbXFD3zwfBD979vbGdW3O6WVdfxw4Ube+8GVNLiVCX9awfkZiXx/wmAKy2rYU1rF9qJyKmoaGNQrjnmf7AHg73eO46ohn89i8MTyXcRFuaisbeCtzYVcPyKVZTuKcatn/fL+STGs3XOYmMhwnl+5mzsvG9AUjiuyS+geE8H5Gd0Z3U/46vh+zP0kjxvPS+VbL66n0e3m5gv6cG5aAgo0upV5n+zhxpFpTWukV9U2MPut7by79SCTRqbyn3X5ZCbHcs8Vmfz81S08uXwX3776nKbzUt/o5jevb6Vfzxjm3z2OipoGrv3jcn73+jbm3nkR/16Xz0//s4mk2Cje2FRIeJiwZNtBhvaOZ/7d44mL8nxk/W6y52bKj3JK+Prza3n43Wx+9cXhAPx5yU52FFUw5xtjiQgPo6SilrTEbjS43c2OraipZ9ZL6ykqr6G4opb//dJ5vLhmH79dvJVukeHcfUUmkeFhvLB6L+9uPUj3mAj+/o2L+N+3t/O7N7bRKyGK5TtL+O61g4l0hTE+sydvbyli58EKGhqVvYeq+Pe6fBrcbmbfOpJfL9rKFQ99wF2XD6DBrby8Lp+k2Ehe31TAwnsv4Q9vbGNHUQWzbx1JaUUdqYlRFJfX8u91+ZyTEsvew8eob1QemzqahGgXVz78AY++v5M/f2UUeaVVzPk4j1tHpTO6X49W38tnwwLDdFmXnpPMZYOSeHJ5Ll+6MJ3uMZE+j3O7lbvnfsrhqjpWPzCBsDChrsFNSWUt6d27AfDe1iJ+8doWnvjqhVw0oGez+sevX//yta3ERLp4+mtjKCyr4dYnP+bnr21hSK94yqrr+XTPYW57elVTvX49Y3CFCx/llHLtsF4UHK3mOy+tZ+Y15zA+syevf1bIhztL+MmkoSzeWMAbmwo5Wl2PWyEh2sVbmwtxqxIX5eLx20dx19ws/vXpfqZfOoDqukaW7jjIlYNTmi5d/OALQ3h1wwHueG4NqspVQ1JY8On+puvzAOFhwqxrBjX9/I3LBvCf9fn8/NXNFJVVsybvMPffMIwpY/rySe4hHn43m7e3FNK3RwzLs0tI6ObiYHktf5s2luiIcKIjwvn+dYP5w5vbmTZnLR/nlnL5oGSe/toYvjk/i0UbC7hmaAoPfvn8prDwdsXgFKaMyeAfa/fy3WsHUdfoZu4ne7htTAbXDut90vHTLunP3z/J47rhvVi0oYCDFTXcfEEfFny6n2U7iimuqGXCsF78323nkxQXBcD3Jgxmbd5h0hKjGZgSh6LcNTeL/35mFSlxUUy7pD8A4wd6pre7/pEPm/3O+64bzFfH92d8ZhJ/WZbDEx945jH78oUZ/Obm4Uz40wq++twa6hrcPP21MUwamdqs/ncnDG56H9U2uJsCf/qlA3hmxW5W7T5EUXkNUa4wfnj9EB/v4PYjoXob2NixYzUrK+vUB5oubcuBMm598mMuHphElCuMA0drmHfnRfRKiG465vXPCvjuPzcA8Oq3L2V4nwSmz1nL+n1HWfHjq4kMD+P6Rz7kUFUdyXGRLPrO5aR370ZZdT0z5meR2C2CqeP6ctfcLH43eQTTLhkAwBMf5PLwu9lEucK49JwkfnvzSLYVltM/KYb+STHERLpQVUoqakmOi6KgrJqfvLyJT3Z9PrB612WZ3H/DMP720W4efjcbEbh8UDIDkmJ5YfVeAH48cSizrhnElKc/4cCRapb/+BoWZu3nF69tYeG9lzAu8/OA+/OSnTy+NIf7rhvMfdcNodGtFBytxhUuhIvgCg+jZ2zzYM05WMHNf/2Y6vpGLujbnX/fewmRrjBUlRfX7OPV9fkcOFrNVUNSKCqvJb17NP9z63nNeh0Pvb2Dd7YWkdGjG3O+cRExkS6qahs4cLSaIb1bv7yy82AF1z/yIT+eOJSSilpeWL2XD350ddOlGm/H6hq44bGP2H/4GG6Fe68cyP03DGPRxgLe2lzIgORYfjJxaNPlKV9UldueXsWWA2X8+1uXcH5G96byp1fsxq3KgKTYpv+O8dERzeqv2X2Id7YW8aPrhxIX5eKNTQV85x8buPvyTH550/BW/1ZvlbUNPLNiFweOVtO/Zyw3j+pDZnJsm+u3RETWqepYn/ssMExX9+LqvfzitS1EusJwhQmpidE8N20sA1PiqKlv5MbHPgJg7+Fj3HvlQPYfqeb1zwoIE7jnioHklVaxIruER6eO4icvb2JAcgxP3jGG7y7YwGf7jwIQH+Wie2wES394NZEuz4dRQ6Ob/35mFev3HeWFu8dxxeC2TZi5u6SS/UeqSYqNZGR6IgDlNfX8Y80+DlXW8uUxGZQdq+crz67myxdm8Mcp5yMiLM8u5ht//5Rf3jScl1bvJS7axaJZlzW7jFZT38iyHcV8YXhvIlr50DzRG5sKeOKDXTzztTE+P6j9bdqctXySW0qDW5kyJoOHp1zQ4rHr9x3h14u2cs8Vmdx8QZ9WLyO25OixOo4cq2+XD2jwhN6glDjC/DBQfbosMIxphaqyaGMBw/skUFZdz91zP6Wmwc03r8hkz6FjvLmpkLl3XsQzK3azft8Rahvc/GTSULYVlPPm5kJU4Rf/dS73XDGQpdsPcs/8LASIdIXx+NTRvLB6Lx/llPKnKRfw5TEZzX53cUUNn+QeYvKoM/vgak12UQXnpMQ2/WtZVbnpLyvZ6tyj/9c7RnPT+X3a9XcGypYDZfx1WS6j+nXnaxf393n5yrSNBYYxp6G4oobfv7Gd1z/z3Bb6k0lD+fbVg3h+ZR6/f2Mb1wxN4fnpF7GloIzJT3zMzRf04dGvjGr6wJ/7cR5vbSli9i0jGdw7nkOVtSzdUcyXL8zwy62Op2NXSSWrdx9iUEpc0zV3Y7xZYBhzBnIOVrC9qIIvnp+GiHCkqo7Hlubw3WsHNQ2I5hZX0j8p5rQu3xjTmVlgGGOMaZPWAsP+WWSMMaZNLDCMMca0iQWGMcaYNjmrwBCRKSKyVUTcIjL2hH0PiEiuiGSLyESv8jEistnZ97izHCvOkq3/csrXiMgArzrTRSTH+ZqOMcaYDne2PYwtwJeAZs/Ci8hwPMuojgAmAU+KyPFZzJ7Cs1zrYOdrklN+N3BEVQcBjwAPOa/VE/g1MB4YB/xaRPw3WYoxxhifziowVHW7qmb72DUZWKCqtaqaB+QC40QkDUhQ1VXquT1rPnCLV515zvbLwASn9zERWKKqh1X1CLCEz0PGGGNMB/HXGEY6sN/r53ynLN3ZPrG8WR1VbQDKgKRWXuskIjJDRLJEJKukpP1WEDPGGNOG2WpF5H0g1ceun6vqopaq+SjTVsrPtE7zQtVngWfB8xxGC20zxhhzBk4ZGKp63Rm8bj7Q1+vnDKDAKc/wUe5dJ19EXEAicNgpv/qEOstP1YB169aVisjeM2j7cclA6VnUD0V2Tnyz83IyOye+BcN56d/SDn/N0LUY+IeI/Bnog2dwe62qNopIhYhcDKwBpgF/8aozHVgF3AYsU1UVkXeB//Ea6L4eeOBUDVDVtk392QIRyWrpaceuys6Jb3ZeTmbnxLdgPy9nFRgiciueD/wU4E0R2aiqE1V1q4gsBLYBDcAsVW10qs0E5gLdgLedL4DngRdEJBdPz2IqgKoeFpHfA586x/1OVTvHCvDGGNOFhOxcUmcr2P8l4A92Tnyz83IyOye+Bft5sSe9W/ZsoBvQCdk58c3Oy8nsnPgW1OfFehjGGGPaxHoYxhhj2sQCwxhjTJtYYJxARCY5Eybmisj9gW5PIInIHmeiyI0ikuWU9RSRJc5EkEtCfV4vEZkjIsUissWrrMVz0NKkm6GmhfPyGxE54LxfNorIjV77Qv68iEhfEflARLY7k7J+3ykPmfeLBYYXZ4LEJ4AbgOHA7c5Eil3ZNao6yuvOjvuBpao6GFjq/BzK5nLy3GU+z8EpJt0MNXPxPafbI877ZZSqvgVd6rw0AD9S1XOBi4FZzt8eMu8XC4zmxgG5qrpbVeuABXgmRTSf854kch6fTx4ZklT1QzzPBXlr6Rz4nHSzI9rZ0Vo4Ly3pEudFVQtVdb2zXQFsxzPvXci8XywwmmvzRIddhALvicg6EZnhlPVW1ULw/A8C9ApY6wKnpXNg7x/4johsci5ZHb/00uXOi7Oez2g8M1qEzPvFAqO5Nk902EVcpqoX4rlEN0tErgx0gzq5rv7+eQo4BxgFFAJ/csq71HkRkTjgP8B9qlre2qE+yjr1ebHAaK6lSRO7JFUtcL4XA6/i6S4fdNY1wfleHLgWBkxL56BLv39U9aCqNqqqG/gbn19e6TLnRUQi8ITFS6r6ilMcMu8XC4zmPgUGi0imiETiGZBaHOA2BYSIxIpI/PFtPJM+buHzSSJxvrc0xX0oa+kcLAamOssNZ+JMuhmA9gXE8Q9Fx6143i/QRc6Ls+Db88B2Vf2z166Qeb/4a7baoKSqDSLyHeBdIByYo6pbA9ysQOkNvOr5fwAX8A9VfUdEPgUWisjdwD5gSgDb6Hci8k880+sni0g+nuWCH8THOTjFpJshpYXzcrWIjMJzWWUPcC90qfNyGfB1YLOIbHTKfkYIvV9sahBjjDFtYpekjDHGtIkFhjHGmDaxwDDGGNMmFhjGGGPaxALDGGNMm1hgGGOMaRMLDGOMMW3y/wFJ+uj5Gx7VqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "9\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 10.4185WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.4185  Val_loss: -1295.9718 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: -3.6723WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.6723  Val_loss: -1769.8896 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: -9.9318WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -9.9318  Val_loss: -2165.5979 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -20.4896WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -20.4896  Val_loss: -2526.4368 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -26.1417WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -26.1417  Val_loss: -2932.4761 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -39.8954WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -39.8954  Val_loss: -3272.2468 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -43.6729WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -43.6729  Val_loss: -3594.8210 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -55.4089WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -55.4089  Val_loss: -4022.3740 \n",
      "Epoch 8/20\n",
      "96/99 [============================>.] - Loss for batch: -59.7070WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.7070  Val_loss: -4543.3745 \n",
      "Epoch 9/20\n",
      "96/99 [============================>.] - Loss for batch: -73.5323WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -73.5323  Val_loss: -5045.9194 \n",
      "Epoch 10/20\n",
      "96/99 [============================>.] - Loss for batch: -81.5370WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -81.5370  Val_loss: -5538.2959 \n",
      "Epoch 11/20\n",
      "96/99 [============================>.] - Loss for batch: -91.1361WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.1361  Val_loss: -6080.5840 \n",
      "Epoch 12/20\n",
      "96/99 [============================>.] - Loss for batch: -101.3006WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -101.3006  Val_loss: -6679.1050 \n",
      "Epoch 13/20\n",
      "96/99 [============================>.] - Loss for batch: -108.4483WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -108.4483  Val_loss: -7065.0908 \n",
      "Epoch 14/20\n",
      "96/99 [============================>.] - Loss for batch: -120.4282WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -120.4282  Val_loss: -7442.0576 \n",
      "Epoch 15/20\n",
      "96/99 [============================>.] - Loss for batch: -128.5052WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -128.5052  Val_loss: -7710.7319 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -143.0655  Val_loss: -7631.3320 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -149.6382  Val_loss: -7557.7910 \n",
      "Epoch 18/20\n",
      "96/99 [============================>.] - Loss for batch: -161.1450WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -161.1450  Val_loss: -7952.6914 \n",
      "Epoch 19/20\n",
      "96/99 [============================>.] - Loss for batch: -176.9278WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -176.9278  Val_loss: -8466.6201 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 8.0188  Val_loss: 138.3897 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 8.2784  Val_loss: 89.0860 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 5.7972  Val_loss: 43.4201 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 5.0216  Val_loss: -2.4946 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 4.4245  Val_loss: -42.9100 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 5.2016  Val_loss: -77.8333 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 3.6868  Val_loss: -110.4555 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 2.8498  Val_loss: -138.1711 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 1.4172  Val_loss: -169.0033 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 1.8275  Val_loss: -199.3550 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -0.0145  Val_loss: -228.5703 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 0.5156  Val_loss: -258.0077 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.0584  Val_loss: -289.0453 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -1.0466  Val_loss: -314.8092 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -1.6251  Val_loss: -343.9610 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -2.9448  Val_loss: -372.4938 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -2.5791  Val_loss: -403.8072 \n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -3.5902  Val_loss: -437.5909 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -4.1553  Val_loss: -469.4051 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -4.6829  Val_loss: -499.6715 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -6.4530  Val_loss: -528.9504 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -5.8339  Val_loss: -566.6128 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -6.9417  Val_loss: -602.3942 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -8.3392  Val_loss: -632.0196 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -8.2175  Val_loss: -659.5903 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -8.9740  Val_loss: -683.6016 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -9.8680  Val_loss: -714.5992 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -10.5259  Val_loss: -739.6766 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -12.1049  Val_loss: -764.9293 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -12.7851  Val_loss: -793.9783 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -13.3394  Val_loss: -796.6252 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -13.5604  Val_loss: -789.6376 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -14.6635  Val_loss: -803.8467 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -15.6528  Val_loss: -852.5565 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -16.8313  Val_loss: -912.7253 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -17.8414  Val_loss: -930.5320 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -18.4903  Val_loss: -966.9731 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -19.6103  Val_loss: -974.9828 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -20.8560  Val_loss: -939.4261 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -20.5925  Val_loss: -926.3146 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -22.4219  Val_loss: -939.8923 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -23.5783  Val_loss: -947.7613 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -24.3267  Val_loss: -960.0870 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -26.1647  Val_loss: -886.6725 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -26.0397  Val_loss: -761.5738 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -27.9904  Val_loss: -662.8755 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -28.8937  Val_loss: -702.5350 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -30.8493  Val_loss: -840.4106 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -31.7737  Val_loss: -1107.2419 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -32.0266  Val_loss: -1245.6117 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -33.6685  Val_loss: -1205.4264 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -35.8051  Val_loss: -1139.2473 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -36.0943  Val_loss: -1242.2173 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -37.0736  Val_loss: -1557.6190 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -39.4372  Val_loss: -1932.7031 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -40.4778  Val_loss: -2080.7729 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -42.8336  Val_loss: -2002.9478 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -43.4965  Val_loss: -2248.7051 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -45.9737  Val_loss: -2895.1982 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -47.8264  Val_loss: -3642.9583 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -49.4557  Val_loss: -4282.2026 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -52.2709  Val_loss: -4593.2964 \n",
      "Epoch 62/200\n",
      "99/99 [==============================] - trainLoss: -53.9486  Val_loss: -5442.8037 \n",
      "Epoch 63/200\n",
      "99/99 [==============================] - trainLoss: -57.1948  Val_loss: -6321.4541 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -60.4001  Val_loss: -7014.5386 \n",
      "Epoch 65/200\n",
      "99/99 [==============================] - trainLoss: -63.3068  Val_loss: -7338.4785 \n",
      "Epoch 66/200\n",
      "99/99 [==============================] - trainLoss: -67.2876  Val_loss: -8101.3979 \n",
      "Epoch 67/200\n",
      "99/99 [==============================] - trainLoss: -71.5993  Val_loss: -8187.1899 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -75.1657WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -75.1657  Val_loss: -8780.7666 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -80.2584  Val_loss: -8308.0723 \n",
      "Epoch 70/200\n",
      "99/99 [==============================] - trainLoss: -83.5524  Val_loss: -8676.6572 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -87.5757WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.5757  Val_loss: -9043.5918 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -88.7672WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.7672  Val_loss: -9053.5410 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -91.3927WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -91.3927  Val_loss: -9297.2549 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -92.2208WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.2208  Val_loss: -9297.4219 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -91.9241  Val_loss: -9296.5742 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -93.5522  Val_loss: -9162.4912 \n",
      "Epoch 77/200\n",
      "96/99 [============================>.] - Loss for batch: -93.3417WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.3417  Val_loss: -9401.8770 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -94.6350  Val_loss: -9291.5586 \n",
      "Epoch 79/200\n",
      "96/99 [============================>.] - Loss for batch: -96.3044WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.3044  Val_loss: -9433.7080 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.3430  Val_loss: -9388.2773 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -95.9444  Val_loss: -9339.9062 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -95.6154  Val_loss: -9372.4648 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -96.0818  Val_loss: -9419.2617 \n",
      "Epoch 84/200\n",
      "96/99 [============================>.] - Loss for batch: -96.3640WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -96.3640  Val_loss: -9457.7188 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.3195  Val_loss: -9441.8828 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.2924  Val_loss: -9416.5547 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.7315  Val_loss: -9408.9258 \n",
      "Epoch 88/200\n",
      "96/99 [============================>.] - Loss for batch: -96.9486WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -96.9486  Val_loss: -9488.0918 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.3682  Val_loss: -9430.1123 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.6706  Val_loss: -9258.1484 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.8956  Val_loss: -9440.4668 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.4942  Val_loss: -9430.8096 \n",
      "Epoch 93/200\n",
      "96/99 [============================>.] - Loss for batch: -98.3656WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -98.3656  Val_loss: -9540.1982 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -97.3808  Val_loss: -9436.9688 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.2648  Val_loss: -9281.7783 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.1142  Val_loss: -9348.2363 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.4466  Val_loss: -9403.6494 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.1427  Val_loss: -9398.4902 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -98.4916  Val_loss: -9197.1260 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.4691  Val_loss: -9425.7510 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -99.1660  Val_loss: -9523.5898 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.0643  Val_loss: -9414.6973 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.8099  Val_loss: -9209.6143 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.2771  Val_loss: -9220.0234 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -97.8094  Val_loss: -9312.6553 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -96.3156  Val_loss: -9288.2227 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -97.6135  Val_loss: -9284.9707 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.5639  Val_loss: -9384.2656 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.5039  Val_loss: -9202.0957 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.5893  Val_loss: -9253.4717 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -96.9344  Val_loss: -9317.5869 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -97.4526  Val_loss: -9330.1943 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.4456  Val_loss: -9255.7529 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -98.0854  Val_loss: -9251.2598 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.5788  Val_loss: -9246.6064 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -96.2066  Val_loss: -9270.3311 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -98.3143  Val_loss: -9270.2236 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.0117  Val_loss: -9282.5781 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -97.2661  Val_loss: -9214.2002 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.9916  Val_loss: -9292.6758 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -96.6749  Val_loss: -9351.1133 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.6207  Val_loss: -9238.1357 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.4763  Val_loss: -9254.9023 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.7141  Val_loss: -9191.3506 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -97.4123  Val_loss: -9251.6094 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.2590  Val_loss: -9317.3438 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.4139  Val_loss: -9310.2090 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -96.9486  Val_loss: -9108.9746 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -98.4804  Val_loss: -9119.9395 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -96.4882  Val_loss: -9085.0615 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.1534  Val_loss: -9278.8818 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -96.5533  Val_loss: -9452.6387 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.1506  Val_loss: -9275.5352 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -96.8606  Val_loss: -9163.9043 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -98.3161  Val_loss: -9235.4492 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -98.8243  Val_loss: -9298.3135 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.4349  Val_loss: -9218.7295 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -99.4244  Val_loss: -9285.1016 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -98.0727  Val_loss: -9336.6973 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.5886  Val_loss: -9363.6299 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.3948  Val_loss: -9339.7188 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.3097  Val_loss: -9221.0518 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -96.5658  Val_loss: -9216.0244 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -97.6849  Val_loss: -9274.4404 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -97.2042  Val_loss: -9290.2637 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -97.7992  Val_loss: -9318.7344 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.8804  Val_loss: -9378.5508 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -99.5416  Val_loss: -9195.1465 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -99.0605  Val_loss: -9160.0938 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -97.3464  Val_loss: -9250.5410 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.9716  Val_loss: -9264.5332 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -99.0314  Val_loss: -9327.1309 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -97.2051  Val_loss: -9323.3633 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.1510  Val_loss: -9270.6631 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -97.1734  Val_loss: -9108.7559 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -97.6932  Val_loss: -9128.2900 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -97.2517  Val_loss: -9409.1006 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.0600  Val_loss: -9463.0879 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -97.2493  Val_loss: -9266.4395 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -99.0014  Val_loss: -9270.6221 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -98.1155  Val_loss: -9212.7744 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -96.7523  Val_loss: -9199.8760 \n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -97.1018  Val_loss: -9194.8809 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -97.8089  Val_loss: -9137.7861 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -98.3282  Val_loss: -9233.9541 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.2879  Val_loss: -9369.5117 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.5114  Val_loss: -9437.3193 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.0450  Val_loss: -9470.6650 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -98.2298  Val_loss: -9443.1738 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -98.5226  Val_loss: -9285.0137 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.5201  Val_loss: -9215.0166 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -96.8565  Val_loss: -9192.6934 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.3473  Val_loss: -9318.8203 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.2512  Val_loss: -9210.3398 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -96.4306  Val_loss: -9034.8291 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.3332  Val_loss: -9253.6094 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -97.0825  Val_loss: -9383.3857 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.3613  Val_loss: -9268.7666 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.0987  Val_loss: -9187.3047 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -97.0925  Val_loss: -9055.8154 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -97.5319  Val_loss: -9154.4395 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -97.1486  Val_loss: -9299.9062 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -98.2170  Val_loss: -9158.7744 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -98.5393  Val_loss: -9169.2637 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -100.3230  Val_loss: -9415.8369 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.1635  Val_loss: -9360.1484 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.4308  Val_loss: -9156.2236 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -99.4720  Val_loss: -9309.7715 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -97.3923  Val_loss: -9351.5059 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -97.9530  Val_loss: -9272.6328 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -96.8652  Val_loss: -9258.6338 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.4904  Val_loss: -9303.7207 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -97.2501  Val_loss: -9207.6064 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -98.8367  Val_loss: -9218.6660 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -96.9835  Val_loss: -9249.6992 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -97.2557  Val_loss: -9123.6846 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -100.7444  Val_loss: -9253.5723 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.1325  Val_loss: -9243.3818 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -98.4421  Val_loss: -9312.7979 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "10\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 22.0352WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 22.0352  Val_loss: -1694.1068 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 12.2426WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 12.2426  Val_loss: -2112.0715 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 6.8632WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 6.8632  Val_loss: -2400.1943 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -3.5705WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.5705  Val_loss: -2512.0430 \n",
      "Epoch 4/20\n",
      "99/99 [==============================] - trainLoss: -14.1424  Val_loss: -2500.8870 \n",
      "Epoch 5/20\n",
      "99/99 [==============================] - trainLoss: -18.8947  Val_loss: -2404.2498 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -29.7223  Val_loss: -2207.6006 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -37.0072  Val_loss: -1896.3356 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -44.9098  Val_loss: -1522.6006 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -55.1409  Val_loss: -1150.7238 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -60.1274  Val_loss: -706.4566 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -70.9315  Val_loss: -331.4270 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -77.7954  Val_loss: -39.6694 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -90.6082  Val_loss: 229.3535 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -95.3658  Val_loss: 474.9562 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -104.1601  Val_loss: 677.9489 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -115.2383  Val_loss: 915.1918 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -122.2757  Val_loss: 1326.7108 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -135.1607  Val_loss: 1589.3835 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -144.8604  Val_loss: 1560.4202 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 2.8273  Val_loss: 1541.3999 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 1.9682  Val_loss: 1630.5737 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 1.9114  Val_loss: 1732.3491 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 0.0104  Val_loss: 1846.9789 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 0.4420  Val_loss: 1965.8035 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: -0.4529  Val_loss: 2091.1736 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -1.1273  Val_loss: 2219.4016 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -2.5020  Val_loss: 2326.7305 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -2.7105  Val_loss: 2424.0547 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -3.2597  Val_loss: 2514.6133 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -4.0625  Val_loss: 2583.7617 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -4.9456  Val_loss: 2646.4263 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -5.3016  Val_loss: 2690.2734 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -5.8014  Val_loss: 2717.1780 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -5.9903  Val_loss: 2728.1714 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -6.4040  Val_loss: 2723.5327 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -7.6747  Val_loss: 2703.3977 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -8.4275  Val_loss: 2681.1538 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -8.9303  Val_loss: 2643.1362 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -9.3139  Val_loss: 2610.6785 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -9.6850  Val_loss: 2575.9226 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -10.9485  Val_loss: 2549.4761 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -10.9315  Val_loss: 2527.2480 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -12.0841  Val_loss: 2491.5955 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -12.8985  Val_loss: 2459.7168 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -13.2019  Val_loss: 2436.4475 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -13.9019  Val_loss: 2405.9619 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -15.0111  Val_loss: 2363.1248 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -14.7068  Val_loss: 2304.9031 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -15.9570  Val_loss: 2226.2405 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -16.9512  Val_loss: 2149.3489 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -17.9522  Val_loss: 2087.8862 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -18.3509  Val_loss: 2010.4896 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -18.7175  Val_loss: 1952.6099 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -20.0724  Val_loss: 1857.2227 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -21.3968  Val_loss: 1752.6545 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -21.1406  Val_loss: 1688.7834 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -22.7576  Val_loss: 1650.8651 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -23.5379  Val_loss: 1540.6357 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -24.6034  Val_loss: 1450.3878 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -24.6564  Val_loss: 1306.3677 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -27.1487  Val_loss: 1118.1919 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -27.0232  Val_loss: 901.6779 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -28.2932  Val_loss: 754.8141 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -30.3874  Val_loss: 514.5950 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -30.1036  Val_loss: 223.1829 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -31.2086  Val_loss: 140.2089 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -33.0905  Val_loss: 135.0676 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -34.0073  Val_loss: 17.3697 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -35.6485  Val_loss: -161.9417 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -36.6923  Val_loss: -376.0644 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -36.9244  Val_loss: -729.0261 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -39.5869  Val_loss: -981.7320 \n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -40.6224  Val_loss: -1239.4675 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -41.8004  Val_loss: -1522.0879 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -44.4009  Val_loss: -1750.1650 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -44.8744  Val_loss: -1764.6876 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -47.1166  Val_loss: -1997.5079 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -48.1386WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -48.1386  Val_loss: -2529.9395 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -50.7676WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -50.7676  Val_loss: -3035.5498 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -52.3482  Val_loss: -3023.6943 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -54.9412WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -54.9412  Val_loss: -3794.7986 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -57.4829WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -57.4829  Val_loss: -4082.3811 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -59.7993WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.7993  Val_loss: -4921.0356 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -62.6916WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.6916  Val_loss: -5713.7227 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -66.7774WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.7774  Val_loss: -6070.9800 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -70.2786WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -70.2786  Val_loss: -7021.8276 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -73.7650WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -73.7650  Val_loss: -7899.8550 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -78.4602WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -78.4602  Val_loss: -8658.3594 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -84.3538WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -84.3538  Val_loss: -9084.5459 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -89.2954WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -89.2954  Val_loss: -9248.6475 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -92.6101WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -92.6101  Val_loss: -9269.1475 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -95.0735WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.0735  Val_loss: -9304.9902 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -94.9631WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.9631  Val_loss: -9400.4209 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.6960  Val_loss: -9286.4092 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -95.7186  Val_loss: -9269.5146 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -97.6206  Val_loss: -9345.6846 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.5029  Val_loss: -9177.0693 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.3133  Val_loss: -9031.0908 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -97.0573  Val_loss: -8943.9102 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.7552  Val_loss: -9075.6367 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -98.5641  Val_loss: -9022.7334 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -97.2753  Val_loss: -8987.1152 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.0645  Val_loss: -8838.8027 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.7820  Val_loss: -8754.0312 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.8425  Val_loss: -9147.9014 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -98.1651  Val_loss: -9218.9043 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -98.2192  Val_loss: -8965.7656 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -98.6265  Val_loss: -8882.0625 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.7362  Val_loss: -9046.4717 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.9102  Val_loss: -8913.3096 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -96.5876  Val_loss: -8793.1543 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.0868  Val_loss: -8751.2852 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -99.2371  Val_loss: -9033.5312 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.3660  Val_loss: -8946.7939 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.1786  Val_loss: -8783.0674 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.2664  Val_loss: -8745.1904 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -99.0894  Val_loss: -9119.9092 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -98.3021  Val_loss: -9239.4814 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.0067  Val_loss: -8944.7588 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -98.4638  Val_loss: -9055.2510 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -99.2154  Val_loss: -8934.7041 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.3907  Val_loss: -9080.8916 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.8639  Val_loss: -8870.6152 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.1463  Val_loss: -8841.9258 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -98.3657  Val_loss: -9023.9883 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -97.9498  Val_loss: -8942.1094 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.1790  Val_loss: -8983.0010 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.4023  Val_loss: -8928.3906 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -96.7027  Val_loss: -8665.1533 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -100.1286  Val_loss: -8944.2236 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -99.0321  Val_loss: -9125.6318 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -100.0406  Val_loss: -9056.2617 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.4109  Val_loss: -8795.2139 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -96.5861  Val_loss: -8787.6641 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.2482  Val_loss: -8965.0723 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.4552  Val_loss: -9081.9580 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.6790  Val_loss: -9096.2861 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -97.5324  Val_loss: -9002.9072 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -98.7638  Val_loss: -8872.5918 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -96.3435  Val_loss: -8849.6475 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -95.3932  Val_loss: -8649.9990 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.5536  Val_loss: -8898.6221 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -96.9032  Val_loss: -9146.1006 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -97.8852  Val_loss: -9204.7578 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -99.4587  Val_loss: -8851.0098 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -98.3484  Val_loss: -8865.6650 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.9790  Val_loss: -8979.0332 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -98.6193  Val_loss: -8913.2266 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.1068  Val_loss: -8754.7119 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -99.7742  Val_loss: -8847.3506 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.0476  Val_loss: -9011.9355 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -98.7570  Val_loss: -9032.1719 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -98.3445  Val_loss: -8974.0322 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.7371  Val_loss: -9011.2295 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -97.9093  Val_loss: -9130.8779 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -98.4103  Val_loss: -9151.7588 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -100.1518  Val_loss: -9131.5645 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -99.1428  Val_loss: -9011.0703 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -99.7352  Val_loss: -9032.2754 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.8902  Val_loss: -8899.2305 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.3475  Val_loss: -8842.1201 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.5207  Val_loss: -8894.9424 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -96.8817  Val_loss: -8861.5654 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.0433  Val_loss: -8856.6523 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -99.0357  Val_loss: -8912.6807 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.2881  Val_loss: -8849.3389 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.0256  Val_loss: -8964.6914 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -99.7585  Val_loss: -8912.0215 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.8741  Val_loss: -8960.0762 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.7565  Val_loss: -8578.5908 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -97.7762  Val_loss: -8711.6465 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -98.9803  Val_loss: -9065.3369 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -98.3029  Val_loss: -9023.4824 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -97.8236  Val_loss: -8769.1465 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -96.6295  Val_loss: -8847.1396 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -98.1093  Val_loss: -8937.9053 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.8474  Val_loss: -8834.4277 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -99.2186  Val_loss: -8923.6904 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.5383  Val_loss: -8962.7979 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -98.1747  Val_loss: -8713.9453 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -99.4533  Val_loss: -8597.3477 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -99.7451  Val_loss: -8745.6865 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -96.3380  Val_loss: -9101.2324 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -99.0768  Val_loss: -9087.2227 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -99.8566  Val_loss: -8894.4922 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -99.5513  Val_loss: -8925.0381 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.7504  Val_loss: -9023.1807 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.9776  Val_loss: -8897.5684 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -98.5347  Val_loss: -8722.4990 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -98.0004  Val_loss: -8898.8828 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -99.2635  Val_loss: -8964.2100 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.4113  Val_loss: -8794.7881 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -97.3256  Val_loss: -8853.2734 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -99.2745  Val_loss: -9054.0645 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -99.4418  Val_loss: -8830.9736 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.1173  Val_loss: -8913.2080 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -96.3650  Val_loss: -8959.7158 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.4537  Val_loss: -8655.1426 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -97.4336  Val_loss: -8745.6797 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.3153  Val_loss: -9049.8525 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -99.0519  Val_loss: -9057.4395 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -98.9962  Val_loss: -9039.9023 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -96.8816  Val_loss: -8893.0762 \n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.2274  Val_loss: -8599.6973 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -96.5774  Val_loss: -8571.1777 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.7691  Val_loss: -8627.4189 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.6862  Val_loss: -8858.5166 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.9238  Val_loss: -8930.9521 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -99.1186  Val_loss: -8850.3232 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -99.7493  Val_loss: -8884.4932 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.2847  Val_loss: -8900.4033 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.0991  Val_loss: -8895.5186 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.5055  Val_loss: -8940.7959 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.2544  Val_loss: -8878.2705 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -99.8484  Val_loss: -8843.4453 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.7501  Val_loss: -8728.3438 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -100.7020  Val_loss: -8877.0205 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -100.5704  Val_loss: -9029.5781 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -95.5769  Val_loss: -9012.8379 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "11\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 16.1065WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 16.1065  Val_loss: -1171.5031 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 8.2904WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.2904  Val_loss: -1686.1376 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: -1.9693WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -1.9693  Val_loss: -2156.7305 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -11.6347WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -11.6347  Val_loss: -2578.4856 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -18.9932WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -18.9932  Val_loss: -2948.8613 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -27.3863WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -27.3863  Val_loss: -3285.1489 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -30.7128WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -30.7128  Val_loss: -3576.0244 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -39.2287WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -39.2287  Val_loss: -3817.5872 \n",
      "Epoch 8/20\n",
      "96/99 [============================>.] - Loss for batch: -44.3776WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -44.3776  Val_loss: -3942.7461 \n",
      "Epoch 9/20\n",
      "96/99 [============================>.] - Loss for batch: -53.7308WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -53.7308  Val_loss: -3977.3845 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -64.2330  Val_loss: -3889.8049 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -73.7926  Val_loss: -3837.0681 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -82.6210  Val_loss: -3812.9558 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -93.5101  Val_loss: -3712.9116 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -104.4247  Val_loss: -3388.6162 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -109.7680  Val_loss: -2817.8806 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -121.4871  Val_loss: -2235.1887 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -136.4117  Val_loss: -1673.7191 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -142.8560  Val_loss: -1190.8965 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -151.6441  Val_loss: -768.0757 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 5.2269  Val_loss: 2118.2004 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 4.8076  Val_loss: 2088.5649 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 4.1483  Val_loss: 2056.5950 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 3.2941  Val_loss: 2024.5914 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 2.7356  Val_loss: 1986.4526 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 2.0201  Val_loss: 1940.3853 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 1.3925  Val_loss: 1895.5144 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 0.9940  Val_loss: 1846.8842 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 0.2038  Val_loss: 1792.6875 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -0.5968  Val_loss: 1732.7650 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -0.4347  Val_loss: 1668.0847 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -1.8502  Val_loss: 1605.3481 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -1.2355  Val_loss: 1536.0847 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -1.3093  Val_loss: 1459.6842 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -3.6418  Val_loss: 1381.2233 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -4.6717  Val_loss: 1308.3202 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -5.0150  Val_loss: 1240.3811 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -4.8197  Val_loss: 1173.6952 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -5.6944  Val_loss: 1110.2272 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -5.8739  Val_loss: 1043.8464 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -6.2952  Val_loss: 986.5021 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -8.1941  Val_loss: 918.8812 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -8.9957  Val_loss: 841.7650 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -9.9850  Val_loss: 766.9944 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -10.8128  Val_loss: 705.8494 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -10.7059  Val_loss: 645.5734 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -11.2011  Val_loss: 578.0214 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -12.7953  Val_loss: 500.1699 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -13.2270  Val_loss: 426.2578 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -13.5306  Val_loss: 342.7408 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -15.0033  Val_loss: 248.5362 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -15.2840  Val_loss: 145.9634 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -16.0624  Val_loss: 45.0747 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -17.3018  Val_loss: -58.5678 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -18.2831  Val_loss: -164.8100 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -19.9423  Val_loss: -225.2309 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -20.8754  Val_loss: -254.6987 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -20.7043  Val_loss: -318.8328 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -21.2643  Val_loss: -431.5846 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -23.3103  Val_loss: -552.6313 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -24.5845  Val_loss: -651.6633 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -25.3028  Val_loss: -760.2670 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -26.5615  Val_loss: -821.1561 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -27.4879  Val_loss: -880.1770 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -28.0511  Val_loss: -1002.7067 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -30.2455  Val_loss: -1187.2501 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -30.9377  Val_loss: -1338.8483 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -30.7878  Val_loss: -1414.3757 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -31.9831  Val_loss: -1547.4197 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -33.4655  Val_loss: -1593.3121 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -36.1148  Val_loss: -1550.8073 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -36.2622  Val_loss: -1674.8970 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -38.2676  Val_loss: -1879.1169 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -38.9426  Val_loss: -2074.3784 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -39.3958  Val_loss: -2317.0374 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -43.3967  Val_loss: -2325.3220 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -44.9546  Val_loss: -2482.8022 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -45.3580  Val_loss: -2895.1606 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -47.6830  Val_loss: -3111.6775 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -50.0415  Val_loss: -3819.8159 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -50.6289WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -50.6289  Val_loss: -4401.6353 \n",
      "Epoch 61/200\n",
      "99/99 [==============================] - trainLoss: -53.5747  Val_loss: -4323.4585 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -55.2871WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -55.2871  Val_loss: -4650.6772 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -58.4678WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -58.4678  Val_loss: -5792.0264 \n",
      "Epoch 64/200\n",
      "99/99 [==============================] - trainLoss: -60.0967  Val_loss: -5747.9956 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -64.4729WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -64.4729  Val_loss: -6492.1382 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -66.5653WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.5653  Val_loss: -7052.2344 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -69.9691WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -69.9691  Val_loss: -7893.9766 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -74.1498WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -74.1498  Val_loss: -8199.1738 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -77.4105WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -77.4105  Val_loss: -8527.8232 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -79.6961WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.6961  Val_loss: -8708.2861 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -85.6448WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -85.6448  Val_loss: -9052.1953 \n",
      "Epoch 72/200\n",
      "96/99 [============================>.] - Loss for batch: -88.6079WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.6079  Val_loss: -9191.5156 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -91.2490  Val_loss: -9125.8828 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -93.3083WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.3083  Val_loss: -9359.4160 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -94.2588  Val_loss: -8988.1602 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -95.7745WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.7745  Val_loss: -9433.5645 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.0191  Val_loss: -9098.7119 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.1102  Val_loss: -9358.3369 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -95.0990  Val_loss: -9223.2891 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.2231  Val_loss: -9371.4258 \n",
      "Epoch 81/200\n",
      "96/99 [============================>.] - Loss for batch: -98.5936WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -98.5936  Val_loss: -9470.6299 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.8685  Val_loss: -9323.4736 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.3511  Val_loss: -9284.9434 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.5983  Val_loss: -8994.4639 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.3279  Val_loss: -8913.2422 \n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -96.8754  Val_loss: -9234.7139 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.2808  Val_loss: -9349.0850 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -95.6571  Val_loss: -9105.7627 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -98.9169  Val_loss: -9176.1064 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -96.1409  Val_loss: -9223.9238 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.4519  Val_loss: -9156.4092 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.0719  Val_loss: -9256.2500 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.1543  Val_loss: -9201.5244 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -98.6903  Val_loss: -9267.6826 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -96.6113  Val_loss: -9230.6572 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.2196  Val_loss: -9265.4229 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.1823  Val_loss: -9250.5654 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -97.0384  Val_loss: -9073.8154 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.2200  Val_loss: -9135.2080 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.5766  Val_loss: -9025.1221 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.1504  Val_loss: -8891.0703 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.4050  Val_loss: -8871.5244 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.9568  Val_loss: -9231.5439 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.1402  Val_loss: -9168.4600 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -98.0649  Val_loss: -9154.7959 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -96.6967  Val_loss: -9172.0039 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.6299  Val_loss: -9123.4639 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.9996  Val_loss: -9074.1973 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -98.6867  Val_loss: -8985.6729 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -98.6968  Val_loss: -9161.1416 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -97.6269  Val_loss: -9174.8379 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -98.6983  Val_loss: -9179.4971 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -99.1467  Val_loss: -9089.9922 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -98.6394  Val_loss: -9174.1523 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -98.7907  Val_loss: -9148.7676 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.5370  Val_loss: -9015.3916 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -99.0219  Val_loss: -8931.2139 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.7809  Val_loss: -9146.9688 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -96.9198  Val_loss: -9149.4707 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -100.2125  Val_loss: -8966.7002 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -96.6177  Val_loss: -8687.6631 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -97.6824  Val_loss: -9025.5010 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.5550  Val_loss: -9091.9727 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -96.9192  Val_loss: -8893.1748 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.0681  Val_loss: -9123.6914 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -96.9476  Val_loss: -9057.5439 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -98.3704  Val_loss: -8892.4570 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -97.5986  Val_loss: -8956.0361 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -95.5942  Val_loss: -9121.1055 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.9482  Val_loss: -8835.8262 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -97.1100  Val_loss: -8835.2422 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -97.3727  Val_loss: -8955.6270 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -99.4174  Val_loss: -9067.1289 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -98.4095  Val_loss: -9259.5527 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -98.9291  Val_loss: -9277.0049 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.3299  Val_loss: -9244.4043 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.2666  Val_loss: -9040.5986 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -99.0252  Val_loss: -9180.1221 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.9606  Val_loss: -9176.6094 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.9847  Val_loss: -9083.3311 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.1727  Val_loss: -9129.9385 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -97.5621  Val_loss: -8869.9453 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -96.9641  Val_loss: -8817.8887 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.7898  Val_loss: -8981.3037 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -99.7691  Val_loss: -9036.5713 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.8718  Val_loss: -9256.7266 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -99.2624  Val_loss: -9237.6738 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -97.5956  Val_loss: -9132.5361 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.3453  Val_loss: -9014.4531 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.1894  Val_loss: -8913.0557 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -98.1142  Val_loss: -8720.6992 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -98.0087  Val_loss: -8363.5645 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -99.2342  Val_loss: -8831.4082 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -99.5134  Val_loss: -9197.2920 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -99.5007  Val_loss: -9311.1348 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -98.0743  Val_loss: -9177.8311 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -99.2884  Val_loss: -8958.9307 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.3799  Val_loss: -8845.4316 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -96.1190  Val_loss: -8713.9346 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.8045  Val_loss: -8833.2822 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -99.4952  Val_loss: -9169.1191 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -99.1432  Val_loss: -9196.1611 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -98.7027  Val_loss: -9048.9688 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -98.9853  Val_loss: -8977.9189 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.6290  Val_loss: -8889.9492 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -99.2254  Val_loss: -8836.1533 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.1250  Val_loss: -9097.7119 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -97.2476  Val_loss: -9089.4639 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -99.9912  Val_loss: -9110.9033 \n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -99.8602  Val_loss: -9005.4795 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -98.5996  Val_loss: -8920.5400 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -97.1192  Val_loss: -8854.6631 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.3002  Val_loss: -9003.1279 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -99.1370  Val_loss: -9227.1299 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -99.1713  Val_loss: -9050.3789 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -98.0779  Val_loss: -8854.7139 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.1866  Val_loss: -8699.3203 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.5478  Val_loss: -8721.1006 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -98.0942  Val_loss: -9162.3447 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.5076  Val_loss: -9256.3018 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -98.4268  Val_loss: -9123.5771 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -98.9955  Val_loss: -8890.8779 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.6722  Val_loss: -8941.6318 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -98.3817  Val_loss: -8998.7207 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -99.7416  Val_loss: -9160.5078 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -99.3509  Val_loss: -9247.9785 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.2496  Val_loss: -9063.2656 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.8769  Val_loss: -9067.7471 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -99.6239  Val_loss: -9040.8350 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.5957  Val_loss: -8965.4404 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -97.8954  Val_loss: -9006.2041 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.8171  Val_loss: -9078.3936 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.4901  Val_loss: -9160.2314 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.8741  Val_loss: -8920.1533 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.4373  Val_loss: -8854.2881 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -99.2846  Val_loss: -8904.1758 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.7564  Val_loss: -8888.5889 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -99.1448  Val_loss: -9009.4941 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -96.5778  Val_loss: -9153.7803 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "12\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 48.4592WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 48.4592  Val_loss: 301.0231 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 39.2449WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 39.2449  Val_loss: -370.0229 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: 29.9280WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 29.9280  Val_loss: -983.3481 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: 21.2447WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 21.2447  Val_loss: -1561.9536 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: 14.4643WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 14.4643  Val_loss: -2085.0320 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: 5.2892WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 5.2892  Val_loss: -2537.7886 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -4.1125WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -4.1125  Val_loss: -2895.0474 \n",
      "Epoch 7/20\n",
      "96/99 [============================>.] - Loss for batch: -12.8247WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -12.8247  Val_loss: -3118.5510 \n",
      "Epoch 8/20\n",
      "96/99 [============================>.] - Loss for batch: -22.9884WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -22.9884  Val_loss: -3191.2546 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -29.7680  Val_loss: -3119.6592 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -37.8737  Val_loss: -2926.1311 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -49.2874  Val_loss: -2556.9280 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -56.3226  Val_loss: -2124.3418 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -65.2917  Val_loss: -1537.4993 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -75.7243  Val_loss: -814.8340 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -83.3078  Val_loss: -226.2489 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -91.3664  Val_loss: 133.9587 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -99.6522  Val_loss: 623.1462 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -109.3615  Val_loss: 1130.2451 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -121.7291  Val_loss: 1378.9220 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: 12.7994  Val_loss: 613.4458 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: 11.3875  Val_loss: 579.0688 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: 10.7937  Val_loss: 549.1620 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: 10.6255  Val_loss: 521.9791 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: 10.1085  Val_loss: 498.6617 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: 9.1844  Val_loss: 479.6161 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: 8.6349  Val_loss: 468.0464 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: 6.9291  Val_loss: 460.8097 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: 7.4468  Val_loss: 457.7815 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: 6.3018  Val_loss: 460.3546 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: 5.1027  Val_loss: 468.4806 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: 5.5607  Val_loss: 473.7081 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: 4.0542  Val_loss: 473.5743 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: 3.2841  Val_loss: 474.9332 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: 2.7886  Val_loss: 474.8361 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: 1.9589  Val_loss: 479.4203 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: 1.6239  Val_loss: 484.7780 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: 0.5338  Val_loss: 490.5095 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -0.2456  Val_loss: 493.8501 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -0.1309  Val_loss: 494.6987 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -0.8749  Val_loss: 489.6479 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -2.0056  Val_loss: 482.0959 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -3.5394  Val_loss: 473.7275 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -3.1996  Val_loss: 469.7518 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -4.0285  Val_loss: 468.2408 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -3.7298  Val_loss: 461.4575 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -5.2479  Val_loss: 443.1176 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -6.0236  Val_loss: 415.5847 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -7.3416  Val_loss: 389.3823 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -7.7221  Val_loss: 357.8407 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -7.5496  Val_loss: 318.2097 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -9.3026  Val_loss: 282.2916 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -9.0037  Val_loss: 249.3826 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -10.1008  Val_loss: 216.8020 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -10.4332  Val_loss: 174.5093 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -11.9868  Val_loss: 132.0154 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -12.1133  Val_loss: 81.9860 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -13.4403  Val_loss: 16.3335 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -13.7841  Val_loss: -57.0443 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -14.6277  Val_loss: -144.0506 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -16.1796  Val_loss: -234.0737 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -16.5863  Val_loss: -333.9450 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -17.8003  Val_loss: -448.0918 \n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -19.3694  Val_loss: -577.9427 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -20.5786  Val_loss: -719.1942 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -20.2221  Val_loss: -867.1260 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -21.8972  Val_loss: -1019.7310 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -23.5433  Val_loss: -1176.2190 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -24.0261  Val_loss: -1329.8110 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -25.1204  Val_loss: -1498.3545 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -26.3571  Val_loss: -1676.8627 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -27.7722  Val_loss: -1860.7834 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -29.6119  Val_loss: -2016.5211 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -30.3364  Val_loss: -2208.8220 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -32.3381  Val_loss: -2486.6052 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -33.1185  Val_loss: -2811.7405 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -34.3212  Val_loss: -3004.1895 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -35.5841WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -35.5841  Val_loss: -3247.3384 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -37.0207WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -37.0207  Val_loss: -3509.9709 \n",
      "Epoch 59/200\n",
      "96/99 [============================>.] - Loss for batch: -38.7956WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -38.7956  Val_loss: -3923.3479 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -40.9224WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -40.9224  Val_loss: -4191.5620 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -42.1746WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -42.1746  Val_loss: -4648.4478 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -44.9809WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -44.9809  Val_loss: -4990.6069 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -47.0017WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -47.0017  Val_loss: -5166.8364 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -49.7261WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -49.7261  Val_loss: -5433.5864 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -52.3602WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -52.3602  Val_loss: -6026.0459 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -54.2630WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -54.2630  Val_loss: -6627.0498 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -56.8165WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -56.8165  Val_loss: -7091.0049 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -59.8304WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.8304  Val_loss: -7494.8252 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -64.5568WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -64.5568  Val_loss: -7683.3838 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -68.4886WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -68.4886  Val_loss: -8407.5557 \n",
      "Epoch 71/200\n",
      "96/99 [============================>.] - Loss for batch: -73.6041WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -73.6041  Val_loss: -8881.0762 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -78.5144  Val_loss: -8821.1367 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -83.5142WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -83.5142  Val_loss: -9145.6748 \n",
      "Epoch 74/200\n",
      "96/99 [============================>.] - Loss for batch: -88.5759WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -88.5759  Val_loss: -9324.7764 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -91.4921  Val_loss: -9298.7725 \n",
      "Epoch 76/200\n",
      "96/99 [============================>.] - Loss for batch: -93.5120WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -93.5120  Val_loss: -9500.2832 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -94.2305  Val_loss: -9317.4111 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -94.9708  Val_loss: -9450.7598 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -95.5045  Val_loss: -9410.3467 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -94.3956  Val_loss: -9410.9141 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -95.8002  Val_loss: -9384.8887 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -95.0051  Val_loss: -9469.9834 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.1074  Val_loss: -9474.0605 \n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -95.6927  Val_loss: -9366.2031 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -96.1080  Val_loss: -9328.2012 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.1836  Val_loss: -9306.5889 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -96.9257  Val_loss: -9322.8896 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -96.1411  Val_loss: -9300.3545 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -96.9970  Val_loss: -9151.9277 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -95.5272  Val_loss: -8935.0215 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.1833  Val_loss: -9251.9258 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -96.2981  Val_loss: -9126.5400 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -96.6655  Val_loss: -9146.5850 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -95.7639  Val_loss: -9180.4131 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.0592  Val_loss: -9175.9512 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.5326  Val_loss: -9167.9473 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -95.8401  Val_loss: -9034.5928 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -96.7977  Val_loss: -9019.5820 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -97.3947  Val_loss: -9064.0322 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -96.5447  Val_loss: -9135.3184 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.9807  Val_loss: -9097.3877 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -97.7481  Val_loss: -9087.1846 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.8916  Val_loss: -9338.1514 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -96.4818  Val_loss: -9206.1650 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -98.4068  Val_loss: -8980.2354 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -97.6455  Val_loss: -9189.5234 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.2219  Val_loss: -9270.3232 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -97.5032  Val_loss: -9281.6455 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.2373  Val_loss: -9294.2744 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -97.6433  Val_loss: -9127.1436 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -95.4787  Val_loss: -8731.8398 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -97.6075  Val_loss: -9129.2139 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -98.0550  Val_loss: -9151.9863 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -98.3402  Val_loss: -9239.8057 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -97.9518  Val_loss: -9266.9053 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.0686  Val_loss: -9143.8154 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -97.3016  Val_loss: -9300.9150 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -98.2755  Val_loss: -8941.7900 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -96.7159  Val_loss: -9125.3369 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -98.4389  Val_loss: -9183.1875 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.2030  Val_loss: -9031.4238 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.3114  Val_loss: -9154.8740 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -97.4436  Val_loss: -9082.2119 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -96.3606  Val_loss: -8689.6025 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.8222  Val_loss: -8736.8477 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -97.4747  Val_loss: -9072.5762 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.2247  Val_loss: -9219.5996 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -97.8372  Val_loss: -9138.4521 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.3867  Val_loss: -9093.4346 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.4790  Val_loss: -9022.8574 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -99.5716  Val_loss: -9318.2930 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -97.9299  Val_loss: -9356.2832 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -97.0700  Val_loss: -9216.6289 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -97.5148  Val_loss: -8995.6582 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -96.9991  Val_loss: -8913.8311 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -97.5909  Val_loss: -8992.1387 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.6743  Val_loss: -9020.8350 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.6607  Val_loss: -8927.3135 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -96.9868  Val_loss: -8983.3311 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -97.6503  Val_loss: -9269.2852 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -97.2567  Val_loss: -9163.1934 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -101.3130  Val_loss: -9329.7158 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -98.3007  Val_loss: -9249.4912 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.2633  Val_loss: -8988.4531 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -96.1488  Val_loss: -9047.1367 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -99.3836  Val_loss: -8946.0283 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -96.6459  Val_loss: -9046.8174 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -96.5770  Val_loss: -8938.1162 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -97.3400  Val_loss: -8916.5225 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -99.0531  Val_loss: -9229.2422 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -96.5152  Val_loss: -9080.3564 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -97.6640  Val_loss: -8937.2734 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -99.2450  Val_loss: -9316.3564 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -96.1770  Val_loss: -9249.0527 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -96.6824  Val_loss: -9080.1514 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -96.0706  Val_loss: -8858.9170 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.5700  Val_loss: -8857.5020 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -98.3839  Val_loss: -8985.4814 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -96.6927  Val_loss: -9133.0146 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -99.0514  Val_loss: -8908.3672 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -95.5894  Val_loss: -8955.0684 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -97.9247  Val_loss: -9064.7900 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.6458  Val_loss: -9069.4131 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -96.2963  Val_loss: -9133.6260 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -98.6336  Val_loss: -9033.3271 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.9819  Val_loss: -9129.1377 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.1590  Val_loss: -9297.6826 \n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -97.6870  Val_loss: -9297.5508 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -99.6128  Val_loss: -9082.8037 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -99.1234  Val_loss: -9343.2031 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.5999  Val_loss: -9334.4736 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -97.6159  Val_loss: -9171.5977 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -97.2614  Val_loss: -9065.7578 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -98.4187  Val_loss: -9015.7578 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -98.9469  Val_loss: -9166.4834 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -97.8372  Val_loss: -9072.3809 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -97.9468  Val_loss: -9092.9629 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -98.3360  Val_loss: -9274.2588 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -96.6018  Val_loss: -9176.7559 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -96.5160  Val_loss: -9046.5391 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -96.3924  Val_loss: -8943.4902 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -99.7772  Val_loss: -8900.7471 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.3354  Val_loss: -8745.5654 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -97.4888  Val_loss: -8847.0244 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -97.2817  Val_loss: -9021.8232 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -97.9685  Val_loss: -9079.7305 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -96.8540  Val_loss: -9162.4355 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -97.5274  Val_loss: -9158.9033 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -98.2782  Val_loss: -9066.7314 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.6685  Val_loss: -9118.9766 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -98.2974  Val_loss: -9083.8633 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -97.3053  Val_loss: -9132.4316 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -99.7320  Val_loss: -8981.6094 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -99.1245  Val_loss: -9176.3291 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -97.9992  Val_loss: -9195.2070 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -98.0093  Val_loss: -9010.2881 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.3812  Val_loss: -9245.9199 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -96.0288  Val_loss: -9057.5293 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -98.3551  Val_loss: -8900.4395 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "13\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 8.3671WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 8.3671  Val_loss: -1397.3223 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: -3.2939WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -3.2939  Val_loss: -1843.7908 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: -10.0439WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -10.0439  Val_loss: -2200.1301 \n",
      "Epoch 3/20\n",
      "96/99 [============================>.] - Loss for batch: -21.3691WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -21.3691  Val_loss: -2446.2390 \n",
      "Epoch 4/20\n",
      "96/99 [============================>.] - Loss for batch: -29.0830WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -29.0830  Val_loss: -2594.2983 \n",
      "Epoch 5/20\n",
      "96/99 [============================>.] - Loss for batch: -41.6375WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -41.6375  Val_loss: -2684.3369 \n",
      "Epoch 6/20\n",
      "96/99 [============================>.] - Loss for batch: -45.7096WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -45.7096  Val_loss: -2729.6089 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -55.6587  Val_loss: -2698.7622 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -66.9656  Val_loss: -2650.2134 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -72.7078  Val_loss: -2590.0583 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -79.5221  Val_loss: -2542.7693 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -91.5543  Val_loss: -2485.1677 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -103.1333  Val_loss: -2265.1172 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -113.8038  Val_loss: -2024.5514 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -123.6236  Val_loss: -1694.9093 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -128.1577  Val_loss: -1327.6913 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -143.3780  Val_loss: -898.1700 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -146.2293  Val_loss: -666.3254 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -160.5944  Val_loss: -592.3170 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -176.6816  Val_loss: -182.7821 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: -1.2774  Val_loss: 537.2384 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: -3.0405  Val_loss: 572.3679 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: -4.4867  Val_loss: 603.6039 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: -4.1360  Val_loss: 631.6987 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: -5.3724  Val_loss: 667.0445 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: -4.7744  Val_loss: 691.9666 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -6.7525  Val_loss: 721.2006 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -5.8187  Val_loss: 747.4558 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -6.9643  Val_loss: 754.3187 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -7.2354  Val_loss: 758.4993 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -8.9273  Val_loss: 742.6122 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -8.5255  Val_loss: 728.1584 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -8.3647  Val_loss: 707.4391 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -9.3047  Val_loss: 700.2576 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -10.5475  Val_loss: 717.1611 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -11.5511  Val_loss: 747.5320 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -11.2298  Val_loss: 759.4855 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -12.0980  Val_loss: 772.3758 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -13.6122  Val_loss: 795.0137 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -13.5966  Val_loss: 779.7952 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -14.6335  Val_loss: 728.0442 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -15.2449  Val_loss: 663.0628 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -15.5925  Val_loss: 605.0674 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -17.2169  Val_loss: 545.2264 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -17.2687  Val_loss: 520.4865 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -17.6481  Val_loss: 476.1160 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -19.1873  Val_loss: 449.8063 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -19.7249  Val_loss: 428.3146 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -19.9630  Val_loss: 397.7756 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -21.0916  Val_loss: 370.7973 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -21.1885  Val_loss: 403.7766 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -21.9297  Val_loss: 460.5370 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -23.0853  Val_loss: 448.6783 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -24.2627  Val_loss: 392.4184 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -24.7976  Val_loss: 331.3230 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -24.9663  Val_loss: 235.2091 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -26.1370  Val_loss: 98.1879 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -27.2537  Val_loss: -11.6968 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -28.2973  Val_loss: -54.3848 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -28.8801  Val_loss: -123.4891 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -30.6292  Val_loss: -230.5326 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -31.4458  Val_loss: -275.4474 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -32.9748  Val_loss: -415.4606 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -33.0127  Val_loss: -608.4559 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -34.1216  Val_loss: -808.6848 \n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -34.9217  Val_loss: -1059.1434 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -36.8968  Val_loss: -1231.6506 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -37.0680  Val_loss: -1343.4020 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -39.0087  Val_loss: -1352.8105 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -39.7759  Val_loss: -1480.4684 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -42.0276  Val_loss: -1664.1604 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -42.5406  Val_loss: -1982.9928 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -43.8252  Val_loss: -2099.2512 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -45.0073  Val_loss: -2270.8191 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -46.1523  Val_loss: -2400.3118 \n",
      "Epoch 55/200\n",
      "99/99 [==============================] - trainLoss: -48.1892  Val_loss: -2694.1257 \n",
      "Epoch 56/200\n",
      "96/99 [============================>.] - Loss for batch: -50.3946WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -50.3946  Val_loss: -2913.9302 \n",
      "Epoch 57/200\n",
      "96/99 [============================>.] - Loss for batch: -52.2422WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -52.2422  Val_loss: -3536.0715 \n",
      "Epoch 58/200\n",
      "96/99 [============================>.] - Loss for batch: -54.0655WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -54.0655  Val_loss: -3703.6143 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -55.6313  Val_loss: -3202.9382 \n",
      "Epoch 60/200\n",
      "96/99 [============================>.] - Loss for batch: -57.8250WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -57.8250  Val_loss: -3787.8132 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -59.8986WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.8986  Val_loss: -4663.6323 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -61.9544WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -61.9544  Val_loss: -4988.6460 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -64.6075WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -64.6075  Val_loss: -5828.0298 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -67.3633WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -67.3633  Val_loss: -6276.9746 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -69.2231WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -69.2231  Val_loss: -7112.6309 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -73.6567WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -73.6567  Val_loss: -7391.5747 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -76.2865WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -76.2865  Val_loss: -8371.0410 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -79.9870WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -79.9870  Val_loss: -8845.1670 \n",
      "Epoch 69/200\n",
      "99/99 [==============================] - trainLoss: -83.2099  Val_loss: -8620.1582 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -87.1124WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -87.1124  Val_loss: -9259.1475 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -92.2793  Val_loss: -9174.2656 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -91.6986  Val_loss: -9103.3262 \n",
      "Epoch 73/200\n",
      "96/99 [============================>.] - Loss for batch: -95.3081WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -95.3081  Val_loss: -9282.6729 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -96.4851  Val_loss: -9208.4199 \n",
      "Epoch 75/200\n",
      "99/99 [==============================] - trainLoss: -96.1866  Val_loss: -9020.8184 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -98.2956  Val_loss: -9018.5010 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -97.4515  Val_loss: -9040.7480 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -97.2298  Val_loss: -8754.6943 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -98.9407  Val_loss: -9171.5488 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -97.9750  Val_loss: -9192.3740 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -96.1618  Val_loss: -8971.3867 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -96.9035  Val_loss: -8348.5146 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -97.8477  Val_loss: -8463.0938 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.5740  Val_loss: -8499.7148 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.1759  Val_loss: -8394.4473 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -99.1144  Val_loss: -8745.2373 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.5287  Val_loss: -8610.9072 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.9072  Val_loss: -8375.6494 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -99.1467  Val_loss: -8746.4951 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -99.2157  Val_loss: -8858.8408 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -99.3243  Val_loss: -8532.9648 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -98.5970  Val_loss: -8161.0103 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -98.3186  Val_loss: -8008.6426 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.3799  Val_loss: -8367.5576 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -98.6898  Val_loss: -8900.8340 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -98.8591  Val_loss: -8489.5605 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -97.6163  Val_loss: -8313.9492 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -97.9976  Val_loss: -8365.4434 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.4260  Val_loss: -8591.1367 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.3048  Val_loss: -8388.6934 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -99.4905  Val_loss: -7910.2583 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -98.9362  Val_loss: -8074.0103 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -98.6569  Val_loss: -8630.6279 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -97.5810  Val_loss: -8439.4688 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -97.6169  Val_loss: -8139.7363 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -99.3427  Val_loss: -8242.2617 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -98.1167  Val_loss: -8438.6709 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.9537  Val_loss: -8225.3203 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -99.6977  Val_loss: -8195.9395 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -101.0369  Val_loss: -8455.2031 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.9654  Val_loss: -8409.9062 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -99.4014  Val_loss: -8250.3574 \n",
      "Epoch 113/200\n",
      "99/99 [==============================] - trainLoss: -100.1364  Val_loss: -8073.2861 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -97.7721  Val_loss: -7648.8857 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -98.0581  Val_loss: -7830.2646 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.8817  Val_loss: -8266.9238 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -99.6285  Val_loss: -8437.3779 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -97.7372  Val_loss: -8338.5938 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -100.0926  Val_loss: -7835.1470 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -98.8957  Val_loss: -8040.1162 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.9806  Val_loss: -8551.8496 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.6376  Val_loss: -8556.6523 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -100.3878  Val_loss: -8366.1689 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -99.1225  Val_loss: -8053.0059 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.3609  Val_loss: -8349.9648 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -98.9305  Val_loss: -8294.4600 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -99.1125  Val_loss: -8398.0723 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.2890  Val_loss: -8441.4775 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.9384  Val_loss: -7985.5430 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -99.1121  Val_loss: -7659.1030 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -98.9288  Val_loss: -7311.1826 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -99.0888  Val_loss: -7323.7969 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -99.7158  Val_loss: -7768.3672 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -101.0575  Val_loss: -8404.3887 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -99.3579  Val_loss: -8775.6865 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -99.3347  Val_loss: -8514.3271 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -100.4829  Val_loss: -8048.7241 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -98.5686  Val_loss: -7993.3574 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -98.2106  Val_loss: -8138.8018 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -99.5740  Val_loss: -7957.0752 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.8300  Val_loss: -8196.5928 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.6603  Val_loss: -7939.1006 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -98.6229  Val_loss: -7520.4443 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.0264  Val_loss: -7512.9697 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -98.5812  Val_loss: -7914.5005 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -98.7922  Val_loss: -7989.7065 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -98.8526  Val_loss: -7883.6616 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -99.2604  Val_loss: -7831.5952 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.5753  Val_loss: -7716.7612 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -99.2222  Val_loss: -7590.4854 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -99.1574  Val_loss: -8016.5430 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -99.4919  Val_loss: -8265.1836 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -99.8936  Val_loss: -8201.1865 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -101.0692  Val_loss: -8087.1631 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -99.0904  Val_loss: -8131.6084 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -100.3889  Val_loss: -7954.3584 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -97.7963  Val_loss: -7961.5327 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -97.6676  Val_loss: -7920.3022 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -99.8332  Val_loss: -7837.3228 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -99.4154  Val_loss: -7603.4868 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -99.2612  Val_loss: -7931.5459 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -98.8142  Val_loss: -7929.3408 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -99.3639  Val_loss: -8065.0645 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -97.9422  Val_loss: -8406.7803 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -98.6203  Val_loss: -8011.5815 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -99.3531  Val_loss: -7686.5566 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.1184  Val_loss: -7609.9971 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -99.0610  Val_loss: -7542.8555 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -100.1434  Val_loss: -7710.8086 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -98.7172  Val_loss: -8224.7061 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -99.5986  Val_loss: -8446.6650 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.8784  Val_loss: -8506.0293 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.7918  Val_loss: -8393.0566 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -99.1157  Val_loss: -7999.3960 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -98.9927  Val_loss: -8037.1494 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -100.1829  Val_loss: -7904.5605 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.5344  Val_loss: -7591.9717 \n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -99.2184  Val_loss: -7984.9863 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -99.8478  Val_loss: -8033.6875 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -99.8540  Val_loss: -8008.9238 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -99.7212  Val_loss: -8284.9277 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -99.3377  Val_loss: -8244.6514 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -99.3092  Val_loss: -8348.8613 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -101.1791  Val_loss: -8662.6748 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -99.9446  Val_loss: -8480.8242 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.4458  Val_loss: -8166.5991 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -97.9299  Val_loss: -7708.5952 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -98.4295  Val_loss: -7190.9346 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -98.4859  Val_loss: -7490.5005 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -98.7765  Val_loss: -7818.1567 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -99.7308  Val_loss: -8173.9854 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -100.0673  Val_loss: -8271.8311 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -98.6493  Val_loss: -8305.4932 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -100.2757  Val_loss: -8006.9360 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -101.4996  Val_loss: -7945.8325 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -99.0571  Val_loss: -8179.4336 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -99.2515  Val_loss: -8237.3301 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -99.2865  Val_loss: -7806.1621 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -100.2470  Val_loss: -7897.8970 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "14\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/20\n",
      "96/99 [============================>.] - Loss for batch: 10.8337WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 10.8337  Val_loss: -1545.1060 \n",
      "Epoch 1/20\n",
      "96/99 [============================>.] - Loss for batch: 0.0900WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: 0.0900  Val_loss: -1720.1171 \n",
      "Epoch 2/20\n",
      "96/99 [============================>.] - Loss for batch: -9.9057WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -9.9057  Val_loss: -1791.1509 \n",
      "Epoch 3/20\n",
      "99/99 [==============================] - trainLoss: -16.3307  Val_loss: -1758.3392 \n",
      "Epoch 4/20\n",
      "99/99 [==============================] - trainLoss: -22.6697  Val_loss: -1589.4030 \n",
      "Epoch 5/20\n",
      "99/99 [==============================] - trainLoss: -32.8741  Val_loss: -1260.9822 \n",
      "Epoch 6/20\n",
      "99/99 [==============================] - trainLoss: -40.6555  Val_loss: -767.1212 \n",
      "Epoch 7/20\n",
      "99/99 [==============================] - trainLoss: -50.0951  Val_loss: -177.6825 \n",
      "Epoch 8/20\n",
      "99/99 [==============================] - trainLoss: -58.5442  Val_loss: 559.0603 \n",
      "Epoch 9/20\n",
      "99/99 [==============================] - trainLoss: -66.1394  Val_loss: 1500.7888 \n",
      "Epoch 10/20\n",
      "99/99 [==============================] - trainLoss: -74.0580  Val_loss: 2556.9304 \n",
      "Epoch 11/20\n",
      "99/99 [==============================] - trainLoss: -84.2755  Val_loss: 3579.0356 \n",
      "Epoch 12/20\n",
      "99/99 [==============================] - trainLoss: -92.1462  Val_loss: 4642.2432 \n",
      "Epoch 13/20\n",
      "99/99 [==============================] - trainLoss: -102.9971  Val_loss: 5596.3735 \n",
      "Epoch 14/20\n",
      "99/99 [==============================] - trainLoss: -110.4993  Val_loss: 6732.6255 \n",
      "Epoch 15/20\n",
      "99/99 [==============================] - trainLoss: -123.1634  Val_loss: 8414.6553 \n",
      "Epoch 16/20\n",
      "99/99 [==============================] - trainLoss: -132.9657  Val_loss: 10054.6260 \n",
      "Epoch 17/20\n",
      "99/99 [==============================] - trainLoss: -145.8694  Val_loss: 11224.0459 \n",
      "Epoch 18/20\n",
      "99/99 [==============================] - trainLoss: -154.2739  Val_loss: 12035.5869 \n",
      "Epoch 19/20\n",
      "99/99 [==============================] - trainLoss: -166.5227  Val_loss: 13088.3584 \n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 0/200\n",
      "99/99 [==============================] - trainLoss: -0.6313  Val_loss: 763.6746 \n",
      "Epoch 1/200\n",
      "99/99 [==============================] - trainLoss: -0.5071  Val_loss: 806.8577 \n",
      "Epoch 2/200\n",
      "99/99 [==============================] - trainLoss: -1.6300  Val_loss: 854.2077 \n",
      "Epoch 3/200\n",
      "99/99 [==============================] - trainLoss: -1.5101  Val_loss: 915.4742 \n",
      "Epoch 4/200\n",
      "99/99 [==============================] - trainLoss: -4.8983  Val_loss: 972.9531 \n",
      "Epoch 5/200\n",
      "99/99 [==============================] - trainLoss: -3.2870  Val_loss: 1020.6869 \n",
      "Epoch 6/200\n",
      "99/99 [==============================] - trainLoss: -3.7856  Val_loss: 1071.3843 \n",
      "Epoch 7/200\n",
      "99/99 [==============================] - trainLoss: -4.1446  Val_loss: 1124.1450 \n",
      "Epoch 8/200\n",
      "99/99 [==============================] - trainLoss: -5.0223  Val_loss: 1169.8013 \n",
      "Epoch 9/200\n",
      "99/99 [==============================] - trainLoss: -6.7866  Val_loss: 1202.3933 \n",
      "Epoch 10/200\n",
      "99/99 [==============================] - trainLoss: -6.2551  Val_loss: 1243.1986 \n",
      "Epoch 11/200\n",
      "99/99 [==============================] - trainLoss: -7.1335  Val_loss: 1275.0946 \n",
      "Epoch 12/200\n",
      "99/99 [==============================] - trainLoss: -9.2657  Val_loss: 1276.1255 \n",
      "Epoch 13/200\n",
      "99/99 [==============================] - trainLoss: -8.1932  Val_loss: 1259.9080 \n",
      "Epoch 14/200\n",
      "99/99 [==============================] - trainLoss: -9.4326  Val_loss: 1234.4952 \n",
      "Epoch 15/200\n",
      "99/99 [==============================] - trainLoss: -9.9696  Val_loss: 1224.0746 \n",
      "Epoch 16/200\n",
      "99/99 [==============================] - trainLoss: -10.6780  Val_loss: 1209.6365 \n",
      "Epoch 17/200\n",
      "99/99 [==============================] - trainLoss: -10.4920  Val_loss: 1199.1906 \n",
      "Epoch 18/200\n",
      "99/99 [==============================] - trainLoss: -11.9387  Val_loss: 1174.6011 \n",
      "Epoch 19/200\n",
      "99/99 [==============================] - trainLoss: -12.9955  Val_loss: 1158.2218 \n",
      "Epoch 20/200\n",
      "99/99 [==============================] - trainLoss: -12.7480  Val_loss: 1148.8607 \n",
      "Epoch 21/200\n",
      "99/99 [==============================] - trainLoss: -15.4169  Val_loss: 1144.0021 \n",
      "Epoch 22/200\n",
      "99/99 [==============================] - trainLoss: -13.6597  Val_loss: 1152.9026 \n",
      "Epoch 23/200\n",
      "99/99 [==============================] - trainLoss: -14.7785  Val_loss: 1171.9441 \n",
      "Epoch 24/200\n",
      "99/99 [==============================] - trainLoss: -16.4396  Val_loss: 1213.4032 \n",
      "Epoch 25/200\n",
      "99/99 [==============================] - trainLoss: -15.8992  Val_loss: 1256.1259 \n",
      "Epoch 26/200\n",
      "99/99 [==============================] - trainLoss: -17.4482  Val_loss: 1285.4061 \n",
      "Epoch 27/200\n",
      "99/99 [==============================] - trainLoss: -18.3170  Val_loss: 1298.8557 \n",
      "Epoch 28/200\n",
      "99/99 [==============================] - trainLoss: -19.1529  Val_loss: 1288.7455 \n",
      "Epoch 29/200\n",
      "99/99 [==============================] - trainLoss: -19.9226  Val_loss: 1293.8345 \n",
      "Epoch 30/200\n",
      "99/99 [==============================] - trainLoss: -20.2193  Val_loss: 1332.8597 \n",
      "Epoch 31/200\n",
      "99/99 [==============================] - trainLoss: -21.5159  Val_loss: 1379.5963 \n",
      "Epoch 32/200\n",
      "99/99 [==============================] - trainLoss: -22.4004  Val_loss: 1427.4392 \n",
      "Epoch 33/200\n",
      "99/99 [==============================] - trainLoss: -22.2042  Val_loss: 1486.6256 \n",
      "Epoch 34/200\n",
      "99/99 [==============================] - trainLoss: -23.3835  Val_loss: 1559.8982 \n",
      "Epoch 35/200\n",
      "99/99 [==============================] - trainLoss: -24.7705  Val_loss: 1584.6006 \n",
      "Epoch 36/200\n",
      "99/99 [==============================] - trainLoss: -26.0868  Val_loss: 1613.4220 \n",
      "Epoch 37/200\n",
      "99/99 [==============================] - trainLoss: -26.6826  Val_loss: 1613.3870 \n",
      "Epoch 38/200\n",
      "99/99 [==============================] - trainLoss: -27.3689  Val_loss: 1575.2070 \n",
      "Epoch 39/200\n",
      "99/99 [==============================] - trainLoss: -28.2351  Val_loss: 1407.5269 \n",
      "Epoch 40/200\n",
      "99/99 [==============================] - trainLoss: -29.1506  Val_loss: 1295.6744 \n",
      "Epoch 41/200\n",
      "99/99 [==============================] - trainLoss: -30.5388  Val_loss: 1247.3252 \n",
      "Epoch 42/200\n",
      "99/99 [==============================] - trainLoss: -30.9982  Val_loss: 1167.3993 \n",
      "Epoch 43/200\n",
      "99/99 [==============================] - trainLoss: -32.1041  Val_loss: 1078.0367 \n",
      "Epoch 44/200\n",
      "99/99 [==============================] - trainLoss: -33.2224  Val_loss: 1024.5253 \n",
      "Epoch 45/200\n",
      "99/99 [==============================] - trainLoss: -34.1522  Val_loss: 933.7216 \n",
      "Epoch 46/200\n",
      "99/99 [==============================] - trainLoss: -35.3578  Val_loss: 775.5442 \n",
      "Epoch 47/200\n",
      "99/99 [==============================] - trainLoss: -35.8971  Val_loss: 599.7681 \n",
      "Epoch 48/200\n",
      "99/99 [==============================] - trainLoss: -37.8334  Val_loss: 587.9152 \n",
      "Epoch 49/200\n",
      "99/99 [==============================] - trainLoss: -37.8259  Val_loss: 545.5853 \n",
      "Epoch 50/200\n",
      "99/99 [==============================] - trainLoss: -41.2471  Val_loss: 375.6507 \n",
      "Epoch 51/200\n",
      "99/99 [==============================] - trainLoss: -41.2919  Val_loss: 216.0774 \n",
      "Epoch 52/200\n",
      "99/99 [==============================] - trainLoss: -42.5145  Val_loss: 178.5790 \n",
      "Epoch 53/200\n",
      "99/99 [==============================] - trainLoss: -42.5379  Val_loss: -9.4584 \n",
      "Epoch 54/200\n",
      "99/99 [==============================] - trainLoss: -44.8784  Val_loss: -48.6074 \n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -46.4187  Val_loss: -286.4977 \n",
      "Epoch 56/200\n",
      "99/99 [==============================] - trainLoss: -48.4318  Val_loss: -89.1070 \n",
      "Epoch 57/200\n",
      "99/99 [==============================] - trainLoss: -48.8642  Val_loss: 107.5656 \n",
      "Epoch 58/200\n",
      "99/99 [==============================] - trainLoss: -50.6411  Val_loss: -222.5638 \n",
      "Epoch 59/200\n",
      "99/99 [==============================] - trainLoss: -52.5758  Val_loss: -751.3058 \n",
      "Epoch 60/200\n",
      "99/99 [==============================] - trainLoss: -55.1657  Val_loss: -1197.5654 \n",
      "Epoch 61/200\n",
      "96/99 [============================>.] - Loss for batch: -57.0274WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -57.0274  Val_loss: -1865.5005 \n",
      "Epoch 62/200\n",
      "96/99 [============================>.] - Loss for batch: -59.4821WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -59.4821  Val_loss: -2443.3650 \n",
      "Epoch 63/200\n",
      "96/99 [============================>.] - Loss for batch: -61.7332WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -61.7332  Val_loss: -3789.6003 \n",
      "Epoch 64/200\n",
      "96/99 [============================>.] - Loss for batch: -62.9088WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -62.9088  Val_loss: -4326.0688 \n",
      "Epoch 65/200\n",
      "96/99 [============================>.] - Loss for batch: -66.9288WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -66.9288  Val_loss: -4968.5806 \n",
      "Epoch 66/200\n",
      "96/99 [============================>.] - Loss for batch: -68.8367WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -68.8367  Val_loss: -6616.0806 \n",
      "Epoch 67/200\n",
      "96/99 [============================>.] - Loss for batch: -72.6238WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -72.6238  Val_loss: -7614.5889 \n",
      "Epoch 68/200\n",
      "96/99 [============================>.] - Loss for batch: -76.0174WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -76.0174  Val_loss: -8096.9819 \n",
      "Epoch 69/200\n",
      "96/99 [============================>.] - Loss for batch: -80.3037WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -80.3037  Val_loss: -8538.8389 \n",
      "Epoch 70/200\n",
      "96/99 [============================>.] - Loss for batch: -83.0754WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -83.0754  Val_loss: -9139.2080 \n",
      "Epoch 71/200\n",
      "99/99 [==============================] - trainLoss: -87.0944  Val_loss: -8720.2666 \n",
      "Epoch 72/200\n",
      "99/99 [==============================] - trainLoss: -91.4687  Val_loss: -8942.0693 \n",
      "Epoch 73/200\n",
      "99/99 [==============================] - trainLoss: -93.3386  Val_loss: -8673.4248 \n",
      "Epoch 74/200\n",
      "99/99 [==============================] - trainLoss: -93.3943  Val_loss: -8952.9688 \n",
      "Epoch 75/200\n",
      "96/99 [============================>.] - Loss for batch: -94.6974WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "99/99 [==============================] - trainLoss: -94.6974  Val_loss: -9234.4951 \n",
      "Epoch 76/200\n",
      "99/99 [==============================] - trainLoss: -95.8204  Val_loss: -8962.7266 \n",
      "Epoch 77/200\n",
      "99/99 [==============================] - trainLoss: -96.4412  Val_loss: -8832.9883 \n",
      "Epoch 78/200\n",
      "99/99 [==============================] - trainLoss: -96.2188  Val_loss: -8975.5938 \n",
      "Epoch 79/200\n",
      "99/99 [==============================] - trainLoss: -96.1133  Val_loss: -8575.8379 \n",
      "Epoch 80/200\n",
      "99/99 [==============================] - trainLoss: -96.0674  Val_loss: -8811.4834 \n",
      "Epoch 81/200\n",
      "99/99 [==============================] - trainLoss: -97.4825  Val_loss: -8889.8330 \n",
      "Epoch 82/200\n",
      "99/99 [==============================] - trainLoss: -98.5364  Val_loss: -9039.4160 \n",
      "Epoch 83/200\n",
      "99/99 [==============================] - trainLoss: -98.8505  Val_loss: -8837.7803 \n",
      "Epoch 84/200\n",
      "99/99 [==============================] - trainLoss: -96.2617  Val_loss: -8778.9453 \n",
      "Epoch 85/200\n",
      "99/99 [==============================] - trainLoss: -98.0138  Val_loss: -9059.3428 \n",
      "Epoch 86/200\n",
      "99/99 [==============================] - trainLoss: -96.7606  Val_loss: -8832.3965 \n",
      "Epoch 87/200\n",
      "99/99 [==============================] - trainLoss: -97.6177  Val_loss: -8460.6592 \n",
      "Epoch 88/200\n",
      "99/99 [==============================] - trainLoss: -97.3664  Val_loss: -8689.5352 \n",
      "Epoch 89/200\n",
      "99/99 [==============================] - trainLoss: -97.2646  Val_loss: -8255.5166 \n",
      "Epoch 90/200\n",
      "99/99 [==============================] - trainLoss: -97.2855  Val_loss: -8219.9521 \n",
      "Epoch 91/200\n",
      "99/99 [==============================] - trainLoss: -97.5302  Val_loss: -8702.8398 \n",
      "Epoch 92/200\n",
      "99/99 [==============================] - trainLoss: -97.2732  Val_loss: -8710.7021 \n",
      "Epoch 93/200\n",
      "99/99 [==============================] - trainLoss: -96.4945  Val_loss: -8210.6221 \n",
      "Epoch 94/200\n",
      "99/99 [==============================] - trainLoss: -99.0751  Val_loss: -8078.1396 \n",
      "Epoch 95/200\n",
      "99/99 [==============================] - trainLoss: -97.6141  Val_loss: -8285.5029 \n",
      "Epoch 96/200\n",
      "99/99 [==============================] - trainLoss: -97.5262  Val_loss: -8164.3105 \n",
      "Epoch 97/200\n",
      "99/99 [==============================] - trainLoss: -96.2469  Val_loss: -8424.8330 \n",
      "Epoch 98/200\n",
      "99/99 [==============================] - trainLoss: -97.5437  Val_loss: -8529.1152 \n",
      "Epoch 99/200\n",
      "99/99 [==============================] - trainLoss: -99.3225  Val_loss: -8576.1680 \n",
      "Epoch 100/200\n",
      "99/99 [==============================] - trainLoss: -97.7829  Val_loss: -8012.9810 \n",
      "Epoch 101/200\n",
      "99/99 [==============================] - trainLoss: -97.5914  Val_loss: -8001.5522 \n",
      "Epoch 102/200\n",
      "99/99 [==============================] - trainLoss: -99.1107  Val_loss: -8377.0850 \n",
      "Epoch 103/200\n",
      "99/99 [==============================] - trainLoss: -97.0627  Val_loss: -8293.2646 \n",
      "Epoch 104/200\n",
      "99/99 [==============================] - trainLoss: -98.0907  Val_loss: -8413.7578 \n",
      "Epoch 105/200\n",
      "99/99 [==============================] - trainLoss: -97.9978  Val_loss: -8193.5498 \n",
      "Epoch 106/200\n",
      "99/99 [==============================] - trainLoss: -98.0468  Val_loss: -8083.1416 \n",
      "Epoch 107/200\n",
      "99/99 [==============================] - trainLoss: -99.1592  Val_loss: -8178.0151 \n",
      "Epoch 108/200\n",
      "99/99 [==============================] - trainLoss: -98.5447  Val_loss: -8415.9434 \n",
      "Epoch 109/200\n",
      "99/99 [==============================] - trainLoss: -97.3842  Val_loss: -8408.5137 \n",
      "Epoch 110/200\n",
      "99/99 [==============================] - trainLoss: -99.0039  Val_loss: -8580.3916 \n",
      "Epoch 111/200\n",
      "99/99 [==============================] - trainLoss: -98.7910  Val_loss: -8184.7729 \n",
      "Epoch 112/200\n",
      "99/99 [==============================] - trainLoss: -98.3713  Val_loss: -8086.9604 \n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - trainLoss: -98.2659  Val_loss: -8178.5547 \n",
      "Epoch 114/200\n",
      "99/99 [==============================] - trainLoss: -98.1610  Val_loss: -8232.7900 \n",
      "Epoch 115/200\n",
      "99/99 [==============================] - trainLoss: -100.2947  Val_loss: -8620.7393 \n",
      "Epoch 116/200\n",
      "99/99 [==============================] - trainLoss: -98.0344  Val_loss: -8424.6045 \n",
      "Epoch 117/200\n",
      "99/99 [==============================] - trainLoss: -98.3757  Val_loss: -8126.1826 \n",
      "Epoch 118/200\n",
      "99/99 [==============================] - trainLoss: -97.1004  Val_loss: -7393.0669 \n",
      "Epoch 119/200\n",
      "99/99 [==============================] - trainLoss: -98.3212  Val_loss: -7359.8345 \n",
      "Epoch 120/200\n",
      "99/99 [==============================] - trainLoss: -97.8576  Val_loss: -7695.1396 \n",
      "Epoch 121/200\n",
      "99/99 [==============================] - trainLoss: -98.2901  Val_loss: -7905.9565 \n",
      "Epoch 122/200\n",
      "99/99 [==============================] - trainLoss: -98.9703  Val_loss: -8185.7192 \n",
      "Epoch 123/200\n",
      "99/99 [==============================] - trainLoss: -98.4000  Val_loss: -8317.0234 \n",
      "Epoch 124/200\n",
      "99/99 [==============================] - trainLoss: -96.7233  Val_loss: -8424.6240 \n",
      "Epoch 125/200\n",
      "99/99 [==============================] - trainLoss: -98.3189  Val_loss: -8140.0088 \n",
      "Epoch 126/200\n",
      "99/99 [==============================] - trainLoss: -99.0901  Val_loss: -8171.3120 \n",
      "Epoch 127/200\n",
      "99/99 [==============================] - trainLoss: -97.4975  Val_loss: -8234.5957 \n",
      "Epoch 128/200\n",
      "99/99 [==============================] - trainLoss: -99.1204  Val_loss: -8252.7285 \n",
      "Epoch 129/200\n",
      "99/99 [==============================] - trainLoss: -97.1033  Val_loss: -8251.6484 \n",
      "Epoch 130/200\n",
      "99/99 [==============================] - trainLoss: -98.2610  Val_loss: -7955.3359 \n",
      "Epoch 131/200\n",
      "99/99 [==============================] - trainLoss: -99.1368  Val_loss: -8049.7129 \n",
      "Epoch 132/200\n",
      "99/99 [==============================] - trainLoss: -100.1698  Val_loss: -8610.8877 \n",
      "Epoch 133/200\n",
      "99/99 [==============================] - trainLoss: -100.0506  Val_loss: -8815.5332 \n",
      "Epoch 134/200\n",
      "99/99 [==============================] - trainLoss: -97.5018  Val_loss: -8312.5283 \n",
      "Epoch 135/200\n",
      "99/99 [==============================] - trainLoss: -98.9133  Val_loss: -8213.1494 \n",
      "Epoch 136/200\n",
      "99/99 [==============================] - trainLoss: -97.5349  Val_loss: -8169.3506 \n",
      "Epoch 137/200\n",
      "99/99 [==============================] - trainLoss: -97.6719  Val_loss: -8396.8438 \n",
      "Epoch 138/200\n",
      "99/99 [==============================] - trainLoss: -97.8050  Val_loss: -7928.1235 \n",
      "Epoch 139/200\n",
      "99/99 [==============================] - trainLoss: -97.9826  Val_loss: -7755.0610 \n",
      "Epoch 140/200\n",
      "99/99 [==============================] - trainLoss: -98.4571  Val_loss: -8216.9941 \n",
      "Epoch 141/200\n",
      "99/99 [==============================] - trainLoss: -98.1877  Val_loss: -8380.4365 \n",
      "Epoch 142/200\n",
      "99/99 [==============================] - trainLoss: -98.1953  Val_loss: -8317.1035 \n",
      "Epoch 143/200\n",
      "99/99 [==============================] - trainLoss: -97.2139  Val_loss: -8008.2007 \n",
      "Epoch 144/200\n",
      "99/99 [==============================] - trainLoss: -98.1228  Val_loss: -7849.9458 \n",
      "Epoch 145/200\n",
      "99/99 [==============================] - trainLoss: -97.7895  Val_loss: -8032.2954 \n",
      "Epoch 146/200\n",
      "99/99 [==============================] - trainLoss: -99.0952  Val_loss: -8327.6279 \n",
      "Epoch 147/200\n",
      "99/99 [==============================] - trainLoss: -97.2783  Val_loss: -8275.4248 \n",
      "Epoch 148/200\n",
      "99/99 [==============================] - trainLoss: -98.1406  Val_loss: -8417.3115 \n",
      "Epoch 149/200\n",
      "99/99 [==============================] - trainLoss: -98.1157  Val_loss: -8464.2402 \n",
      "Epoch 150/200\n",
      "99/99 [==============================] - trainLoss: -98.6178  Val_loss: -8360.3350 \n",
      "Epoch 151/200\n",
      "99/99 [==============================] - trainLoss: -99.0372  Val_loss: -7940.3906 \n",
      "Epoch 152/200\n",
      "99/99 [==============================] - trainLoss: -98.0126  Val_loss: -8270.8887 \n",
      "Epoch 153/200\n",
      "99/99 [==============================] - trainLoss: -96.8516  Val_loss: -8128.3916 \n",
      "Epoch 154/200\n",
      "99/99 [==============================] - trainLoss: -98.0999  Val_loss: -7867.0840 \n",
      "Epoch 155/200\n",
      "99/99 [==============================] - trainLoss: -99.4255  Val_loss: -8386.8721 \n",
      "Epoch 156/200\n",
      "99/99 [==============================] - trainLoss: -96.6521  Val_loss: -8054.8340 \n",
      "Epoch 157/200\n",
      "99/99 [==============================] - trainLoss: -98.6076  Val_loss: -8024.8408 \n",
      "Epoch 158/200\n",
      "99/99 [==============================] - trainLoss: -97.9892  Val_loss: -8109.4160 \n",
      "Epoch 159/200\n",
      "99/99 [==============================] - trainLoss: -98.1266  Val_loss: -7827.9282 \n",
      "Epoch 160/200\n",
      "99/99 [==============================] - trainLoss: -97.4143  Val_loss: -7685.9048 \n",
      "Epoch 161/200\n",
      "99/99 [==============================] - trainLoss: -97.3696  Val_loss: -7592.0962 \n",
      "Epoch 162/200\n",
      "99/99 [==============================] - trainLoss: -97.5581  Val_loss: -7631.0771 \n",
      "Epoch 163/200\n",
      "99/99 [==============================] - trainLoss: -97.8004  Val_loss: -7952.7695 \n",
      "Epoch 164/200\n",
      "99/99 [==============================] - trainLoss: -97.5182  Val_loss: -8080.0581 \n",
      "Epoch 165/200\n",
      "99/99 [==============================] - trainLoss: -97.6599  Val_loss: -8269.1787 \n",
      "Epoch 166/200\n",
      "99/99 [==============================] - trainLoss: -98.1077  Val_loss: -8167.7808 \n",
      "Epoch 167/200\n",
      "99/99 [==============================] - trainLoss: -98.0867  Val_loss: -8115.1694 \n",
      "Epoch 168/200\n",
      "99/99 [==============================] - trainLoss: -97.7478  Val_loss: -8221.9209 \n",
      "Epoch 169/200\n",
      "99/99 [==============================] - trainLoss: -98.9138  Val_loss: -7927.5469 \n",
      "Epoch 170/200\n",
      "99/99 [==============================] - trainLoss: -99.6075  Val_loss: -8024.6143 \n",
      "Epoch 171/200\n",
      "99/99 [==============================] - trainLoss: -97.0747  Val_loss: -8207.4512 \n",
      "Epoch 172/200\n",
      "99/99 [==============================] - trainLoss: -98.6103  Val_loss: -8029.9907 \n",
      "Epoch 173/200\n",
      "99/99 [==============================] - trainLoss: -98.5055  Val_loss: -7981.1250 \n",
      "Epoch 174/200\n",
      "99/99 [==============================] - trainLoss: -97.1776  Val_loss: -7573.2783 \n",
      "Epoch 175/200\n",
      "99/99 [==============================] - trainLoss: -97.6581  Val_loss: -7405.0815 \n",
      "Epoch 176/200\n",
      "99/99 [==============================] - trainLoss: -97.9827  Val_loss: -7402.0112 \n",
      "Epoch 177/200\n",
      "99/99 [==============================] - trainLoss: -98.1838  Val_loss: -7551.5630 \n",
      "Epoch 178/200\n",
      "99/99 [==============================] - trainLoss: -97.8034  Val_loss: -8227.0312 \n",
      "Epoch 179/200\n",
      "99/99 [==============================] - trainLoss: -99.2099  Val_loss: -8272.4521 \n",
      "Epoch 180/200\n",
      "99/99 [==============================] - trainLoss: -98.8445  Val_loss: -8244.9678 \n",
      "Epoch 181/200\n",
      "99/99 [==============================] - trainLoss: -99.2632  Val_loss: -8333.2275 \n",
      "Epoch 182/200\n",
      "99/99 [==============================] - trainLoss: -96.9704  Val_loss: -8060.4575 \n",
      "Epoch 183/200\n",
      "99/99 [==============================] - trainLoss: -97.4163  Val_loss: -7867.4316 \n",
      "Epoch 184/200\n",
      "99/99 [==============================] - trainLoss: -98.0380  Val_loss: -7658.0454 \n",
      "Epoch 185/200\n",
      "99/99 [==============================] - trainLoss: -98.0616  Val_loss: -7727.0342 \n",
      "Epoch 186/200\n",
      "99/99 [==============================] - trainLoss: -98.2967  Val_loss: -8017.1704 \n",
      "Epoch 187/200\n",
      "99/99 [==============================] - trainLoss: -98.2771  Val_loss: -7588.2153 \n",
      "Epoch 188/200\n",
      "99/99 [==============================] - trainLoss: -96.7682  Val_loss: -7381.3989 \n",
      "Epoch 189/200\n",
      "99/99 [==============================] - trainLoss: -98.8340  Val_loss: -7717.3789 \n",
      "Epoch 190/200\n",
      "99/99 [==============================] - trainLoss: -99.0038  Val_loss: -7435.5283 \n",
      "Epoch 191/200\n",
      "99/99 [==============================] - trainLoss: -99.2976  Val_loss: -7893.1509 \n",
      "Epoch 192/200\n",
      "99/99 [==============================] - trainLoss: -98.1261  Val_loss: -8060.2280 \n",
      "Epoch 193/200\n",
      "99/99 [==============================] - trainLoss: -97.1823  Val_loss: -8004.0337 \n",
      "Epoch 194/200\n",
      "99/99 [==============================] - trainLoss: -97.7330  Val_loss: -7574.7266 \n",
      "Epoch 195/200\n",
      "99/99 [==============================] - trainLoss: -98.7189  Val_loss: -7585.4590 \n",
      "Epoch 196/200\n",
      "99/99 [==============================] - trainLoss: -99.0416  Val_loss: -7618.5278 \n",
      "Epoch 197/200\n",
      "99/99 [==============================] - trainLoss: -98.1188  Val_loss: -7876.8618 \n",
      "Epoch 198/200\n",
      "99/99 [==============================] - trainLoss: -98.1853  Val_loss: -8156.8511 \n",
      "Epoch 199/200\n",
      "99/99 [==============================] - trainLoss: -99.9720  Val_loss: -8297.4990 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "test_loglik_list = []\n",
    "val_loglik_list = []\n",
    "\n",
    "for i in range(15):\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state = keras.layers.GRU(hidden_state_size,return_sequences=True,return_state=True)(inputs=x_in,initial_state=hidden_state_in)\n",
    "\n",
    "    hidden_model = keras.models.Model(inputs=[x_in,x_out,hidden_state_in],outputs=[output2,state])\n",
    "\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "    hr_out = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "    hr_in = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state= hidden_model([x_in,x_out,hidden_state_in])\n",
    "\n",
    "    layer_hr = keras.layers.Dropout(0.3)(output2)\n",
    "    layer_hr = keras.layers.Dense(16,activation=\"elu\")(layer_hr)\n",
    "    layer_hr = keras.layers.Dropout(0.3)(layer_hr)\n",
    "    final_hr_mean = keras.layers.TimeDistributed(keras.layers.Dense(num_dims_hr,bias_initializer='zeros'))(layer_hr) + hr_in\n",
    "    sigma_mle_hr = (K.mean((final_hr_mean- hr_out)**2))**0.5\n",
    "\n",
    "    loglik_hr = loglik_gaussian_hr(hr_out,final_hr_mean,sigma_mle_hr)\n",
    "\n",
    "    nloglik_hr = loss(loglik_hr)\n",
    "\n",
    "    rnn_training_hr = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[nloglik_hr])\n",
    "    rnn_generate_hr = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[final_hr_mean,sigma_mle_hr,state])\n",
    "\n",
    "\n",
    "    x_in = keras.layers.Input(shape=[None,num_dims])\n",
    "    x_out = keras.layers.Input(shape=[None,num_dims])\n",
    "    hr_out = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "    hr_in = keras.layers.Input(shape=[None,num_dims_hr])\n",
    "\n",
    "    hidden_state_in = keras.layers.Input(shape=[hidden_state_size])\n",
    "\n",
    "    output2,state = hidden_model([x_in,x_out,hidden_state_in],training=False)\n",
    "\n",
    "    layer = keras.layers.Dropout(0.3)(output2)\n",
    "    layer = keras.layers.Dense(8,activation=\"elu\")(layer)\n",
    "    layer = keras.layers.Dropout(0.3)(layer)\n",
    "    final_x_mean = keras.layers.TimeDistributed(keras.layers.Dense(num_dims,bias_initializer='zeros'))(layer) + x_in #this means we predict the residuals (better for learning)\n",
    "    sigma_mle_x = (K.mean((final_x_mean- x_out)**2))**0.5\n",
    "\n",
    "\n",
    "    loglik_x = loglik_gaussian_x(x_out,final_x_mean,sigma_mle_x)\n",
    "\n",
    "    nloglikx = loss(loglik_x)\n",
    "\n",
    "    rnn_training_x = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[nloglikx])\n",
    "    rnn_generate_x = keras.models.Model(inputs=[x_in,x_out,hr_in,hr_out,hidden_state_in],outputs=[final_x_mean,sigma_mle_x,state])\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(inputs,model):\n",
    "        \"\"\"Decorated train_step function which applies a gradient update to the parameters\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model(inputs,training=True)\n",
    "            loss = tf.add_n([loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    def fit_model(input_list,epochs,model,simulator,history,validation_loss\n",
    "                  ,valid_list,hr_toggle,index,batch_size=32):\n",
    "\n",
    "        start = time.time()\n",
    "        K.clear_session()\n",
    "\n",
    "        batch_loss = []\n",
    "        batches_per_epoch = int(np.ceil(input_list[0].shape[0]/batch_size))\n",
    "        \n",
    "        rnn_generate_x.save(\"tl_models/{}.h5\".format(index))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "                print(\"Epoch {}/{}\".format(epoch,epochs))\n",
    "                for i in range(batches_per_epoch):\n",
    "                    batch_list= create_batch(\n",
    "                        input_list,batch_size)\n",
    "                    loss = train_step(batch_list,model)\n",
    "                    batch_loss.append(loss)\n",
    "                    average_batch_loss = list_average(batch_loss)\n",
    "                    print_status_bar(i*batch_size,input_list[0].shape[0],average_batch_loss)\n",
    "\n",
    "                training_loss_for_epoch = list_average(batch_loss)\n",
    "                batch_loss = []\n",
    "                history.append(training_loss_for_epoch)\n",
    "\n",
    "                sigma_mle = simulator(input_list)[1]\n",
    "\n",
    "                val_loss = valid_loss(valid_list,simulator=simulator,sigma_x = sigma_mle,hr=hr_toggle)\n",
    "\n",
    "                validation_loss.append(val_loss)\n",
    "                if val_loss == min(validation_loss):\n",
    "                    rnn_generate_x.save(\"tl_models/{}.h5\".format(index))\n",
    "\n",
    "                print_status_bar_epoch(input_list[0].shape[0]\n",
    "                                 ,input_list[0].shape[0],training_loss_for_epoch,val_loss )\n",
    "\n",
    "        done = time.time()\n",
    "        elapsed = done-start\n",
    "\n",
    "        \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    \n",
    "    fit_model(input_list,20,rnn_training_hr,rnn_generate_hr,training_losses,validation_losses\n",
    "              ,valid_list,hr_toggle=True,index=i,batch_size=32)\n",
    "    \n",
    "    \n",
    "    hidden_model.trainable=False\n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(inputs,model):\n",
    "        \"\"\"Decorated train_step function which applies a gradient update to the parameters\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model(inputs,training=True)\n",
    "            loss = tf.add_n([loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    def fit_model(input_list,epochs,model,simulator,history,validation_loss\n",
    "                  ,valid_list,hr_toggle,index,batch_size=32):\n",
    "\n",
    "        start = time.time()\n",
    "        K.clear_session()\n",
    "\n",
    "        batch_loss = []\n",
    "        batches_per_epoch = int(np.ceil(input_list[0].shape[0]/batch_size))\n",
    "        \n",
    "        rnn_generate_x.save(\"tl_models/{}.h5\".format(index))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "                print(\"Epoch {}/{}\".format(epoch,epochs))\n",
    "                for i in range(batches_per_epoch):\n",
    "                    batch_list= create_batch(\n",
    "                        input_list,batch_size)\n",
    "                    loss = train_step(batch_list,model)\n",
    "                    batch_loss.append(loss)\n",
    "                    average_batch_loss = list_average(batch_loss)\n",
    "                    print_status_bar(i*batch_size,input_list[0].shape[0],average_batch_loss)\n",
    "\n",
    "                training_loss_for_epoch = list_average(batch_loss)\n",
    "                batch_loss = []\n",
    "                history.append(training_loss_for_epoch)\n",
    "\n",
    "                sigma_mle = simulator(input_list)[1]\n",
    "\n",
    "                val_loss = valid_loss(valid_list,simulator=simulator,sigma_x = sigma_mle,hr=hr_toggle)\n",
    "\n",
    "                validation_loss.append(val_loss)\n",
    "                if val_loss == min(validation_loss):\n",
    "                    rnn_generate_x.save(\"tl_models/{}.h5\".format(index))\n",
    "\n",
    "                print_status_bar_epoch(input_list[0].shape[0]\n",
    "                                 ,input_list[0].shape[0],training_loss_for_epoch,val_loss )\n",
    "\n",
    "        done = time.time()\n",
    "        elapsed = done-start\n",
    "\n",
    "        plt.plot(validation_loss,label=\"validation\")\n",
    "        plt.show()\n",
    "\n",
    "    fit_model(input_list,200,rnn_training_x,rnn_generate_x,training_losses,validation_losses\n",
    "              ,valid_list,hr_toggle=False,index=i,batch_size=32)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    rnn_generate_x = keras.models.load_model(\"tl_models/{}.h5\".format(i))\n",
    "    \n",
    "    sigma_x = rnn_generate_x(input_list)[1]\n",
    "    mean = rnn_generate_x(test_list)[0]\n",
    "    loglik = np.mean(loglik_gaussian_x(test_nn_output,mean,sigma_x))\n",
    "\n",
    "    test_loglik_list.append(loglik)\n",
    "    \n",
    "    mean = rnn_generate_x(valid_list)[0]\n",
    "    loglik = np.mean(loglik_gaussian_x(valid_nn_output,mean,sigma_x))\n",
    "\n",
    "    val_loglik_list.append(loglik)\n",
    "    \n",
    "a = np.array(test_loglik_list)\n",
    "b = np.array(val_loglik_list)\n",
    "array_loglik = np.stack([b,a],axis=1)\n",
    "np.save(\"tl_models/loglik_array.npy\",array_loglik)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9447.353, 2779064.2  ],\n",
       "       [   9129.026, 2678161.5  ],\n",
       "       [   9420.567, 2713152.   ],\n",
       "       [   9119.233, 2703558.   ],\n",
       "       [   9398.688, 2734757.8  ],\n",
       "       [   9459.448, 2763107.2  ],\n",
       "       [   9522.136, 2778008.2  ],\n",
       "       [   9453.144, 2765898.5  ],\n",
       "       [   9365.953, 2756722.   ],\n",
       "       [   9540.198, 2792608.2  ],\n",
       "       [   9400.421, 2744609.5  ],\n",
       "       [   9470.63 , 2775609.5  ],\n",
       "       [   9500.283, 2794984.   ],\n",
       "       [   9282.673, 2760949.5  ],\n",
       "       [   9234.495, 2736996.   ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_loglik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6753729e+03,  1.3989975e+06],\n",
       "       [ 2.2109958e+03,  1.9560465e+06],\n",
       "       [ 1.7163282e+03,  1.6983150e+06],\n",
       "       [ 2.7829414e+03,  1.4063108e+06],\n",
       "       [ 4.2518799e+03,  1.4718738e+06],\n",
       "       [-1.1344034e+03, -9.0117445e+04],\n",
       "       [ 5.3731134e+02, -2.9211159e+05],\n",
       "       [ 5.8165449e+03,  2.1455115e+06],\n",
       "       [-7.6814703e+02, -2.1399133e+05],\n",
       "       [ 1.4390370e+03,  7.1822850e+05],\n",
       "       [ 4.1379209e+03,  1.4822712e+06],\n",
       "       [ 2.5738913e+02,  1.8782148e+06],\n",
       "       [ 4.0522866e+03,  1.9413259e+06],\n",
       "       [-1.2877104e+03, -1.9659972e+05],\n",
       "       [ 4.4812061e+03,  1.6783796e+06]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_array = np.load(\"no_tl_models/loglik_array.npy\")\n",
    "loglik_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmax(loglik_array[:,0])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145511.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_array[index,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 16:27:23.553984: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-11 16:27:24.254611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5208 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:3b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "rnn_no_tl = keras.models.load_model(\"no_tl_models/{}.h5\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 16:27:29.226607: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0019546913>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = rnn_no_tl(input_list)[1]\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999871771163216"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = rnn_no_tl(test_list)[0]\n",
    "\n",
    "r2_score(np.ravel(test_list[1]),np.ravel(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3316415e-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((test_list[1] - mean)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9447.353, 2779064.2  ],\n",
       "       [   9129.026, 2678161.5  ],\n",
       "       [   9420.567, 2713152.   ],\n",
       "       [   9119.233, 2703558.   ],\n",
       "       [   9398.688, 2734757.8  ],\n",
       "       [   9459.448, 2763107.2  ],\n",
       "       [   9522.136, 2778008.2  ],\n",
       "       [   9453.144, 2765898.5  ],\n",
       "       [   9365.953, 2756722.   ],\n",
       "       [   9540.198, 2792608.2  ],\n",
       "       [   9400.421, 2744609.5  ],\n",
       "       [   9470.63 , 2775609.5  ],\n",
       "       [   9500.283, 2794984.   ],\n",
       "       [   9282.673, 2760949.5  ],\n",
       "       [   9234.495, 2736996.   ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_array = np.load(\"tl_models/loglik_array.npy\")\n",
    "loglik_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argmax(loglik_array[:,0])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2792608.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_array[index,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.08694166666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_array[index,1] / 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:04:44.785406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-11 17:04:45.463504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5699 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:3b:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "rnn_tl = keras.models.load_model(\"tl_models/{}.h5\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 17:04:53.170404: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.001787844>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = rnn_tl(input_list)[1]\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999995362777461"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = rnn_tl(test_list)[0]\n",
    "\n",
    "r2_score(np.ravel(test_list[1]),np.ravel(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.815701e-06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((test_list[1] - mean)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cloud_param_gpu]",
   "language": "python",
   "name": "conda-env-cloud_param_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
